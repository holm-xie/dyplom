\chapter{Definicja Problemu}

\section*{Streszczenie}
W poniższym rozdziale zostanie zaprezentowany problem, który usiłują rozwiązać systemy opisane w niniejszej pracy.
Przedstawione zostaną sposoby skalowania aplikacji przy zastosowaniu relacyjnych baz danych.
Opisane zostanie także pojęcie NoSQL i jakie problemy próbuje ten ruch rozwiązać.

\section{Wstęp}
Popularyzacja dostępu do internetu przyczyniła się w ostatnich latach do  powstania licznych serwisów, które mogą się pochwalić dziesiątkami, a nawet setkami milionów odwiedzin dziennie. 
Twórcy serwisów takich jak Facebook, Twitter czy Google zostali postawieni przed problemem stworzenia rozproszonej architektury bazodanowej, która zapewni horyzontalną skalowalność przy równoczesnym zachowaniu wysokiej dostępności. 
Ze względu na występujący jeszcze kilka lat temu brak takich rozwiązań na rynku firmy te były zmuszone do implementacji tego typu baz na własne potrzeby. 
Ostatnimi laty jednak sytuacja zaczęła ulegać zmianie: produkty wytworzone na wewnętrzny użytek zostają upubliczniane na licencjach Open Source, dzięki czemu obecnie mamy już dostęp do przynajmniej kilkunastu rozwiązań umożliwiających dostęp do peta-bajtów danych rozproszonych na tysiącach serwerów.

\section{Skalowalność}
Niniejsza praca stawia przed sobą zadanie wprowadzenia czytelnika w świat wysoce skalowalnych systemów bazodanowych.
Aby jednak tego dokonać musimy najpierw przedstawić, czym jest skalowalność w rozumieniu autora i jakiego typu skalowalnością będziemy się zajmować.

Wyobraźmy sobie aplikację internetową, na przykład stronę społecznościową taką jak Nasza Klasa czy Facebook.
Aplikacje takie jak ta początkowo mają tysiące użytkowników, a gdy odniosą sukces, liczba ta może wzrosnąć do dziesiątek czy nawet setek milionów.
Ponadto aplikacje te podlegają ciągłemu rozwojowi przez wiele lat, co bardzo często pociąga za sobą konieczność wprowadzania zmian w schemacie bazy, a także niejednokrotnie dokonywania migracji danych.

System bazodanowy jest skalowalny w rozumieniu tej pracy, jeżeli koszty jego utrzymania wzrastają co najwyżej liniowo wraz ze wzrostem liczby użytkowników aplikacji. 
Warunkiem koniecznym jest także to, aby czas potrzebny na wykonanie operacji na rzecz użytkownika aplikacji (zapisy, odczyty), nie degradował się znacznie wraz ze wzrostem ilości danych, którymi system zarządza.

\section{Tradycyjne rozwiązania}
Dotychczas najczęściej stosowanym rozwiązaniem problemów skalowalności było zastosowanie bazy danych takiej jak MySQL połączonej z Memcached jako przechowywany w pamięci operacyjnej, rozproszony cache \cite{highscalability-mysql-end-of-an-era}.
Opiszmy pokrótce, jak takie skalowanie aplikacji w uproszczeniu wygląda.

\subsection{Replikacja}
Początkowo cała baza danych mieści się na jednej maszynie i jest w stanie poradzić sobie ze wszystkimi operacjami odczytu i zapisu jakich dokonuje aplikacja.
Wraz ze wzrostem liczby użytkowników serwer zaczyna docierać do granic swojej przepustowości. 
Ponieważ aplikacje internetowe wykonują zazwyczaj dużo więcej odczytów niż zapisów, dodajemy stopniowo kilka kolejnych serwerów replikowanych w konfiguracji master-slave, zwiększając w ten sposób liczbę równoczesnych odczytów, jednak nie zwiększając (a nawet zmniejszając) liczby możliwych zapisów.
Alternatywą jest dodawanie kolejnych serwerów w konfiguracji master-master, która jest zazwyczaj trudniejsza do poprawnego skonfigurowania, ale za to w przypadku gdy jeden z serwerów master zawiedzie, inny z łatwością przejmie jego rolę.

\myfigure{chapters/definicja_problemu/master-slave.png}{Replikacja Master-Slave}{fig:master-slave}

Warto jednak zwrócić uwagę, na to jak szybko takie rozwiązanie się degraduje.
Załóżmy, że początkowo serwer \emph{master} jest obciążony w 50\% zapisami.
Oznacza to, że każdy z węzłów \emph{slave} musi także poświęcić 50\% zasobów na radzenie sobie z replikacją zapisów\footnote{Zakładam, że wszystkie serwery są identyczne}, a resztę może poświęcić na przetwarzanie odczytów.
Wraz ze wzrostem obciążenia serwera \emph{master}, serwery \emph{slave} muszą coraz więcej zasobów poświęcać na replikację zapisów, co zmniejsza ogólną przepustowość systemu.
Ponadto problemem może być także to, że niektóre systemy baz danych, tak jak, np. MySQL dokonują replikacji asynchronicznie.
Powoduje to, że po dokonaniu operacji zapisu, odczyt może zwrócić wartość niezgodą z zapisaną.
Wymaga to dodatkowej pracy ze strony programisty \cite{zaitsev-scaling-mysql}.

\subsection{Partycjonowanie}
Kiedy oczywiste staje się, że nasz serwer nie jest w stanie sobie poradzić z obciążeniem wynikającym z zapisów, mamy dwie drogi do wyboru: wymienić maszynę na mocniejszą, albo zacząć przetrzymywać tylko część danych na pojedynczym serwerze.
Pierwsza opcja, nazywana \emph{skalowaniem wzwyż}, ma pewne zalety: nie wymaga zmian w aplikacji i jej nie komplikuje.
Wadą tego rozwiązania jest jednak cena w porównaniu do możliwości.
Cytując za artykułem na blogu \emph{Coding Horror} \cite{codinghorror-scaling-up-vs-out}: za cenę stu tysięcy dolarów możemy albo kupić jeden potężny serwer z 32 procesorami, 512GB RAM i 4TB przestrzeni dyskowej, albo 83 mniejsze serwery posiadające łącznie 332 rdzenie, 664GB RAM i 40,5TB przestrzeni dyskowej.
Oczywiście nie można w ten sposób skalować aplikacji wzwyż w nieskończoność, ale warto pamiętać, że tylko nieliczne strony mogą konkurować rozmiarami z takimi gigantami jak Facebook.
Większość aplikacji nigdy nie wyrośnie ponad rozmiar, w którym ,,superkomputer'' nie wystarcza już do utrzymania ich obciążenia.

\myfigure{chapters/definicja_problemu/hp-proliant-dl785.jpg}{HP ProLiant DL785 G5}{fig:superkomputer}

Z drugiej strony mamy partycjonowanie danych, czyli \emph{skalowanie aplikacji wszerz}.
W tym rozwiązaniu wraz ze wzrostem liczby użytkowników zamiast wymieniać serwer na większy i mocniejszy dodajemy kolejne maszyny.
Nie możemy jednak całości bazy danych przechowywać na każdym z serwerów - problemy z tym związane zostały opisane powyżej.
W związku z tym, dokonuje się podziału danych (partycjonowania) poziomego, pionowego albo obu równocześnie.

Kiedy mowa o pojedynczej bazie danych, horyzontalne partycjonowanie oznacza, że wiersze na podstawie jakiegoś kryterium trafiają do różnych tabel.
Dla przykładu: tabela użytkowników może być podzielona w taki sposób, że użytkownicy z Polski trafiają do tabeli \verb=polish_users=, natomiast użytkownicy z Niemiec do tabeli \verb=german_users=.
Tego rodzaju partycjonowania dokonuje się zazwyczaj w celu zwiększenia wydajności i niektóre bazy danych (w tym MySQL\footnote{http://dev.mysql.com/tech-resources/articles/performance-partitioning.html}) pozwalają na definiowanie partycjonowania w schemacie bazy danych.
W przypadku rozproszonych baz danych, mówimy zamiennie o partycjonowaniu horyzontalnym bądź shardowaniu (ang. \emph{sharding}).
Różni się ono od partycjonowania poziomego dla pojedynczej bazy tym, że dane zamiast trafiać do różnych tabel, trafiają do tej samej tabeli, ale na różne węzły bazy danych.

\myfigure{chapters/definicja_problemu/sharding.png}{Shardowanie}{fig:sharding}

Partycjonowanie pionowe (wertykalne) podobnie ma dwa znaczenia w zależności od kontekstu.
Dla pojedynczej bazy polega ono na podziale tabel na mniejsze (zawierające tylko część kolumn).
Przypomina to normalizację bazy, ale dzielimy także już znormalizowane tabele, np. po to aby aby część kolumn umieścić na innym dysku, albo aby oddzielić częściej odczytywane dane od rzadziej odczytywanych.
W rozproszonym systemie partycjonowanie pionowe oznacza, że nie połączone ze sobą tabele mogą być umieszczone na różnych węzłach bazy danych.
W ten sposób zapis do jednej tabeli nie obciąża dwóch, tylko jeden serwer.
Oczywiście bardzo często nie jest możliwe znalezienie tabel, które nie są za sobą połączone pośrednio lub bezpośrednio.
Dlatego często takie partycjonowanie wymaga zduplikowania części tabel na obu węzłach.

Opisane wyżej formy partycjonowania systemów rozproszonych najczęściej muszą być obsługiwane przez warstwę aplikacji.
Z tego względu praktycznie niemożliwe jest zapewnienie transakcyjności pomiędzy poszczególnymi węzłami.
Kosztowne i trudne są także operacje joinowania pomiędzy serwerami.

\subsection{Memcached}

Podstawową receptą na przyspieszenie aplikacji internetowych jest cacheowanie.
Najpopularniejszym rozwiązaniem stosowanym do tego celu jest obecnie Memcached.
Memcached to \emph{darmowy i open source, rozproszony, wysokowydajny system do przechowywania obiektów w pamięci, ogólnego zastosowania ale przeznaczony do przyspieszania dynamicznych aplikacji internetowych przez zmniejszenie obciążenia bazy danych}\footnote{ang. Free \& open source, high-performance, distributed memory object caching system, generic in nature, but intended for use in speeding up dynamic web applications by alleviating database load. - http://memcached.org/}.
Ponieważ serwery Memcached nie komunikują się między sobą bezpośrednio, możemy zwiększać przepustowość systemu liniowo, poprzez dodawanie kolejnych maszyn.
Stosowanie Memcached w porównaniu do cache bazy danych ma wiele zalet: cache bazy danych jest ograniczony do pojedynczego serwera, czyszczony przy zapisach i ograniczony w tym, co możemy do niego zapisywać.
Dla porównania nad Memcached mamy o wiele większą kontrolę i większą swobodę co do tego co w nim się znajdzie.
Możemy cacheować pojedyncze wiersze tabel bazy danych, całe tabele, wyniki zapytań wymagających skomplikowanych obliczeń, pliki, fragmenty wygenerowanych stron HTML i wiele innych obiektów.

W architekturach wielu wysokowydajnych aplikacjach internetowych Memcached odgrywa centralną rolę.
W artykule \cite{highscalability-mysql-memcached} czytelnik znajdzie interesujący opis strategii wykorzystania Memcached w serwisie Fotolog.
Szczególnie warta uwagi jest złożoność zaprojektowanego tam systemu, oraz to że fragmenty aplikacji wymagające największej wydajności komunikują się nie z bazą danych bezpośrednio, ale z serwerami cache, w których część tabel jest w całości odwzorowana.

\subsection{Problemy z tradycyjnymi rozwiązaniami}

Tradycyjne rozwiązania, oparte na shardowaniu, replikacji i cacheowaniu sprawdziły się i są w ciągłym użyciu w wielu aplikacjach.
Niestety niosą one ze sobą istotne ograniczenia: shardowanie pociąga za sobą wysoki koszt operacji na zbiorach danych, które są rozproszone na wielu węzłach systemu i brak transakcji, asynchroniczna replikacja wymaga aby odczyty i zapisy pojedynczego klienta były kierowane do tego samego serwera a cache wymaga skomplikowanych procedur inwalidacji\footnote{Poprzez ,,inwalidację'' rozumiem oznaczanie części zapisanych w cache danych jako nieaktualne, usunięcie ich lub zastąpienie aktualnymi. W praktyce bardzo trudno jest zapewnić aktualność danych zapisanych w cache w skomplikowanym systemie, dlatego częściej stosuje się mechanizmy oparte na uaktualnianiu cache po określonym czasie.}, aby zapewnić konsystencję między nim a bazą.
Innym problemem jest też konieczność dokonywania migracji schematu bazy danych wraz z rozwojem aplikacji.
Dodanie kolumny czy indeksu do tabeli zawierającej miliony wierszy czasem trwa nawet godzinami.

Wszystko powyższe wymaga bardzo dużych nakładów pracy na stworzenie i utrzymanie takiego systemu.
Co więcej, systemy stworzone według tej receptury tracą główne zalety relacyjnych baz danych: rezygnując z łączenia tabel rezygnujemy z relacyjności bazy, zaś wprowadzając shardowanie rezygnujemy z możliwości zadawania zapytań, które dotyczyłyby wszystkich wierszy tabeli.
W związku z tym, że systemy te są tworzone od zera na własne potrzeby i często są ściśle związane z infrastrukturą i architekturą aplikacji, bardzo problematyczne jest udostępnienie tego kodu na licencji open source.
W ostatnich latach jednak część z rozwiązań mających na celu zastąpić relacyjne bazy danych w pewnych rozwiązaniach wymagających skalowalności została upubliczniona.
Noszą one wspólną nazwę systemów NoSQL.

\section{NoSQL}
Powszechny i darmowy dostęp do produktów bazodanowych obiecujących wysoką skalowalność zaowocował powstaniem ruchu określanego popularnie mianem NoSQL (\emph{Not only SQL} - nie tylko SQL).
Termin ten powstał początkowo jako nazwa grupy użytkowników rozproszonych baz danych udostępnionych na licencji open source.
Ze względu na to, że nazwa ta umożliwia bardzo szeroką gamę interpretacji, pod metką NoSQL znajdujemy dziś systemy zaprojektowane w celu rozwiązywania diametralnie różnych problemów \cite{evans-nosql-what-is-in-a-name}. 
Ze względu na to, że większość nowych produktów bazodanowych stworzonych z myślą o wysokiej skalowalności nie dysponuje możliwością zadawania zapytań w języku SQL, niezależnie od tego czy są to bazy grafowe, oparte na dokumentach czy nawet proste kontenery klucz-wartość, wszystkie one noszą wspólną nazwę systemów NoSQL.

W literaturze trudno znaleźć nazwę problemu, który próbuje rozwiązać ruch NoSQL. 
W artykule \cite{monash-db-hvsp} autor sugeruje nazwę HVSP (ang. \emph{High Volume Simple Processing}). 
Sugerowane wyróżniki problemu to:
\begin{itemize}
 \item Wielu równocześnie korzystających z bazy użytkowników, dokonujących zarówno odczytów jak i zapisów.
 \item Operacje wykonywane przez użytkowników są nieskomplikowane, bez transakcji, łączenia tabel czy operacji grupujących.
\end{itemize}

Nie wszystkie systemy NoSQL spełniają powyższe warunki.
Warto pamiętać, że przeważająca większość tworzonych w dzisiejszych czasach systemów z powodzeniem działa rozproszona na co najwyżej kilka węzłów, często nawet bez potrzeby partycjonowania danych.
Dlatego właśnie, chociaż ruch NoSQL kojarzy się przede wszystkim ze skalowalnością, jednym z jego założeń jest dostosowanie systemu bazodanowego do potrzeb konkretnej aplikacji.
Przykładowo: chociaż w relacyjnej bazie danych można bez większego problemu odwzorować graf, bazy grafowe umożliwiają znacznie efektywniejsze implementacje algorytmów na tej strukturze danych, ponieważ złożoność operacji znalezienia krawędzi wychodzących bądź wchodzących do wierzchołka nie zależy od wielkości całego grafu (w odróżnieniu od bazy relacyjnej).

W dalszej części tej pracy opisane zostały różne rodzaje baz danych -- zarówno takie, które ułatwiają skalowanie aplikacji, jak i takie, które upraszczają różne aspekty modelowania danych. 