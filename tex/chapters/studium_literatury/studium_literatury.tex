\chapter{Studium Problemu}

\section*{Streszczenie}

W studium problemu opisana została teoria CAP (\emph{Consistency, Availability, Partition Tolerance}), zwana również teorią Brewer'a od nazwiska jej autora. 
Teoria ta twierdzi, że rozproszony system nie jest w stanie zapewnić równocześnie wszystkich trzech gwarancji: konsystencji danych widzianych przez węzły systemu, odporności całości systemu na awarie poszczególnych jego węzłów oraz odporności systemu na utratę połączenia pomiędzy poszczególnymi węzłami lub ich grupami. 

Opisane zostały także BASE (\emph{Basically Available, Soft state, Eventual consistency}) i Eventual Consistency, które wprowadzają model konsystencji systemu bazodanowego, który o wiele lepiej przystaje do systemów rozproszonych niż ACID, dając programiście dużo większe możliwości wpłynięcia na zachowanie systemu i jego charakterystyki wydajnościowe, ale opłacając to kosztem zwiększenia złożoności korzystania z takiego systemu.

Google MapReduce to nie tylko narzędzie pozwalające na przetwarzanie astronomicznych ilości danych.
Jest to także wzorzec wykorzystywany przez wiele systemów NoSQL w celu zapewnienia możliwości przetwarzania dużych zbiorów rekordów pod nieobecność takich operatorów jak GROUP BY w SQL.

Przedstawione zostały także zasady działania Google BigTable oraz Amazon Dynamo, które bardzo istotnie wpłynęły na architekturę systemów NoSQL. 
Bazy te przedstawiają sobą zupełnie różne podejścia do problemu skalowalności: Amazon Dynamo stawia przede wszystkim na dostępność, podczas gdy Google BigTable stawia na konsystencję.

Koncepcje i techniki opisane w tym rozdziale odbijają się echem w architekturach wielu z systemów opisanych w kolejnych częściach niniejszej pracy, dlatego przedstawienie ich tutaj ma za zadanie umożliwić czytelnikowi lepsze zrozumienie tych systemów i tego, jakie założenia czynili ich autorzy podczas ich projektowania.

\section{Teoria CAP}

\subsection*{Wprowadzenie}

Pierwszym zagadnieniem omawianym w tym rozdziale jest Teoria CAP.
Zrozumienie tej teorii ma istotne znaczenie dla udanej analizy rozproszonych systemów bazodanowych.
Wzmianki i odniesienia do niej można znaleźć w bardzo wielu artykułach dotyczących NoSQL, a ponieważ teoria ta nie została przez autora sformułowana w postaci publikacji, istnieje wiele jej interpretacji i rozbieżności w tym, jak różni ludzie ją rozumieją.

\subsection*{Historia}

Teoria CAP (\emph{Consistency, Availability, Partition Tolerance}) zwana również teorią Brewera od nazwiska jej autora została po raz pierwszy zaprezentowana podczas prezentacji profesora Uniwersytetu Berkley Eryka Brewera 19 czerwca 2000r. na konferencji \emph{ACM Symposium on the Principles of Distributed Computing} \cite{podc-keynote}. 
W około dwa lata później, w 2002 roku, teoria ta (pod nazwą \emph{Brewer's Conjecture} - Domysł Brewera) została formalnie udowodniona przez Nancy Lynch oraz Setha Gilberta z MIT \cite{brewers-conjecture}.

Teoria CAP powstała jako efekt doświadczeń Brewera w firmie Inktomi oraz jego prac badawczych nad systemami rozproszonymi na Uniwersytecie w Berkley. 
Mówi ona, że z trzech pożądanych właściwości systemu rozproszonego: Konsystencji (ang. \emph{Consistency}), Wysokiej Dostępności (ang. \emph{Availability}) oraz Odporności na Podział Sieci (ang. \emph{Partition Tolerance}) możliwe jest zapewnienie co najwyżej dwóch z nich \cite{browne-cap-theorem}.

\subsection*{Konsystencja}

Rozproszony system bazodanowy jest konsystentny jeżeli zachowuje się tak samo, jakby każda operacja była wykonywana po kolei na pojedynczym węźle.
W praktyce oznacza to, że jeżeli operacja zapisu się powiedzie, to dla każdego klienta systemu jest widoczna natychmiast po zakończeniu.
Dla przykładu system bazodanowy MySQL udostępnia możliwość replikacji synchronicznej i asynchronicznej.
Jedynie jeżeli jest włączona replikacja synchroniczna system nazwiemy konsystentnym, w przeciwnym razie bowiem klient po dokonaniu modyfikacji i odczytując następnie wartość z innego węzła może otrzymać wartość sprzed modyfikacji.
 
\subsection*{Wysoka Dostępność}

Wysoka dostępność jest najbardziej pożądaną właściwością z trzech wymienionych.
Oznacza ona, jak sama nazwa wskazuje, że system powinien udostępniać swoje usługi w pełni przez cały czas, wliczając w to awarie poszczególnych węzłów, aktualizacje oprogramowania czy awarie sieci. 
Bardziej formalnie: jeżeli operacja dotrze do nie ulegającego właśnie awarii węzła, to w pewnym skończonym czasie zwróci wynik do klienta.
Warto przy tym zwrócić uwagę (za \cite{brewers-conjecture}), że dostępność zawodzi najczęściej właśnie wtedy, gdy jest najbardziej potrzebna, czyli w okresach największego obciążenia systemu.

\subsection*{Odporność na Podział Sieci}

W systemach rozproszonych, działających na tysiącach węzłów, często rozsianych w centrach obliczeniowych na wielu kontynentach utrata połączenia pomiędzy grupami węzłów jest oczekiwanym, codziennym problemem.
Podział sieci, rozumiany tu właśnie jako utrata połączenia między dowolnymi dwoma lub więcej węzłami systemu, przy zachowaniu połączenia tych węzłów z klientem, może nastąpić z wielu powodów: awarie switchy lub routerów, utrata połączenia między centrami obliczeniowymi, dokonywane naprawy.
W przypadku kiedy węzeł lub ich grupa zostanie całkowicie odcięty od klientów i innych węzłów systemu, możemy traktować te węzły tak samo jak gdyby na przykład odcięto im nagle zasilanie, dlatego definicja podziału takiego przypadku nie obejmuje.

Dla przykładu wyobraźmy sobie bazę danych replikowaną w systemie master-master.
Jeżeli połączenie między węzłami zostanie zerwane, modyfikacje dokonane na jednym z nich nie będą widoczne na drugim. 
Z kolei w sytuacji gdy mamy bazę danych z horyzontalnym podziałem danych (ang. \emph{sharded}), ponieważ każdy z serwerów zawiera informacje dotyczące tylko części danych i z góry wiadomo do którego z nich należy się zwrócić aby otrzymać informacje dotyczące dowolnego klucza, nawet w przypadku utraty połączenia między nimi, o ile klient ma dostęp do obu serwerów, ciągłość dostarczanych usług jest zapewniona.

\subsection*{Znaczenie Teorii}

Teoria CAP nabiera znaczenia w miarę wzrostu wielkości systemu. 
Gdy dysponujemy bazą rozsianą na kilku maszynach, narzut czasowy replikacji danych pomiędzy nimi jest akceptowalny dla większości zastosowań, nie musimy się też zbytnio martwić o podział sieci, gdyż zazwyczaj jest tak, że maszyny zlokalizowane w jednej szafie (ang. \emph{rack}) będą albo działać wszystkie, albo żadna. 
Kiedy jednak zajmujemy się usługami rozproszonymi na tysiącach węzłów, nawet gdybyśmy dysponowali 10000 maszynami o niezawodności MTBF 30 lat, każdego dnia następowałaby awaria którejś z nich \cite{google-lessons}. 
W przypadku tak dużych systemów, czas jakiego wymaga replikacja danych aby doprowadzić aby każdy węzeł widział ten sam stan, czy to jak system reaguje na podziały sieci nabiera o wiele większego znaczenia.

\subsubsection*{Podział systemów}

Teoria CAP mówi, że nie możemy zapewnić równocześnie wszystkich trzech gwarancji, dlatego skalowalne systemy muszą porzucić jedną z nich. 
Ze względu na to dzielimy je na:

\begin{description}
 \item[CA] (Consistent, Available) te systemy mają problemy z podziałem sieci, wymagając zazwyczaj aby operacje dotyczące poszczególnych transakcji trafiały do pojedynczej grupy węzłów, które podlegają awarii ,,atomowo'' - albo wszystkie działają, albo żaden. 
 \item[AP] (Available, Partition-Tolerant) te systemy zapewniają największą odporność na awarie wynikające z rozproszonego środowiska, jednocześnie jednak stawiając twórców aplikacji przed trudnym zadaniem radzenia sobie z problemami wynikającymi z niespójności danych widzianych przez klientów bazy.
 \item[CP] (Consistent, Partition-Tolerant) te systemy w wypadku podziału oczekują na przywrócenie połączenia, ograniczając w ten sposób dostępność.
\end{description}

W praktyce wysoce skalowalne systemy omawiane w tej pracy zazwyczaj zadowalają się częściowym zapewnieniem wszystkich wymienionych gwarancji, przy czym odporność na podział sieci odgrywa główną rolę, a poświęcana w obliczu wystąpienia podziału sieci jest albo dostępność, albo konsystencja. 
Dlatego systemy te należą albo do grupy CP (Google BigTable, HBase), albo do grupy AP (Amazon Dynamo, Riak).
Z drugiej strony, jeżeli system jest tworzony z przeznaczeniem bycia rozproszonym na zaledwie kilka węzłów, to prawdopodobieństwo podziału sieci jest znikome, zatem całkiem akceptowalne jest rozwiązanie, w którym system w takim przypadku staje się całkowicie niedostępny.
Systemy takie najczęściej klasyfikujemy jako CA, ponieważ powinny być one odporne na awarie pojedynczych węzłów bez utraty dostępności, a równocześnie przy małej skali systemu prostsze jest zapewnienie konsystencji.

\section{BASE}

\subsection*{Wprowadzenie}

BASE to wzorzec, który w przypadku rozproszonych systemów bazodanowych pozwala na zastąpienie skomplikowanego i obniżającego dostępność systemu mechanizmu koordynacji transakcji kolejką zadań do wykonania w tle, co odbywa się kosztem konsystencji.
Artykuł \cite{base-an-acid-alternative} jest krótki, prosty do zrozumienia i okraszony licznymi przykładami prowadzącymi czytelnika od rozwiązania używającego 2PC \footnote{2 Phase Commit - patrz poniżej} do rozwiązania opartego na BASE drobnymi krokami.
Wzorzec ten jest bardzo uniwersalny, dlatego warto się z nim dokładniej zapoznać.

\subsection*{Opis}

BASE (\emph{Basically Available, Soft state, Eventual consistency}) to model konsystencji, który jest przeciwstawiany modelowi ACID (\emph{Atomicity, Consistency, Isolation, Durability}). 
Oba te modele dotyczą baz danych, zatem oba wymagają aby operacje klienta były trwałe (\emph{Durability}).
Różnica między nimi bierze się z podejścia do konsystencji.
W ACID system zawsze musi być w spójnym stanie, a dokonanie zmiany może wymagać szeregu operacji które doprowadzą system do tego stanu.
Operacje te ponadto zostają objęte transakcją i zostają aplikowane albo wszystkie, albo żadna.
W BASE system może być w stanie niespójnym z punktu widzenia aplikacji, a operacje które mają przywrócić tą spójność są wykonywane asynchronicznie.

\label{sec:2-phase-commit}
Producenci relacyjnych baz danych od dawna już byli świadomi potrzeby partycjonowania danych na wiele węzłów.
Aby zapewnić semantykę ACID w kontekście rozproszonych transakcji stosuje się technikę 2PC (ang. \emph{2 Phase Commit}).
Protokół 2PC działa dwustopniowo:

\begin{enumerate}
 \item Najpierw koordynator transakcji żąda od wszystkich węzłów biorących udział w operacji aby wstępnie dokonały operacji commit dla transakcji i potwierdziły możliwość wykonania tej operacji.
 Jeżeli wszystkie węzły dokonały tego potwierdzenia, przechodzi się do drugiego kroku.
 \item W drugim kroku koordynator żąda od wszystkich zainteresowanych węzłów dokonania operacji commit.
 Jeżeli którakolwiek z baz zawetuje tą operację, wszystkie muszą wycofać transakcję.
\end{enumerate}

Problem, na jaki napotykamy w tym podejściu, to ograniczenie dostępności systemu (A w CAP).
Wystarczy aby jeden z węzłów systemu podległ awarii, aby cały system stał się niedostępny dla zapisów.
Dostępność w kontekście transakcji staje się iloczynem dostępności poszczególnych węzłów systemu.
Jeżeli mamy zatem węzły o indywidualnej dostępności 99.9\% to transakcja, która obejmuje trzy z nich będzie miała dostępność ok. 99.7\% - czyli o ok. 90 minut mniejszy \emph{uptime} w skali miesiąca \cite{base-an-acid-alternative}.

W BASE natomiast system stosuje kolejkę zadań, które mają za zadanie przywrócić mu spójność.
Ponieważ zadania te są wykonywane z pewnym opóźnieniem do operacji, która je zainicjowała, to system implementujący wzorzec BASE oferuje niższy poziom konsystencji (konkretnie Eventual Consistency, patrz niżej), ale za to zyskuje na dostępności.

Operacje przywracające spójność systemu, aby zapewnić jak największą odporność na awarie i błędy, powinny być idempotentne.
Operacją idempotentną nazywamy operację, która może być bezpiecznie powtórzona, na przykład operacja dodająca do salda użytkownika 100 złotych nie jest idempotentna ponieważ w wypadku powtórzenia przyzna użytkownikowi więcej pieniędzy niż powinien otrzymać, natomiast operacja sumująca środki wpływające i wypływające z konta użytkownika może być bezpiecznie powtórzona co czyni ją idempotentną.
Zapewnienie tej właściwości sprawi, że system obsługujący kolejkę zadań nie będzie musiał wykonywać ich po kolei (na przykład w sytuacji kiedy zadania są wykonywane równolegle przez wiele procesów), a wypadku awarii będzie mógł je bezpiecznie powtórzyć nie ryzykując w ten sposób wprowadzenia niespójności do systemu.

\section{Eventual Consistency}

\subsection*{Wprowadzenie}

Eventual Consistency to kolejny wzorzec mający duże znaczenie dla systemów rozproszonych.
W dalszej części tej pracy Eventual Consistency występuje najczęściej w połączeniu z replikacją, ale jak już czytelnik miał okazję zobaczyć przy okazji BASE, wzorzec ten może dotyczyć także innych aspektów działania aplikacji.

Eventual Consistency w praktyce występuje w dwóch najczęstszych przypadkach: w systemach AP zaprojektowanych z myślą o skalowalności, albo w systemach (nawet jednowęzłowych) które korzystają z więcej niż jednego źródła danych równocześnie lub stosują asynchroniczną replikację.
W pierwszym przypadku mamy najczęściej możliwość konfiguracji systemu aby zapewnić mu takie właściwości jakie chcemy (włącznie z silną konsystencją), w drugim najczęściej problem niespójności występuje, ale bez możliwości wpłynięcia na właściwości systemu.

\subsection*{Opis}

Eventual Consistency (w wolnym tłumaczeniu: konsystencja po pewnym czasie, ostatecznie) to słaba forma gwarancji konsystencji, która gwarantuje jedynie, że po pewnym, możliwym do przewidzenia czasie od momentu wykonania operacji, jej efekty będą widziane przez klientów systemu, niezależnie od tego, do którego z węzłów systemu się zwrócą z zapytaniem.
Okno czasowe między operacją a propagacją jej efektów do wszystkich zainteresowanych węzłów w systemie nazywamy oknem niespójności (ang. \emph{inconsistency window}).

Choć początkowo może się wydawać, że tego typu model sprawia duże trudności w implementacji aplikacji korzystających z baz danych, które go zapewniają, w rzeczywistości tego typu interakcje napotykamy każdego dnia.
Kiedy w systemie bankowym dokonujemy przelewu z konta na konto, pieniądze znikają z bilansu jednego z nich, ale na drugim pojawiają się z pewnym opóźnieniem.
Innym przykładem może być system DNS, gdzie zmiana jest propagowana w systemie stopniowo, często oczekując na przeterminowanie cache, ale po jakimś czasie jest zauważalna u każdego klienta.

Artykuł \cite{vogels-eventually-consistent} wprowadza ponadto kilka rodzajów Eventual Consistency:

\begin{description}
 \item[Causal Consistency] 
 Jeżeli proces A wykonał jakąś operację, a następnie zakomunikował ten fakt procesowi B, to proces B będzie widział zmienione dane w taki sam sposób jak proces A, a jego zapisy nie będą wchodzić w konflikt z tą operacją.
 Proces C, któremu ta informacja nie została przekazana, będzie podlegał normalnym regułom.
 \item[Read-your-writes Consistency]
 Proces dokonujący operacji w kolejnych operacjach zawsze widzi rezultaty tej operacji.
 \item[Session Consistency]
 To praktyczna realizacja poprzedniego rodzaju konsystencji.
 W tym przypadku proces komunikuje się z systemem w kontekście sesji, w ramach której ma zapewnioną gwarancję odczytu swoich operacji.
 W przypadku awarii i konieczności nawiązania nowej sesji, gwarancje te nie przechodzą na nowo nawiązaną sesję.
 \item[Monotonic Write Consistency]
 W tym przypadku system gwarantuje, że operacje zostaną wykonane w tej samej kolejności, w jakiej żądania ich wykonania zostały wysłane.
 Systemy, które nie oferują tej gwarancji są bardzo trudne w użyciu.
\end{description}

\subsection*{Konfiguracja Eventual Consistency}

Werner Vogels w artykule o Eventual Consistency \cite{vogels-eventually-consistent} wprowadził nomenklaturę stosowaną w konfiguracji konsystencji wielu systemów NoSQL (np. Cassandra, Riak).
Konfigurację tą opisują zazwyczaj trzy liczby:

\begin{description}
 \item[N] liczba węzłów systemu na które zostanie zreplikowany pojedynczy rekord.
 Liczba ta jest zazwyczaj określana jako parametr konfiguracji systemu, lub podczas wydawania polecenia utworzenia ``tabeli'' (nazwanego zbioru rekordów).
 Niektóre systemy pozwalają na zmianę tej wartości w trakcie działania systemu (np. Riak), ale większość wymaga ponownego uruchomienia aplikacji w celu zastosowania tej zmiany.
 \item[R] liczba węzłów systemu, które muszą dokonać odczytu zanim wartość zostanie zwrócona do klienta.
 Czasem wartości zwrócone przez poszczególne węzły będą różne.
 Wtedy system  odpowiada albo za rozwiązanie konfliktu, albo za przekazanie wielu wersji klientowi.
 Parametr R jest najczęściej określany z osobna dla każdego polecenia odczytu.
 \item[W] liczba węzłów systemu, które muszą potwierdzić zapis aby operacja została zakończyła się sukcesem.
 Podobnie jak R jest to parametr przekazywany dla każdego zapytania.
\end{description}

Jeżeli $R+W>N$, to mamy do czynienia z silną konsystencją (ang. \emph{Strong Consistency}) - każdy odczyt zwróci ostatnią zapisaną wartość.
Jeżeli $W = 0$, to zapis jest dokonywany w pełni asynchronicznie.

\subsection*{Znaczenie}

Eventual Consistency opisuje problem dotykający każdej rozproszonej bazy danych, niezależnie od tego czy jest to baza relacyjna, sieciowy system plików czy baza NoSQL.
Tradycyjne podejście do konsystencji w kontekście replikacji jest ograniczające.
Systemy bazodanowe najczęściej implementują rozwiązanie typu wszystko-albo-nic: operacja zapisu musi się powieść na wszystkich węzłach albo zostać cofnięta.
Podejście takie nie tylko ogranicza dostępność systemu, powoduje ono także ograniczenie możliwości decyzyjnych autorów aplikacji korzystających z tych systemów.
Nawet jeżeli system umożliwia asynchroniczną replikację, zazwyczaj jest to bardzo prymitywny mechanizm, który nie bierze pod uwagę wersjonowania rekordów i sprowadza bazę do konfiguracji R=1, W=1.

Z drugiej strony systemy takie jak Amazon Dynamo pozwalają swoim użytkownikom na pełną dowolność w konfiguracji mechanizmów persystencji.
Nawet przy $R+W>N$ mamy możliwość sterowania zachowaniem systemu: czy zapisy powinny być szybsze kosztem odczytów, czy na odwrót, czy też może gdzieś pomiędzy.
Wiele z tych systemów zapewnia \emph{Read-your-writes Consistency} co stanowi dodatkowe ułatwienie.
Możliwość konfiguracji parametrów R, W i N stopniowo staje się standardem wśród systemów NoSQL obsługujących partycjonowanie danych.

\section{Google MapReduce}
\label{sec:google-map-reduce}

\subsection*{Wprowadzenie}

Google MapReduce to narzędzie pozwalające na przetwarzanie ogromnych zbiorów danych równolegle na wielu węzłach.
Bezpośrednim odpowiednikiem MapReduce jest dostępny na licencji Open Source projekt Apache Hadoop, który jest stosowany przez takich internetowych gigantów jak Yahoo i Facebook.
Jednak znaczenie MapReduce jest o wiele większe niż zainspirowanie tego projektu.
Map-Reduce jest aktualnie de-facto standardem wykonywania skomplikowanych zapytań w systemach, które poza tym udostępniają jedynie bardzo uproszczony interfejs, tak jak bazy klucz-wartość, a nawet w systemach o rozbudowanych językach zapytań jak MongoDB. 
MapReduce jest stosowane w przypadku zapytań, które w SQL wymagałyby użycia klauzuli GROUP BY.
Najdalej posuwa się w zastosowaniu MapReduce CouchDB, gdzie wzorzec ten jest wykorzystywany do zapytań w trybie on-line, co możliwe jest dzięki temu, że wyniki operacji map są zapisywane dla każdego dokumentu i przeliczane przy każdej jego zmianie. 

\subsection*{Opis}

Google MapReduce \cite{google-mapreduce} jest biblioteką wykorzystywaną do przetwarzania dużych zbiorów danych w środowisku rozproszonym.
Użytkownik biblioteki specyfikuje dwie funkcje nazywane \emph{map} i \emph{reduce} oraz kilka innych parametrów konfiguracyjnych.
Zadaniem biblioteki jest przetworzenie pliku wejściowego, w którym są zapisane rekordy, w taki sposób, aby dla każdego rekordu w tym pliku została wywołana funkcja \emph{map}, a na wynikach tej funkcji została wywołana funkcja \emph{reduce}.

Operacje \emph{map} i \emph{reduce} są powszechnie spotykane w językach funkcyjnych, takich jak na przykład LISP.
\emph{Map} na wejściu otrzymuje parę klucz-wartość, gdzie kluczem jest identyfikator rekordu, a wartością sam rekord z pliku wejściowego.
Funkcja \emph{map} może zwrócić dowolnie wiele par klucz-wartość.
Klucze zwracane przez funkcje \emph{map} są nazywane \emph{kluczami pośrednimi} i nie muszą być w żaden sposób związane z identyfikatorami rekordów.
Funkcji \emph{reduce} jest przekazywany klucz pośredni, oraz lista wszystkich wartości zwróconych dla tego klucza przez funkcję \emph{map} dla różnych rekordów.
Wynikiem działania funkcji \emph{reduce} jest para klucz-wartość, gdzie kluczem jest klucz pośredni przekazany jako argument funkcji\footnote{W większości implementacji frameworka MapReduce, funkcja \emph{reduce} może być wywołana na wynikach swojego działania, dlatego zazwyczaj funkcja ta zwraca dane w takim samym formacie w jakim je przyjmuje.}.

\subsection*{Przykład}

Poniżej przedstawiam przykładowy kod funkcji \emph{map} i \emph{reduce} w języku Python dla problemu zliczania wystąpień słów w zbiorze tekstów. 
Jak widzimy funkcja \emph{map} przyjmuje pary (klucz, wartość) z przestrzeni (Nazwy Dokumentów, Treść Dokumentów), zwracając pary z innej przestrzeni (Słowa, Liczby Naturalne).
Funkcja \emph{reduce} w przykładzie przyjmuje słowo oraz listę liczb naturalnych określającą liczby wystąpień tego słowa w różnych dokumentach (albo wielokrotnie w tym samym dokumencie).

\begin{verbatim}
def map(document_name, document_value):
  """ funkcja mapujaca dokumenty na pary (slowo, 1)  """
  for word in words(document_value):
    yield (word, 1) # emit word

def reduce(word, counts):
  """ 
  funkcja redukujaca, przyjmuje slowo 
  i liste (iterator) po liczbie jego wystapien
  zwrace sumaryczna liczbe wystapien danego slowa
  """
  sum = 0
  for value in counts:
    sum += value
    # sum += 1
    # tak tez mozna byloby zapisac, 
    # ale wtedy funkcja nie bylaby laczna     
  return sum 
\end{verbatim}


\subsection*{Opis działania}

Użytkownik tworzy aplikację, w której specyfikuje dwie funkcje \emph{map} i \emph{reduce}, oraz dwa parametry konfiguracyjne: \emph{M} i \emph{R}:

\begin{itemize}
 \item \emph{M} - określa na ile części ma zostać podzielony plik wejściowy.
 Zazwyczaj wybiera się taką liczbę aby wielkość plików wejściowych zawierała się między 16MB a 64MB.
 Ponieważ GFS dzieli pliki na kawałki (ang. \emph{chunks}) wielkości 64MB, jest dość istotne aby pliki wejściowe nie przekraczały tej wielkości, gdyż w przeciwnym przypadku mogłaby występować konieczność komunikacji sieciowej w celu odczytania danych z pliku wejściowego.
 \emph{M} określa ponadto liczbę zadań \emph{map}.
 \item \emph{R} - określa liczbę zadań \emph{reduce}.
\end{itemize}

\myfigure{chapters/studium_literatury/map-reduce.png}{Google MapReduce}{fig:map-reduce}

\begin{enumerate}
 \item Biblioteka MapReduce dzieli plik wejściowy na \emph{M} części.
 \item Program użytkownika zostaje wysłany i uruchomiony na maszynach klastra.
 Jedna z tych maszyn przyjmuje specjalną rolę \emph{master}, pozostałe zaś mają rolę \emph{worker}.
 \item \emph{master} przypisuje poszczególnym \emph{workerom} po jednym zadaniu do wykonania.
 Kolejne są przydzielane w miarę jak węzły kończą przydzieloną im pracę.
 Zadanie \emph{map} zostanie przydzielone w pierwszej kolejności maszynie która jest równocześnie \emph{chunkserverem} przechowującym odpowiedni plik wejściowy.
 Pozwala to uniknąć komunikacji sieciowej w celu odczytania pliku.
 \item \emph{Worker} przetwarza plik wejściowy rekord po rekordzie wywołując funkcję \emph{map} i zapisując jej wynik w pamięci.
 \item Co pewien czas dane zapisane w pamięci są zrzucane na dysk do plików lokalnych.
 W tym procesie dane są rozdzielane do \emph{R} plików poprzez funkcję partycjonującą, domyślnie $hash(key) mod R$.
 Lokacje tych plików są przekazywane do węzła \emph{master}, który z kolei jest odpowiedzialny za przekazanie ich do węzła wykonującego operację \emph{reduce} na odpowiednim fragmencie danych.
 \item Węzeł wykonujący operację \emph{reduce} po otrzymaniu takiego powiadomienia pobiera odpowiednie pliki bezpośrednio od węzła, który je przechowuje.
 Po otrzymaniu wszystkich potrzebnych plików, \emph{worker} sortuje otrzymane dane po kluczu, tak aby wartości dla danego klucza sąsiadowały ze sobą w pliku.
 \item Po posortowaniu plików wejściowych węzeł przechodzi kolejno po kluczach i dla każdego z nich przekazuje klucz oraz listę wszystkich przypisanych mu wartości do funkcji \emph{reduce}, zapisując następnie jej wynik w pliku wyjściowym.
 \item Kiedy wszystkie operacje \emph{reduce} zakończą się, \emph{master} budzi program użytkownika i wywołanie funkcji \emph{MapReduce} kończy się.
\end{enumerate}

Wynikiem operacji jest \emph{R} plików wynikowych.
W większości przypadków konsumentem tych danych są inne operacje MapReduce, bądź aplikacje rozproszone, więc nie ma potrzeby łączenia tych plików w jedną całość.

\subsection*{Optymalizacje}

W artykule \cite{google-mapreduce} zostało opisanych kilka istotnych optymalizacji i ulepszeń:

\begin{enumerate}
 \item Operacja \emph{map} na pliku wejściowym jest wykonywana na tym samym serwerze, który przechowuje ten plik.
 \item Operacja \emph{map} może zwrócić bardzo wiele wartości dla danego klucza pośredniego.
 Z tego względu biblioteka wprowadza pojęcie funkcji łączącej (ang. \emph{combiner}).
 Funkcja ta dokonuje wstępnej redukcji przed wysłaniem wartości przez sieć do węzła wykonującego operację \emph{reduce}.
 Najczęściej stosuje się w tym miejscu tą samą funkcję co w operacji \emph{reduce}, ale aby to było możliwe, funkcja ta musi być łączna i przemienna, co czasem wymaga wprowadzenia pewnych zmian.
 Dla przykładu: przedstawiona wcześniej funkcja map zwracająca wszystkie słowa w danym dokumencie, zwraca powtarzające się słowa wielokrotnie.
 Poprzez zsumowanie wystąpień przed przesłaniem znacznie zmniejszamy ilość danych do wysłania.
 \item Funkcja partycjonująca może być wyspecyfikowana przez użytkownika, dzięki czemu potencjalnie możliwe jest takie jej określenie, aby dane powiązane ze sobą znalazły się w jednym pliku wynikowym (aczkolwiek kosztem ryzyka nierównomiernego podziału kluczy między partycje).
 \item Dzięki sortowaniu kluczy pośrednich, pliki wynikowe są łatwiejsze do przetwarzania, umożliwiając na przykład wyszukiwanie binarne.
 \item Kiedy zbliża się koniec operacji, zadania \emph{reduce} są zlecane do wykonania przez dodatkowe węzły.
 Dzięki temu uszkodzone, nadmiernie obciążone przez inne procesy albo wadliwie skonfigurowane maszyny nie powodują nadmiernego wydłużenia całości operacji MapReduce.
\end{enumerate}

\subsection*{Odporność na awarie}

Ponieważ biblioteka MapReduce służy do wykonywania operacji w rozproszonym środowisku, często nawet na tysiącach węzłów, konieczne jest aby była ona odporna na awarie części z węzłów.
Rozróżniamy dwa typy awarii: awaria węzła \emph{master} i awarie węzłów typu \emph{worker}.

\subsubsection*{Awaria węzła master}

Ponieważ \emph{master} przechowuje między innymi informacje o zrealizowanych zadaniach i lokalizacji plików wynikowych, \emph{Master} musi działać aby operacja MapReduce się zakończyła powodzeniem.
Możliwe jest aby jego struktury danych były zapisywane w GFS, albo replikowane do zapasowego węzła.
W opisanym systemie awaria węzła master zawsze kończy się niepowodzeniem całości operacji MapReduce i koniecznością jej ponownego uruchomienia.
Jest to dopuszczalne ponieważ czas trwania operacji jest liczony w minutach, więc awaria tego konkretnego węzła jest mało prawdopodobna (w odróżnieniu od np. BigTable, który jest systemem, który działa bez przerwy).

\subsubsection*{Awaria węzła slave}

\emph{Master} regularnie komunikuje się z węzłami \emph{slave} w celu ustalenia ich stanu.
W przypadku gdy węzeł przestaje odpowiadać jest uznawany za ,,martwy'', w związku z czym \emph{master} oznacza zadanie aktualnie przez niego wykonywane jako przeznaczone do przydziału, tak samo wszystkie wykonane przez niego zadania \emph{map}.
Zadania \emph{map} muszą być wykonane ponownie, ponieważ ich wyniki zostały zapisane w lokalnych plikach i przez to są niedostępne do odczytu.
Zadania \emph{reduce} zapisują swoje wyniki w GFS, w związku z tym nie muszą być powtarzane. 

\subsection*{Znaczenie}

Większość systemów opisanych w niniejszej pracy nie dysponuje zaawansowanymi metodami wykonywania zapytań, a w szczególności zapytań agregujących czy zliczających takich jak funkcje COUNT, SUM, AVG i operator GROUP BY w relacyjnych bazach danych.
Operacje tego typu są szczególnie trudne w kontekście systemów rozproszonych, gdzie wykonanie zapytań tego typu w trybie on-line przy zachowaniu odpowiedniego czasu odpowiedzi jest często wręcz niemożliwe.
Dlatego najczęściej wykonywanie tego typu operacji jest dokonywane co pewien czas, lub zlecane przy zapisie danych, a jego wyniki są przechowywane w systemie.

W przeważającej większości obliczenia te są wykonywane przy zastosowaniu algorytmu MapReduce.
Wiele systemów, tak jak MongoDB czy Riak, zapewnia taką funkcjonalność, inne wymagają zastosowania zewnętrznych narzędzi.
Wierną implementacją Google MapReduce jest Hadoop, który opisany zostanie nieco bliżej przy okazji HBase.
Bardzo ciekawe podejście do MapReduce prezentuje CouchDB, która przechowuje wyniki funkcji map, dzięki czemu umożliwia dokonywanie zapytań opartych o MapReduce w trybie on-line.
CouchDB zostanie opisane bliżej w kolejnym rozdziale.

Algorytm MapReduce ma duże znaczenie w systemach NoSQL, gdyż stanowi surogat dla wykonywania skomplikowanych zapytań.
Stanowi on jedno z podstawowych narzędzi dla praktyki prostych odczytów, ale złożonych zapisów.

\section{Amazon Dynamo}

\subsection*{Wprowadzenie}

W tej części opisany został jeden z systemów, które wpłynęły znacząco na architekturę dostępnych publicznie systemów NoSQL.
Amazon Dynamo jest systemem stworzonym przez firmę Amazon i cechuje się tym, że został zaprojektowany z myślą o wysokiej dostępności.
System ten, mimo że jako baza typu klucz-wartość jest bardzo prosty z punktu widzenia użytkownika, opiera się wewnętrznie na zastosowaniu wielu ciekawych technik, którym poświęcono więcej uwagi w dalszej części rozdziału.
Wybór dostępności ponad konsystencję wiąże się z istotnymi konsekwencjami.
Najbardziej widoczną z nich jest skomplikowany system wersjonowania rekordów, który wprawdzie umożliwia systemowi zachowanie dostępności w przypadku podziału sieci lub awarii grup węzłów, ale także sprawia, że system jest znaczniej bardziej skomplikowany w użyciu.
Z drugiej strony system ten oferuje znakomite możliwości konfiguracji i kontroli nad replikacją, co umożliwia dopasowanie go na potrzeby wielu różnych aplikacji.

\subsection*{Opis}

Amazon Dynamo to baza typu klucz-wartość używana w największym na świecie sklepie internetowym \emph{amazon.com}.
Baza została opisana w artykule z 2007 roku \cite{amazon-dynamo} i od tego czasu opisany w nim system doczekał się już dwóch implementacji open-source: Dynomite i Riak, oraz stał się inspiracją dla innych baz takich jak Cassandra, czy rozszerzenia CouchDB pozwalającego na rozpraszanie tej bazy.

Amazon Dynamo skaluje się bardzo dobrze - do setek węzłów, co dzięki zastosowaniu architektury opartej na usługach w zupełności wystarcza nawet takiemu gigantowi jak Amazon.
Interesującym aspektem architektury tego sklepu internetowego jest to, że poszczególne usługi muszą oferować gwarancje na czas wykonania (ang. \emph{Service Level Agreements}).
Przykładowym kontraktem tego typu jest gwarancja, że usługa zwróci odpowiedź w ciągu 300ms dla 99,9\% zapytań przy obciążeniu 500 zapytań na sekundę.
Konsekwencją istnienia takich gwarancji jest to, że Dynamo musi udostępniać wiele możliwości konfiguracji, tak aby usługi mogły dostosować właściwości bazy na potrzeby oferowanego kontraktu.

Jednym z wymagań dla systemu obsługującego sklep internetowy jest to aby użytkownik był w stanie zawsze dodać przedmioty do koszyka czy złożyć zamówienie.
W związku z tym Amazon Dynamo jest systemem, w którym dostępność (A w CAP) odgrywa kluczową rolę, a odporność na podział sieci (P w CAP) jest jej uzupełnieniem.
Wydawało by się, że konsystencja ma duże znaczenie w przypadku sklepu internetowego - nie można przecież sprzedać towaru, którego się nie ma, a przecież w przypadku sklepu z którego korzystają miliony użytkowników równocześnie warunki wyścigu (ang. \emph{race conditions}) muszą występować nagminnie.
W amazon.com dopuszczalne jest aby dwóch klientów zamówiło ostatnią z książek w magazynie, a kiedy okaże się że jeden z nich jej nie może otrzymać sklep kontaktuje się z nim proponując na przykład dłuższy okres dostawy.
Nawet jeżeli nie wszyscy użytkownicy się zgodzą z taką sytuacją, to i tak przekłada się to na wyższe przychody.
Pokazuje to jak Eventual Consistency może z powodzeniem być stosowane w sytuacjach, gdzie normalnie kładzie się duży nacisk na spójność danych, nie powodując przy tym ujmy dla systemu.

\subsection*{Główne założenia architektury}

Autorzy Amazon Dynamo określili takie założenia co do architektury:

\begin{itemize}
 \item system jest zawsze w stanie przyjąć operację zapisu, aby użytkownik zawsze mógł dodać towary do koszyka,
 \item w związku z replikacją danych i naciskiem na wysoką dostępność, w systemie może wystąpić wiele wersji rekordu (koszyka),
 \item rozwiązywanie konfliktów między wersjami następuje przy odczycie i jest dokonywane przez aplikację, nie przez bazę (ale aplikacja może z tego zrezygnować i wybrać prosty mechanizm, np. ostatni zapis wygrywa), w ten sposób w wypadku połączenia dwóch wersji koszyka, co najwyżej ponownie pojawią się w nim usunięte przez użytkownika towary, ale nic nie zostanie utracone,
 \item system musi się łatwo skalować wszerz poprzez dodawanie kolejnych węzłów i nie powinno to mieć dużego wpływu ani na administrację systemem ani na sam system,
 \item system musi się charakteryzować symetrią: każdy węzeł ma taki sam zestaw obowiązków jak wszystkie inne,
 \item system musi być zdecentralizowany: żaden węzeł nie jest wyróżniony i wszelkie operacje są wykonywane korzystając z mechanizmów \emph{peer-to-peer},
 \item system musi radzić sobie z heterogenicznością środowiska: narzut pracy na pojedynczy węzeł powinien uwzględniać jego możliwości w porównaniu do innych węzłów.
\end{itemize}

\subsection*{Stosowane techniki}
\label{sec:dynamo-techniki}

Amazon Dynamo łączy w sobie wiele ciekawych technik rozwiązujących problemy takie jak partycjonowanie, wersjonowanie rekordów czy wykrywanie awarii.
Niniejszy rozdział przybliży je czytelnikowi.

\subsubsection*{Partycjonowanie - Consistent Hashing} 
\label{sec:dynamo-consistent-hashing}

W systemie takim jak Dynamo, który ma za zadanie skalować się do setek węzłów, horyzontalne partycjonowanie jest nieuniknione.
W Amazon Dynamo za podział na partycje odpowiada zmodyfikowany algorytm Consistent Hashing.
Kolejne paragrafy opisują najpierw podstawowy algorytm, a następnie kolejne jego modyfikacje.

Consistent Hashing to algorytm który dla dowolnego klucza określa który węzeł systemu przechowuje dane z nim powiązane.
Ponieważ klucze są dowolnymi ciągami bajtów, zawsze operując na nich używamy funkcji mieszającej (ang. \emph{hashing function}).
Przeciwdziedzina tej funkcji mieszającej jest niejako pierścieniem, gdzie najmniejsza i największa możliwa wartość ,,stykają się'' ze sobą, podobnie jak ma to na przykład miejsce w przypadku długości geograficznych czy godzin na tarczy zegara.
W podstawowej wersji systemu każdy węzeł systemu ma przypisaną jedną losową wartość na tym pierścieniu.
Aby określić któremu węzłowi odpowiada dany klucz, obliczamy dla niego wartość funkcji mieszającej, a następnie znajdujemy węzeł, którego ,,pozycja'' na pierścieniu jest najbliższą zgodnie z ruchem wskazówek zegara po wartości wyliczonej.
W takim schemacie każdemu węzłowi odpowiada jeden, ciągły fragment pierścienia (patrz rysunek \ref{fig:consistent-hashing-01}).

\myfigure{chapters/studium_literatury/consistent-hashing-01.png}{Podstawowe Consistent Hashing}{fig:consistent-hashing-01}

Podstawowy wariant algorytmu ma wiele wad.
Problemem jest na przykład potencjalnie bardzo nierównomierna dystrybucja kluczy między węzłami.
Nie ma też żadnego wsparcia dla heterogeniczności środowiska - nie możemy ,,mocniejszemu'' serwerowi przekazać większego zakresu kluczy.
W związku z tymi ograniczeniami, wprowadza się tak zwane ,,wirtualne węzły'': pojedynczemu fizycznemu węzłowi przypisuje się wiele pozycji na pierścieniu (zazwyczaj liczba tych pozycji jest znacznie większa od ogólnej liczby węzłów).
Dzięki tej modyfikacji (o ile liczba wirtualnych węzłów jest wystarczająco duża) dystrybucja kluczy będzie znacznie bardziej sprawiedliwa, możemy też kontrolować obciążenie poszczególnych węzłów poprzez przyporządkowanie im mniejszej lub większej liczby pozycji na pierścieniu (patrz rysunek \ref{fig:consistent-hashing-02}).

\myfigure{chapters/studium_literatury/consistent-hashing-02.png}{Consistent Hashing z wirtualnymi węzłami}{fig:consistent-hashing-02}

Opisana powyżej wersja algorytmu lepiej radzi sobie z dodawaniem i usuwaniem węzłów niż wersja podstawowa, jednak w rzeczywistości nie sprawdza się zbyt dobrze.
Przy dodaniu węzła do systemu, klucze znajdujące się do tej pory pod opieką innych węzłów muszą być przekazane nowemu węzłowi.
Aby tego dokonać, konieczne jest wykonanie przeglądu wszystkich kluczy w dzielonym zakresie, konieczne jest także przeliczenie na nowo i synchronizacja drzew Merkle (vide \emph{Merkel Trees} na stronie \pageref{merkle-trees}). 
Przegląd taki obciąża system i musi być dokonywany w tle aby nie złamać gwarancji dawanych przez korzystającą z Dynamo usługę.
Aby uniknąć tego problemu należy rozdzielić mechanizm partycjonowania danych (w jaki sposób są tworzone przedziały) od tego, które węzły nimi zarządzają.

W tym wariancie algorytmu przestrzeń kluczy zostaje podzielona z góry na określoną liczbę przedziałów S.
Najczęściej liczba ta będzie znacznie większa niż liczba węzłów systemu N ($S >> N$).
Następnie każdy z przedziałów przydzielamy losowo jednemu z węzłów tak aby każdy miał ich po $S/N$\footnote{oczywiście ten mechanizm może być dostosowany do wymagania heterogeniczności, tak aby jedne węzły otrzymywały więcej przedziałów niż inne}.
Dzięki temu rekordy przynależące do różnych z przedziałów mogą być przechowywane w odrębnych plikach, które z kolei mogą być przesyłane w ramach potrzeby do przejmujących nad przedziałem kontrolę węzłów bez zbędnego przeglądania danych na dysku.
Rysunek \ref{fig:consistent-hashing-03} przedstawia opisaną powyżej wersję algorytmu.

\myfigure{chapters/studium_literatury/consistent-hashing-03.png}{Consistent Hashing z rozdziałem partycjonowania i pozycjonowania rekordów}{fig:consistent-hashing-03}

\subsubsection*{Replikacja}
\label{sec:dynamo-replikacja}

Mechanizm opisany w poprzednim rozdziale przydziela przedziały kluczy do węzłów, które są \emph{koordynatorami} tych przedziałów.
Nazwa ,,koordynator'' może być dość myląca ponieważ węzeł ten niczego w rzeczywistości nie koordynuje, jedyne jego wyróżnienie polega na tym, że jest pierwszym węzłem na liście węzłów przechowujących dane z danego przedziału kluczy.
Oczywiście nie wystarcza aby każdy przedział był zapisany tylko na dysku koordynatora - awaria pojedynczego węzła powodowałaby wtedy (potencjalnie nieodwracalne) straty danych, a przynajmniej ich czasową niedostępność.
W Amazon Dynamo dane są replikowane do N fizycznych węzłów, gdzie N\footnote{
Uważny czytelnik zwróci uwagę na to, że ta sama nomenklatura była wykorzystana w artykule o Eventual Consistency.
W rzeczy samej, autor tego artykułu Werner Vogels (CTO amazon.com) figuruje także na liście autorów artykułu o Amazon Dynamo.
Obie prace są ze sobą blisko związane i dobrze uzupełniają się.
}
jest parametrem określanym w konfiguracji bazy.
Najczęściej stosowaną wartością N jest 3.

Klucze są zapisywane na dysku koordynatora, oraz na dyskach N-1 kolejnych węzłów.
Kolejne węzły to węzły, które są koordynatorami kolejnych w kierunku ruchu wskazówek zegara przedziałów pierścienia.
Ponieważ może zajść sytuacja, że koordynatorem kolejnych przedziałów jest ten sam węzeł, poruszamy się wzdłuż pierścienia aż znajdziemy N różnych węzłów.
Lista węzłów odpowiedzialnych za przechowywanie klucza jest nazywana \emph{listą preferencyjną}.
Lista ta zazwyczaj zawiera więcej niż N adresów, na wypadek awarii jednego lub więcej z N podstawowych węzłów.

\subsubsection*{Wersjonowanie - Zegary Wektorowe}
\label{sec:dynamo-vector-clocks}

Amazon Dynamo jest systemem, w którym dane są replikowane asynchronicznie i który zachowuje dostępność nawet w wypadku podziałów sieci, czy awarii poszczególnych węzłów.
Konsekwencją tego podejścia jest możliwość występowania wielu wersji rekordu równocześnie w systemie, a w przypadku długotrwałych podziałów sieci możliwe jest nawet istnienie równoległych ,,drzew historii'' dla tego rekordu.

Podobnie jak wcześniej i tu widzimy wyraźny wpływ tego, jak wymagania biznesowe wpłynęły na wybór algorytmów i architektury Dynamo.
Jednym z rodzajów danych, które są przechowywane w tym systemie jest koszyk użytkownika.
Ze względów finansowych jest istotne aby użytkownik nie tylko mógł zawsze dodać nowe przedmioty do swojego koszyka, ale także aby informacja o dodaniu tych przedmiotów nigdy nie została utracona.
Gdyby zatem do wersjonowania rekordów w systemie użyto znaczników czasowych, nie byłoby możliwe określenie logicznej kolejności modyfikacji danego rekordu.
Przykładowo użytkownik, który w krótkim odstępie czasu dodałby do koszyka kilka przedmiotów, gdyby zapytania te trafiły do różnych węzłów systemu, mógłby stworzyć kilka konfliktujących ze sobą wersji koszyka.
Wykorzystanie strategii ,,nowszy wygrywa'' do rozwiązywania ewentualnych konfliktów mogłoby grozić utratą zamówień z koszyka, a zatem negatywnymi konsekwencjami finansowymi dla firmy.

Autorzy Amazon Dynamo zdecydowali się na wykorzystanie mechanizmu nazywanego zegarami wektorowymi (ang. \emph{vector clocks}).
Zegar wektorowy jest to zbiór par, gdzie pierwszym elementem pary jest identyfikator węzła\footnote{Riak, opisany w rozdziale \ref{sec:riak}, używa identyfikatorów klientów jako pierwszych elementów pary. Użycie identyfikatorów serwerów wiąże się bowiem z ryzykiem utraty danych. Problem ten jest opisany bliżej w \cite{basho-vector-clocks-hard}.}, a drugim elementem jest liczba naturalna.
Przy każdej modyfikacji rekordu serwer dokonujący tej modyfikacji zwiększa o 1 liczbę przypisaną do swojego identyfikatora w zegarze wektorowym (albo wpisuje swój identyfikator z wartością 1, jeżeli go wcześniej nie było).
Jeżeli wszystkie identyfikatory węzłów dla zegara A mają odpowiadające im wartości mniejsze bądź równe odpowiednim wartościom w zegarze B, to mówimy że A jest przodkiem wektora B i w przypadku napotkania takich dwóch wersji B zastępuje A.
Jeżeli natomiast ani A nie jest przodkiem B ani vice versa, to mówimy, że te dwie wersje rekordu znajdują się w konflikcie, który z kolei musi zostać rozwiązany przez aplikację (klienta).

Zegar wektorowy rekordu o długim czasie życia w systemie może osiągnąć potencjalnie nieograniczoną długość.
Aby temu zapobiec do pary identyfikator węzła-liczba, dodaje się jeszcze trzeci element: znacznik czasu (ang. \emph{timestamp}), który zapisuje kiedy ostatni raz dany węzeł modyfikował wartość rekordu.
Długość zegara można dzięki temu kontrolować poprzez usuwanie najstarszych elementów, kiedy długość zegara przekroczy pewien próg (10 dla Dynamo).
W normalnych warunkach długość zegara nie powinna przekroczyć N (stopnia replikacji), ale awarie węzłów i podziały sieci mogą sprawić, że długość ta będzie większa.
Usuwając część elementów zegara tracimy jednak część zawartych w nim informacji, a to może sprawić, szczególnie w wypadku zaistnienia podziału sieci, że rekord, który w jednej z partycji w ogóle nie został zmodyfikowany, zostanie oznaczony jako pozostający w konflikcie z wersją, która została zmodyfikowana w drugiej partycji, tylko dlatego, że nowy element wektora spowodował usunięcie starego elementu, który pozostał w niezmodyfikowanym zegarze.

Bardzo dobry opis zegarów wektorowych czytelnik może znaleźć w artykułach na blogu firmy Basho, która to firma zajmuje się rozwojem bazy Riak: \cite{basho-vector-clocks-easy} opisuje tą technikę z punktu widzenia klienta, zaś \cite{basho-vector-clocks-hard} opisuje ją z punktu widzenia implementacji serwera.

\subsubsection*{Operacje odczytu i zapisu}

Jako baza typu klucz-wartość, Amazon Dynamo udostępnia użytkownikowi dwie podstawowe operacje: \emph{put} i \emph{get}.
Operacja \emph{get} przyjmuje między innymi parametr R, określający minimalną liczbę węzłów, które muszą dokonać operacji odczytu aby zakończyła się ona sukcesem.
Operacja \emph{put} jako jeden z parametrów przyjmuje z kolei wartość W, określającą ile węzłów musi potwierdzić zapis wartości, aby operacja się powiodła.

Amazon Dynamo używa protokołu HTTP w komunikacji między klientem i serwerem.
Zaletą tego podejścia jest brak konieczności linkowania aplikacji z kodem służącym do komunikacji z Amazon Dynamo, wadą jednak jest to, że klient, który traktuje bazę jako ,,czarną skrzynkę'' jest wolniejszy.
Jeżeli klient nie jest świadomy istnienia list preferencyjnych i informacji w nich zawartych, a zatem nie wie, na którym węźle przechowywane są dane interesującego go klucza, operacja odczytu przebiega następująco: 
\begin{enumerate}
 \item Klient wysyła zapytanie, które jest obsługiwane przez \emph{load balancer}.
 \item \emph{Load balancer} może wybrać węzeł, do którego ma przekazać zapytanie, albo poprzez inspekcję przekazywanego zapytania i wybór węzła na podstawie listy preferencyjnej, albo losowo z pośród wszystkich węzłów systemu.
 \item Jeżeli węzeł, do którego trafiło polecenie zapisu nie znajduje się na jednym z N pierwszych miejsc listy preferencyjnej, przekazuje on zapytanie dalej do pierwszego, nie podlegającego aktualnie awarii węzła na tej liście.
 Nie dzieje się tak w przypadku poleceń odczytu, które mogą być koordynowane przez dowolny węzeł, gdyż nie muszą modyfikować zegarów wektorowych powiązanych z rekordami.
 \item Węzeł ten wykonuje żądaną operację, oraz przekazuje ją do wykonania do N-1 innych węzłów znajdujących się na szczycie listy preferencyjnej.
 \item Kiedy węzeł otrzyma potwierdzenie od $R-1$ bądź $W-1$ z tych węzłów, operacja kończy się powodzeniem.
 Jeżeli w systemie występują wersje rekordu, które znajdują się w konflikcie, wszystkie one zostaną przekazane do klienta.
 Nieaktualne wersje rekordów zostaną wykryte i automatycznie uaktualnione w sposób przeźroczysty dla klienta.
\end{enumerate}

Jak widać w powyższym schemacie, klient znający listy preferencyjne systemu jest w stanie całkowicie pominąć \emph{load balancer} i ewentualne przekazać zapytania do jednego z węzłów na liście preferencyjnej klucza. 
W przypadku gdy Dynamo posługuje się znacznikami czasu do wersjonowania rekordów, klient może przejąć na siebie także obowiązki koordynatora zapytań.
W przypadku wykorzystania zegarów wektorowych nie jest to możliwe, gdyż w zegarze wektorowym w Dynamo jest zapisywany identyfikator węzła systemu, nie klienta (tak jak to ma miejsce w Riak).
Koordynacja zapytań przez klienta zmniejsza opóźnienia (ang. \emph{latency}) w systemie o ponad połowę, zarówno dla wartości średnich, jak i dla 99.9\% zapytań.

\subsubsection*{Obsługa awarii - Hinted Handoff}
\label{sec:dynamo-hinted-handoff}

W poprzednich rozdziałach opisane zostały listy preferencyjne oraz mechanizm koordynacji operacji zapisu i odczytu.
Przypomnijmy, że Amazon Dynamo na liście preferencyjnej zawiera więcej węzłów, niż liczba N podana przez użytkownika, a w razie awarii części węzłów przechowujących dany zakres kluczy, klient będzie kierował swoje zapytania do węzłów znajdujących się dalej na liście preferencyjnej, pomijając te, które uległy awarii.
Informacja o tym, że rekord miał trafić do innego węzła, ale ze względu na jego awarię trafił do węzła aktualnego jest zapisywana w metadanych tego rekordu.
Rekordy takie są przechowywane osobno od reszty rekordów i regularnie jest dokonywane sprawdzenie, czy można już taki rekord przekazać do węzła, na który miał on trafić oryginalnie.
Technikę tę nazywamy \emph{Hinted Handoff}, czyli w wolnym tłumaczeniu przekazywanie z sugestiami.
W Amazon Dynamo operacje dołączenia, czy usunięcia fizycznego węzła są jawne, stąd też przyjmujemy że węzły stają się niedostępne jedynie tymczasowo, a w przypadku permanentnej awarii węzeł powinien zostać jawnie usunięty.

\subsubsection*{Wykrywanie różnic - Merkle Trees}
\label{merkle-trees}

W Amazon Dynamo każdy węzeł jest odpowiedzialny za przechowywanie pewnej liczby zakresów kluczy.
Węzły odpowiedzialne za określony zakres kluczy nazywamy jego replikami.
Repliki mogą zawierać różne wersje rekordów i aby zmniejszyć ryzyko utraty danych należy co jakiś czas dokonywać synchronizacji danych między nimi.
W tym celu stosuje się drzewa Merkle (ang. \emph{Merkle Trees}).
Drzewo takie jako liście posiada sumy kontrolne wartości dla wszystkich kluczy danego przedziału, wszystkie pozostałe węzły drzewa zawierają sumę kontrolną ze swoich dzieci.
Dzięki temu, że dwa drzewa o tej samej wartości w korzeniu są identyczne, możliwe jest porównanie zakresów kluczy przechowywanych przez różne repliki w bardzo efektywny sposób, znacznie ograniczając ilość danych do przesłania.

\subsubsection*{Optymalizacje}

Podobnie jak wiele innych wysokowydajnych baz danych\footnote{MongoDB, Riak, Redis}, w celu zmniejszenia opóźnień w Amazon Dynamo zapisy mogą być przechowywane tymczasowo w pamięci i zrzucane na dysk w tle co jakiś czas.
Aby zapewnić trwałość danych Dynamo dba o to aby przynajmniej jeden węzeł z N zapisywał dane od razu na dysku.
Ponieważ jednak W jest zazwyczaj mniejsze od N, nie zmniejsza to szybkości działania.

Inną wartą uwagi optymalizacją, jest taka konstrukcja list preferencyjnych aby każdy zakres kluczy był przechowywany na węzłach znajdujących się w co najmniej dwóch centrach danych.
Dzięki temu w razie awarii całego centrum danych system jest w stanie zachować dostępność.

\subsection*{Znaczenie}

Amazon Dynamo jest bardzo ciekawym przykładem rozproszonego systemu bazodanowego.
Jest jednym z nielicznych systemów, w których wszystkie węzły są sobie równe.
Jest też warty uwagi ze względu na niezwykle wysokie gwarancje dostępności jakie oferuje i jakie ma to konsekwencje dla konsystencji.
Dynamo doczekało się naśladowców w postaci baz Riak i Dynomite, oraz zainspirowała twórców Apache Cassandra i programistów firmy Cloudant tworzących rozproszoną wersję CouchDB.
Artykuł ,,Dynamo: amazon's highly available key-value store'' \cite{amazon-dynamo} jest ponadto jednym z najciekawszych i najbardziej przystępnych artykułów dotyczących zagadnień związanych ze skalowalnymi bazami danych znanych autorowi tej pracy i warty polecenia wszystkim osobom zainteresowanym ruchem NoSQL.

\section{Google BigTable}

\subsection*{Wprowadzenie}

Opisany w tym rozdziale system jest pierwowzorem dla wszystkich baz typu kolumnowego, a zarazem jest także dobrym przykładem bazy, która w wypadku podziału sieci stawia na konsystencję kosztem dostępności.
Google BigTable nie da się łatwo zanalizować na podstawie artykułu, który ten system przedstawia, ponieważ aby zrozumieć działanie tej bazy należy sięgnąć do źródeł opisujących dwa systemy, na których bardzo mocno się ona opiera: Google Chubby i Google File System (GFS).
Pierwszy z nich umożliwia BigTable wybór węzła master i ułatwia zadania takie jak utrzymywanie listy aktywnych węzłów systemu, drugi zaś zapewnia możliwość trwałego zapisu danych i replikację.

Google BigTable jest wartym uwagi systemem, ponieważ od wielu lat stanowi kluczowy element architektury największej i najpopularniejszej wyszukiwarki internetowej na świecie, a jego wpływy można odnaleźć w wielu różnych systemach NoSQL.

\subsection*{Opis}

Google BigTable to podstawowa baza danych używana przez firmę Google.
Opisana została w artykule z 2006 roku pod tytułem ,,BigTable: A Distributed Storage System for Structured Data'' \cite{google-bigtable}.
Baza ta stała się inspiracją dla systemów takich jak Apache Cassandra, które zawdzięcza BigTable model danych, HBase, które jest dla BigTable tym, czym dla Dynamo jest Riak, czy też MongoDB, które stosuje mechanizm partycjonowania i replikacji podobny do bazy Google.

Google BigTable skaluje się bardzo dobrze: do tysięcy serwerów i petabajtów danych.
Podobnie jak Amazon Dynamo został stworzony z myślą o uruchamianiu go na klastrze maszyn średniej klasy.
Podstawową różnicą między BigTable a Dynamo jest natomiast podejście do konsystencji.
Baza firmy Amazon jest w stanie przyjąć zapis w każdej niemal sytuacji, przypłacając to kosztem tego, że aplikacja musi radzić sobie z wieloma wersjami rekordu, które mogą równocześnie występować w systemie.
BigTable gwarantuje konsystencję (w sensie CAP), ale kosztem opóźnień (wybór węzła \emph{master}, przekazanie roli serwera \emph{tabletów}, replikacja na poziomie GFS) oraz zmniejszonej odporności na podział sieci.

\subsection*{Model Danych}
\label{google-bigtable-model-danych}

Google BigTable jest prekursorem kolumnowych baz danych.
Model danych można opisać jako macierz, gdzie rzędami są rekordy, a kolumny reprezentują pola tych rekordów.
Każdy rząd identyfikowany jest przez klucz o wielkości maksymalnej 64KB, ale przeciętnie klucze są mniejsze niż 100B.
System przechowuje rekordy posortowane po kluczu, podzielone na grupy zwane tabletami.
W miarę dodawania i usuwania rekordów tablety mogą być dzielone i łączone.
Ponieważ rekordy są posortowane po kluczu, każdy tablet zawiera przedział kluczy do którego zdefiniowania wystarcza klucz początkowy i klucz końcowy.
Ułatwia to określenie, który tablet odpowiada za określony klucz, bez konieczności przechowywania bardzo dużych ilości metadanych.

Fakt, że rekordy są przechowywane w postaci uporządkowanej ma zarówno zalety, jak i wady.
Zaletą jest to, że dzięki umiejętnej konstrukcji kluczy, rekordy które są ze sobą powiązane mogą być przechowywane razem, przez co operacje na nich wymagają interakcji z mniejszą liczbą węzłów.
Przykładowo, tabela przechowująca wyniki indeksowania sieci WWW przechowuje adresy URL jako klucze w odwróconej kolejności (np. pl.edu.agh.eaie.www zamiast www.eaie.agh.edu.pl).
W ten sposób operacje na wszystkich podstronach serwisu WWW nie muszą łączyć się z wieloma węzłami aby pobrać potrzebne dane.
Wadą tej właściwości jest to, że nieodpowiednia konstrukcja klucza może sprawić, że kilka tabletów może stać się tak zwanym ,,gorącym'' punktem systemu, czyli większość operacji zapisu bądź odczytu będzie dotyczyć właśnie tych tabletów.
Dla przykładu, jeżeli kluczem w systemie byłaby liczba, a każdy nowo utworzony rekord otrzymywałby klucz o jeden większy niż poprzednio utworzony rekord, to wszystkie operacje dodania rekordu operowałby na jednym i tym samym tablecie, co w konsekwencji mogłoby nawet doprowadzić do awarii systemu.
Dla porównania w Amazon Dynamo dla klucza jest wyliczana suma kontrolna i dopiero na podstawie tej wartości następuje przydział rekordu do określonego przedziału a co za tym idzie węzła, w związku z czym podobne klucze mogą znaleźć się na zupełnie innych węzłach.

Kolumny są grupowane w rodziny kolumn (ang. \emph{column families}).
Wszystkie kolumny z jednej rodziny mają nazwę postaci nazwa\_grupy:nazwa\_kolumny.
Nazwa grupy kolumn musi składać się ze znaków nadających się do wydruku, zaś nazwa kolumny może być dowolnym ciągiem bajtów.
Rodzina kolumn zazwyczaj przechowuje wartości tego samego typu, gdyż wartości te są razem kompresowane.
Rodzina kolumn musi być dodana do schematu zanim będzie możliwe dodawanie wartości w jej kolumnach, ale co ważne nie jest konieczne deklarowanie samych kolumn.
W bazach takich jak BigTable przyjmuje się, że liczba rodzin kolumn jest niewielka i zmienia się nieznacznie wraz z rozwojem aplikacji.
Jedynie nie-puste wartości kolumn są zapisywane, więc można powiedzieć, że tabela BigTable jest ,,macierzą rzadką'' (ang. \emph{sparse}).

Dzięki temu, że nie ma konieczności deklarowania kolumn, oraz tego że puste komórki nie zajmują miejsca, kolumny w BigTable są bardziej wszechstronne niż kolumny, które są czytelnikowi znane z relacyjnych baz danych.
Czasami nazwą kolumny może być liczba, na przykład będąca identyfikatorem innego rekordu (bardzo łatwo w ten sposób modelować relację jeden do wielu).
Ponadto BigTable pozwala na wersjonowanie komórek macierzy, czyli parze (klucz, nazwa kolumny) odpowiada lista wartości, z których każda opisana jest czasem modyfikacji.
Stare rewizje mogą być usuwane przez system automatycznie albo dzięki określeniu maksymalnej liczby wartości do zapisania, albo przez określenie jak dawne wersje mają być przechowywane (np. z ostatnich siedmiu dni).
Inną właściwością BigTable jest to, że zmiana wielu wartości kolumn jest dokonywana atomowo, co upraszcza pracę w rozproszonym środowisku.

Ponieważ rekord w BigTable może mieć bardzo wiele kolumn, system ten udostępnia stosunkowo rozbudowane mechanizmy limitowania i wyszukiwania kolumn na poziomie pojedynczego rekordu.

W Google BigTable nie ma możliwości wyszukiwania rekordów - dostęp do rekordów jest wyłącznie po ich kluczu, albo po przedziale kluczy.
Nie oznacza to oczywiście, że wyszukiwanie po wartości konkretnego pola jest niemożliwe, ale wymaga to od użytkownika stworzenia osobnych tabel, które pełniłyby funkcję indeksów.
Dla przykładu mając tabelę pracowników i chcąc móc wyszukiwać pracowników po nazwisku, oraz po adresie e-mail, musielibyśmy stworzyć dwie dodatkowe tabele, w jednej z nich kluczem byłoby nazwisko pracownika, a w drugiej adres e-mail, natomiast nazwy kolumn mogłyby zawierać klucze pracowników o tym adresie e-mail bądź nazwisku.
Do wykonywania operacji na dużych liczbach rekordów służy albo opisywane wcześniej Google MapReduce, które wtedy zamiast wczytywać dane wejściowe i zapisywać dane wyjściowe do GFS, wczytuje je i zapisuje do BigTable, albo wykonywanie skryptów w przestrzeni adresowej serwera.
Skrypty te (pisane w języku Sawzall) nie mogą wprawdzie dokonywać żadnych modyfikacji, ale są przydatne w celu dokonywania różnorakich obliczeń czy podsumowań.

\subsection*{Architektura wysokiego poziomu}

Google BigTable do działania potrzebuje dwóch innych systemów: Google Chubby i Google File System (GFS).
Pierwszy z nich przede wszystkim pozwala na wybranie spośród węzłów systemu węzła master, a drugi zapewnia mechanizm replikacji.
Oba te systemy zostały opisane nieco bliżej w sekcji ,,Zależności'' (patrz strona \pageref{sec:bigtable-zaleznosci}).

\subsubsection*{Podział węzłów}

\myfigure{chapters/studium_literatury/bigtable-nodes.png}{Typy węzłów BigTable}{fig:bigtable-nodes}

Węzły BigTable dzielimy na trzy rodzaje:

\begin{description}
 \item[master] - w danym momencie w systemie może występować tylko jeden węzeł tego typu.
 Węzeł ten przyjmuje na siebie rolę zarządzania serwerami tabletów.
 Jego zadaniem jest przydzielenie obsługi konkretnych tabletów do węzłów, wykrywanie kiedy serwer tabletów ulegnie awarii i przypisane mu tablety należy przydzielić innemu węzłowi.
 Może on także zajmować się równoważeniem obciążenia węzłów poprzez przekazywanie tabletów z bardziej obciążonych węzłów do mniej obciążonych.
 Innym zadaniem serwera master jest usuwanie zbędnych plików z GFS. 
 \item[serwer tabletów] - każdy tablet jest przypisany do jednego węzła, który odpowiada za obsługę wszystkich operacji odczytu i zapisu dotyczących tego tabletu.
 Same tablety są zapisywane w plikach w systemie plików GFS, co oznacza, że dane mogą znajdować się na innym węźle niż serwer tabletów.
 Typowy węzeł jest serwerem od 10 do 1000 tabletów.
 Dla porównania, w Amazon Dynamo za obsługę zapytań dotyczących przedziału rekordów, odpowiadają węzły, które również przechowują te dane.
 \item[klient] - klient dokonuje zapytań w systemie.
 Interesującą właściwością BigTable jest to, że typowy klient nie musi wcale komunikować się z węzłem master.
 Za pośrednictwem Google Chubby i innych serwerów tabletów klient jest w stanie poznać przydział tabletów do węzłów i w ten sposób nawiązać komunikację bezpośrednio z odpowiednim serwerem tabletów.
\end{description}

\subsubsection*{Drzewo tabletów}

\myfigure{chapters/studium_literatury/bigtable-tablets.png}{Drzewo Tabletów}{fig:bigtable-tablets}

Metadane dotyczące wszystkich tabletów są zapisane w trzypoziomowym drzewie.
Korzeniem tego drzewa jest specjalny tablet (tzw. \emph{root tablet}).
Różni się on od innych tabletów tym, że jako jedyny nie może ulec podziałowi ani usunięciu.
Zadaniem tego tabletu jest przechowywanie informacji od tabletach drugiego poziomu.

Drugi poziom tabletów zawiera metadane tabletów zawierających dane użytkownika, które to stanowią trzeci poziom drzewa.

Klient nie znający lokalizacji tabletu zawierającego interesujący go klucz musi:

\begin{enumerate}
 \item Odczytać z Google Chubby adres serwera tabletów odpowiadającego za \emph{root tablet}.
 \item Wykonać zapytanie do tego serwera tabletów o lokalizację tabletu, który zawiera informacje o tablecie przechowującym interesujący klienta przedział.
 \item Odczytać rekord z tabletu drugiego poziomu wskazujący na lokalizację tabletu zawierającego rekord interesujący klienta.
 \item Znając lokalizację serwera tabletów, który odpowiada za rekord interesujący klienta, może on skierować do niego zapytanie.
\end{enumerate}

Jak widać, ważne jest aby klient zapisywał dane o lokalizacji tabletów.
Widać także, że wspomniany wcześniej fakt, że powiązane rekordy mogą należeć do tego samego tabletu, pomaga zmniejszyć opóźnienia operacji na nich.

W przypadku jeżeli klient posiana nieaktualne informacje o lokalizacji tabletu, próbuje on skontaktować się kolejno z serwerami od trzeciego do pierwszego poziomu korzystając z zapisanych danych o ich lokalizacji, a następnie wykrywa lokalizację tabletu według wcześniej opisanego schematu począwszy od tabletu, o którym informacje nie uległy dezaktualizacji.
W pesymistycznym przypadku może to oznaczać konieczność połączenia aż z sześcioma\footnote{W przypadku gdy klient nie posiada żadnych informacji o węzłach, musi wykonać 3 zapytania aby poznać lokalizację tabletu. Jeżeli posiada całkowicie nieaktualne informacje, to najpierw dowiaduje się o tym poprzez wykonanie 3 zapytań do węzłów, które już nie odpowiadają za serwowanie tabletów każdego z 3 poziomów, a następnie kolejne 3 aby poznać aktualną lokalizację interesującego tabletu.} węzłami, ale zazwyczaj nie jest to konieczne.

Serwery tabletów używają Google Chubby do rejestrowania się w systemie.
Aby tego dokonać, przy starcie serwer tabletów tworzy plik w specjalnym katalogu w Google Chubby i zdobywa na nim blokadę do zapisu.
Dopóki serwer tabletów posiada tą blokadę, dopóty może on zajmować się serwowaniem tabletów.
Jeżeli straci blokadę, stara się ją odzyskać, jeżeli jednak plik na którym miał blokadę został usunięty, serwer tabletów jest zmuszony zakończyć działanie.
Węzeł master komunikuje się co pewien czas ze wszystkimi serwerami tabletów, żądając od nich podania statusu ich blokady.
Jeżeli master nie jest w stanie się połączyć z serwerem tabletów, lub jeżeli odpowie on, że stracił blokadę na pliku, master próbuje zdobyć tą blokadę i w przypadku powodzenia, usuwa plik powodując tym samym restart serwera tabletów.

\subsection*{Architektura serwera tabletów}
\label{sec:bigtable-architektura-serwera-tabletow}

\myfigure{chapters/studium_literatury/bigtable-tablet-datastructures.png}{Serwer Tabletów}{fig:bigtable-tablet-server}

Dane o tablecie są zapisywane przez serwer tabletów w trzech lokacjach.
Pierwszą z nich jest \emph{tablet log}, do którego zapisywane są wszelkie modyfikujące tablet operacje.
Każda taka operacja musi zostać zapisana w tym pliku zanim zostanie przetworzona.

Po zapisaniu do \emph{tablet logu} operacja może zostać odwzorowana w pamięci operacyjnej.
Zmiany są wykonywane korzystając z techniki \emph{copy-on-write} (kopiowanie przy zapisie), dzięki czemu wynik operacji nie jest widoczny aż do jej zakończenia.
Co pewien czas struktura w pamięci (nazywana \emph{memtable}) jest zrzucana na dysk (do GFS) do pliku SSTable.
SSTable to format pozwalający na zapisywanie tablic asocjacyjnych, odczytywanie kluczy zakresami i posiadający specjalny indeks, który, po wczytaniu do pamięci operacyjnej przy otwarciu pliku, umożliwia odczyt dowolnej wartości z pliku przy pomocy pojedynczego wyszukania na dysku.

Odczyt musi przeszukać \emph{memtable} i wszystkie pliki SSTable, dlatego po przekroczeniu pewnego limitu plików SSTable, cześć z nich jest łączona w jeden.
Istnieje także możliwość połączenia wszystkich plików SSTable w jeden.

\subsection*{Zależności}
\label{sec:bigtable-zaleznosci}

BigTable opiera się bardzo mocno na dwóch innych systemach: Google File System (GFS) oraz Google Chubby.
W kolejnych sekcjach zostaną one pokrótce opisane aby ułatwić czytelnikowi zrozumienie architektury tej bazy i jaką te systemy pełnią w niej rolę.

\subsubsection*{Google File System}

Google File System (GFS) opisany w artykule \cite{google-file-system} jest rozproszonym systemem plików (ang. \emph{distributed file system}), który jest zoptymalizowany pod duże pliki, najczęściej aktualizowane przez dopisywanie na koniec (ang. \emph{append-only files}), ale umożliwia także przechowywanie małych plików i losowy dostęp do nich.
Wszystkie pliki w GFS dzielone są na fragmenty rozmiaru 64MB (ang. \emph{chunk}).
System ten jest zaprojektowany z myślą o pracy na setkach lub tysiącach średniej klasy maszyn.

Podobnie jak w BigTable, w GFS występuje pojedynczy węzeł master wybierany korzystając z tego samego mechanizmu co w BigTable, korzystając z Google Chubby.
Pozostałe węzły przyjmują role serwerów fragmentów (ang. \emph{chunkserver}).
Jeden fragment jest zazwyczaj replikowany na 3 takie serwery, z których jeden jest wyróżniony.
Wyróżniona replika odpowiada za koordynację zapisów.

\emph{Master} przechowuje metadane o systemie plików, oraz o podziale plików na fragmenty.
Informacja o lokalizacji fragmentów nie jest zapisywana trwale przez węzeł \emph{master}, ale budowana po wyborze \emph{mastera} i uaktualniana w miarę potrzeby.
Dane \emph{mastera} są replikowane na kilka maszyn aby zapobiec ich utracie.

\emph{Master} przyznaje dla każdego fragmentu jednej z jego replik dzierżawę (trwającą 60s), która sprawia, że węzeł ten staje się wyróżniony dla tej repliki i zajmuje się koordynacją zapisów.
Klienci komunikują się z \emph{masterem} w celu zdobycia dostępu do metadanych systemu (lokalizacja fragmentów, system plików).
Operacje zapisu i odczytu nie wymagają zazwyczaj komunikacji z węzłem \emph{master}, pod warunkiem oczywiście, że klient ma zapisane lokalizacje fragmentów.

Poza typowymi operacjami na plikach, GFS udostępnia operację dodania ,,rekordu'' na koniec pliku.
Rekord taki jest dodawany atomowo, ale może wystąpić w pliku więcej niż raz, a poszczególne rekordy mogą być rozdzielone obszarami zawierającymi nic nie znaczące śmieci.

Zapis na koniec pliku w GFS przebiega w następujący sposób: 
\begin{enumerate}
 \item Najpierw klient przesyła dane do najbliższej\footnote{adresy IP serwerów pozwalają na określenie ,,odległości'' między nimi, gdyż są ściśle związane z topologią sieci} z replik,
 \item Replika ta przekazuje dane dalej w ten sam sposób i jest to powtarzane, aż wszystkie serwery otrzymają dane,
 \item Klient jest powiadamiany o zakończeniu transferu,
 \item Klient wysyła do wyróżnionej repliki żądanie zapisu,
 \item Wyróżniona replika definiuje kolejność zapisów (szereguje je) i zleca je pozostałym,
 \item Operacja kończy się sukcesem tylko jeżeli wszystkie repliki zapiszą poprawnie rekord,
 W przeciwnym razie błąd jest zgłaszany do użytkownika, ale ponieważ zapis mógł się powieść na niektórych replikach, rekord może występować w pliku więcej niż raz.
\end{enumerate}

BigTable wykorzystuje GFS do przechowywania tabletów, których dane zapisywane są w dwóch rodzajach plików: plikach typu SSTable, oraz dzienniku operacji (ang. \emph{tablet log}).
Żaden z powyższych rodzajów plików nie wymaga losowego dostępu dla zapisów - pliki SSTable są zapisywane raz, w całości, zaś dziennik tabletu jest zapisywany poprzez dodawanie rekordów na koniec.

W momencie pisania tych słów w użyciu jest już nowa wersja GFS -- GFS2, zaprojektowana z myślą o BigTable i zastosowaniach gdzie nawet kilkunastosekundowe opóźnienia spowodowane wyborem nowego mastera są niedopuszczalne.
Nowa wersja GFS zmniejsza znacznie rozmiar fragmentu pliku, z 64MB do 1MB oraz opiera się na architekturze opartej na wielu serwerach master i partycjonowaniu metadanych systemu plików.
Niestety dokładny opis tej architektury nie jest jeszcze dostępny.

\subsubsection*{Google Chubby}
\label{sec:google-chubby}

Google Chubby jest to rozproszony system blokad (ang. \emph{distributed lock service}).
Jest to usługa pozwalająca klientom na zakładanie blokad (do odczytu bądź do zapisu), co z kolei umożliwia stosowania w środowisku rozproszonym powszechnie znanego modelu programowania w oparciu o muteksy.
Google Chubby został dokładniej opisany w artykule z 2006 roku \cite{google-chubby}.

Ponieważ blokady służą zazwyczaj do strzeżenia jakichś danych, architekci Chubby postanowili udostępnić także interfejs systemu plików, tak aby nie trzeba było wykorzystywać dwóch różnych systemów do tworzenia blokad oraz odczytu i zapisu danych.
Google Chubby nie jest przeznaczony do stosowania jako typowy system plików, dlatego pliki w Chubbym są małe (limit 256kb) oraz odczytywane i zapisywane atomowo, w całości.

Innymi ważnymi funkcjami Google Chubby jest mechanizm zdarzeń i mechanizm cacheowania.
Klienci mogą zapisywać się na otrzymywanie powiadomień o szeregu różnych zdarzeń, które mogą zajść w systemie, najważniejszym z których jest zdarzenie modyfikacji pliku.
Ponieważ klient utrzymuje połączenie z Google Chubby, informowany jest o zdarzeniach bardzo szybko.
Z tego samego mechanizmu korzysta cacheowanie w Chubby.
Każdy klient, który dokonał odczytu jakiejś wartości może zapisać ją lokalnie.
Jeżeli ulegnie ona zmianie, serwer prześle klientowi informacje o tym, że nastąpiła zmiana (ale nie przesyła nowej wartości).
Klient może wtedy ponownie odczytać nową wartość, sprawiając tym samym że zostanie poinformowany o kolejnych ewentualnych zmianach.
Klient, który nie odczyta ponownie zmienionej wartości nie będzie już więcej powiadamiany o jej zmianach.

Połączenie wyżej wymienionych funkcjonalności sprawia, że Chubby jest powszechnie używany jako serwer nazw, lepszy niż serwery DNS gdyż nie wymagający konfigurowania wartości TTL (ang. \emph{Time-To-Live}), która źle ustawiona może doprowadzić albo do nadmiernego obciążenia serwerów nazw, albo zbyt wolną propagację zmian wartości.

Innym bardzo ważnym zastosowaniem Google Chubby jest wybór wyróżnionego serwera (np. serwera \emph{master}).
Problem wyboru mastera jest problemem rozproszonego konsensu implementowany zazwyczaj przy pomocy algorytmu Paxos.
W takim rozwiązaniu każdy węzeł musi wziąć udział w głosowaniu i większością głosów wybierany jest wyróżniony węzeł.
Zastosowanie usługi takiej jak Chubby nie tylko znacznie upraszcza ten problem w stosunku do rozwiązania gdzie każdy węzeł implementuje Paxos, ale także pozwala na dokonanie wyboru nawet w sytuacji, gdy nie da się osiągnąć kworum (ze względu na awarie węzłów, czy podział sieci).

Procedura wyboru wyróżnionego serwera w Chubby przebiega następująco:

\begin{enumerate}
 \item Wszystkie zainteresowane węzły próbują otworzyć określony plik (np. /ls/foo/master) z blokadą do zapisu.
 \item Chubby pozwala jednemu z nich na otwarcie tego pliku.
 \item Węzeł zapisuje w tym pliku swój adres albo identyfikator.
 \item Wszystkie węzły są informowane o zmianie węzła master poprzez zdarzenie zmodyfikowania pliku, na które powinny wszystkie być zarejestrowane.
\end{enumerate}

Podobnie łatwo można zastosować ten system do wykrywania węzłów.
Chubby umożliwia tworzenie specjalnego rodzaju plików, zwanych plikami efemerycznymi.
Pliki te są usuwane natychmiast po ich zamknięciu, bądź po utracie połączenia z klientem, który go otwarł.
Jeżeli każdy węzeł podłączany do systemu utworzy efemeryczny plik w ogólnie znanym katalogu, wszystkie inne węzły z łatwością dowiedzą się o tej zmianie przy pomocy mechanizmu zdarzeń.
Podobnie jeżeli węzeł ulegnie awarii, jego plik zostanie wkrótce usunięty i inne węzły dowiedzą się o tym niemal natychmiast.

Pojedynczy serwer Google Chubby jest w stanie obsłużyć nawet 90 tysięcy klientów.
Jest to konieczne, ponieważ cała komunikacja odbywa się pomiędzy klientami a jednym, wyróżnionym serwerem master\footnote{Artykuł \cite{google-chubby} opisuje potencjalne techniki skalowania przy pomocy partycjonowania i serwerów proxy, ale nie były one wykorzystywane w czasie pisania tego artykułu}.
Serwer ten jest replikowany zazwyczaj na 4 inne serwery.
Wszystkie one (master i jego repliki są nazywane komórką - ang. \emph{cell}) biorą udział w wyborze mastera, wykorzystując do tego algorytm Paxos.
Komórki Chubby są zazwyczaj współdzielone między różnymi aplikacjami.

W Google BigTable Chubby jest wykorzystywany do zapewnienia istnienia pojedynczego węzła master, wykrywania serwerów tabletów i ich awarii, przechowywania danych dotyczących schematu bazy i list dostępu.
Awaria i niedostępność Chubby powoduje także niedostępność BigTable.
Cytując za artykułem \cite{google-bigtable}, przełożyło się to na zmniejszenie dostępności systemu średnio o 0.0047\%, a w najgorszym przypadku o 0.0326\%\footnote{Dla lepszego zobrazowania: odpowiednio 24 minuty i 171 minut w ciągu roku}.

\subsection*{Znaczenie}

Wpływy Google BigTable można znaleźć w HBase, Hypertable, Apache Cassandra i nawet MongoDB.
Baza ta jest typowym przykładem systemu, który w obliczu wystąpienia podziałów sieci wybiera konsystencję kosztem dostępności (CP w Teorii CAP).
Bardzo interesujące jest zastosowanie Google Chubby w tym systemie jako sposób na uniknięcie skomplikowanego problemu wyboru wyróżnionego węzła.
Odpowiednik Google Chubby o nazwie Zookeeper, zaimplementowany na potrzeby HBase, jest wykorzystywany do wyboru węzła master w grafowej bazie Neo4J.
Technika ta może być z powodzeniem stosowana w wielu systemach rozproszonych upraszczając ich architekturę.

Zainteresowanym lekturą artykułu przedstawiającego Google BigTable \cite{google-bigtable} polecam także lekturę dwóch innych pokrewnych artykułów o Google Chubby \cite{google-chubby} i Google File System \cite{google-file-system}.
Pominięcie ich może bowiem sprawić, że czytelnik nie będzie w stanie samodzielnie zrozumieć architektury BigTable, a tym bardziej konsekwencji jakie powodują założenia przyjęte przez architektów firmy Google.

\section{Podsumowanie}

W powyższym rozdziale przedstawione zostały na podstawie literatury koncepcje, które mają wpływ na skalowalne bazy danych obecnie na rynku.
Opisane zostały dwie wysoko skalowalne bazy danych wykorzystywane przez internetowych gigantów -- Amazon i Google.
Sukces obu rozwiązań nie ulega wątpliwości, a pokazują one jak bardzo mogą różnić się podejścia do skalowalności.
Z jednej strony mamy Amazon Dynamo, które stawia przede wszystkim na dostępność systemu, którą opłaca trudniejszym interfejsem z punktu widzenia programisty.
Z drugiej strony mamy Google BigTable, które poświęca dostępność dla konsystencji, ale dzięki temu jest o wiele prostsze i wymaga mniejszych nakładów pracy od programisty.
Przedstawiony został także framework MapReduce, który jest podstawą do wykonywania zapytań, które muszą dokonać przeglądu wszystkich lub dużej części rekordów w bazie, w wielu nierelacyjnych systemach bazodanowych.