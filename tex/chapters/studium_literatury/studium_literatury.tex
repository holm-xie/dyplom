\chapter{Studium Literatury}

\section*{Streszczenie}

W studium literatury zajmę się opisaniem teorii CAP \cite{brewers-conjecture} (\emph{Consistency, Availability, Partition Tolerance}), zwanej również teorią Brewer'a od nazwiska jej autora. 
Teoria ta twierdzi, że rozproszony system nie jest w stanie zapewnić równocześnie wszystkich trzech gwarancji: konsystencji danych widzianych przez węzły systemu, odporności całości systemu na awarie poszczególnych jego węzłów oraz odporności systemu na utratę połączenia pomiędzy poszczególnymi węzłami lub ich grupami. 
Przedstawię także zasady działania Google BigTable \cite{google-bigtable} oraz Amazon Dynamo \cite{amazon-dynamo}, które bardzo istotnie wpłynęły na architekturę systemów NoSQL. 
Porównam także semantykę BASE (\emph{Basically Available, Soft-state, Eventually-consistent}) z ACID (\emph{Atomicity, Consistency, Isolation, Durability}).\todo{napisać dlaczego, uporządkować}

\section{Teoria CAP}

Teoria CAP (\emph{Consistency, Availability, Partition Tolerance}) zwana również teorią Brewera od nazwiska jej autora została po raz pierwszy zaprezentowana podczas prezentacji profesora Uniwersytetu Berkley Eryka Brewera 19 czerwca 2000r. na konferencji \emph{ACM Symposium on the Principles of Distributed Computing} \cite{podc-keynote}. 
W około dwa lata później, w 2002 roku, teoria ta (pod nazwą \emph{Brewer's Conjecture} - Domysł Brewera) została formalnie udowodniona przez Nancy Lynch oraz Setha Gilberta z MIT \cite{brewers-conjecture}.

Teoria CAP powstała jako efekt doświadczeń Brewera w firmie Inktomi oraz jego prac badawczych nad systemami rozproszonymi na Uniwersytecie w Berkley. 
Mówi ona, że z trzech pożądanych właściwości systemu rozproszonego: Konsystencji (ang. \emph{Consistency}), Wysokiej Dostępności (ang. \emph{Availability}) oraz Odporności na Podział Sieci (ang. \emph{Partition Tolerance}) możliwe jest zapewnienie co najwyżej dwóch z nich \cite{browne-cap-theorem}.

\subsection*{Konsystencja}

Termin ,,Konsystencja'' w Teorii CAP ma nieco inne znaczenie niż w ACID, gdzie oznacza on, iż zapisywane dane nie mogą złamać pewnych określonych reguł integralności. 
W Teorii CAP \emph{Consistency} jest dużo bardziej zbliżone do \emph{Atomicity} z ACID, oznacza ono bowiem, że gdy dokonamy operacji zapisu $x=x_0$ każdy kolejny odczyt $x$, niezależnie do którego węzła byłby skierowany, zwróci wartość $x_0$.

\subsection*{Wysoka Dostępność}

Wysoka dostępność jest najbardziej pożądaną właściwością z trzech wymienionych.
Oznacza ona, jak sama nazwa wskazuje, że system powinien udostępniać swoje usługi w pełni przez cały czas, wliczając w to awarie poszczególnych węzłów, aktualizacje oprogramowania czy awarie sieci. 
Bardziej formalnie: jeżeli operacja dotrze do nie ulegającego właśnie awarii węzła, to w pewnym skończonym czasie zwróci wynik do klienta.
Warto przy tym zwrócić uwagę (za  \cite{brewers-conjecture}), że dostępność zawodzi najczęściej właśnie wtedy, gdy jest najbardziej potrzebna, czyli w okresach największego obciążenia systemu.

\subsection*{Odporność na Podział Sieci}

W systemach rozproszonych, działających na tysiącach węzłów, często rozsianych w centrach obliczeniowych na wielu kontynentach utrata połączenia pomiędzy grupami węzłów jest oczekiwanym, codziennym problemem.
Podział sieci, rozumiany tu właśnie jako utrata połączenia między dowolnymi dwoma lub więcej węzłami systemu, przy zachowaniu połączenia tych węzłów z klientem, może nastąpić z wielu powodów: awarie switchy lub routerów, utrata połączenia między centrami obliczeniowymi, dokonywane naprawy.
W przypadku kiedy węzeł lub ich grupa zostanie całkowicie odcięty od klientów i innych węzłów systemu, możemy traktować te węzły tak samo jak gdyby na przykład odcięto im nagle zasilanie, dlatego definicja podziału takiego przypadku nie obejmuje.

Dla przykładu wyobraźmy sobie bazę danych replikowaną w systemie master-master.
Jeżeli połączenie między węzłami zostanie zerwane, modyfikacje dokonane na jednym z nich nie będą widoczne na drugim. 
Z kolei w sytuacji gdy mamy bazę danych z horyzontalnym podziałem danych (ang. \emph{sharded}), ponieważ każdy z serwerów zawiera informacje dotyczące tylko części danych i z góry wiadomo do którego z nich należy się zwrócić aby otrzymać informacje dotyczące dowolnego klucza, nawet w przypadku utraty połączenia między nimi, o ile klient ma dostęp do obu serwerów, ciągłość dostarczanych usług jest zapewniona.

\subsection*{Znaczenie Teorii}

Teoria CAP nabiera znaczenia w miarę wzrostu wielkości systemu. 
Gdy dysponujemy bazą rozsianą na kilku maszynach, narzut czasowy replikacji danych pomiędzy nimi jest akceptowalny dla większości zastosowań, nie musimy się też zbytnio martwić o podział sieci, gdyż zazwyczaj jest tak, że maszyny zlokalizowane w jednej szafie (ang. \emph{rack}) będą albo działać wszystkie, albo żadna. 
Kiedy jednak zajmujemy się usługami rozproszonymi na tysiącach węzłów, nawet gdybyśmy dysponowali 10000 maszynami o niezawodności MTBF 30 lat, każdego dnia następowałaby awaria którejś z nich \cite{google-lessons}. 
W przypadku tak dużych systemów, czas jakiego wymaga replikacja danych aby doprowadzić aby każdy węzeł widział ten sam stan, czy to jak system reaguje na podziały sieci nabiera o wiele większego znaczenia.

\subsubsection*{Podział systemów}

Teoria CAP mówi, że nie możemy zapewnić równocześnie wszystkich trzech gwarancji, dlatego skalowalne systemy muszą porzucić jedną z nich. 
Ze względu na to dzielimy je na:

\begin{enumerate}
 \item \emph{CA} - (Consistent, Available) te systemy mają problemy z podziałem sieci, wymagając zazwyczaj aby operacje dotyczące poszczególnych transakcji trafiały do pojedynczej grupy węzłów, które podlegają awarii ,,atomowo'' - albo wszystkie działają, albo żaden. 
 To podejście zazwyczaj wiąże się z problemami dla skalowalności.
 \item \emph{AP} - (Available, Partition-Tolerant) te systemy zapewniają największą odporność na awarie wynikające z rozproszonego środowiska, jednocześnie jednak stawiając twórców aplikacji przed trudnym zadaniem radzenia sobie z problemami wynikającymi z niespójności danych widzianych przez klientów bazy.
 \item \emph{CP} - (Consistent, Partition-Tolerant) te systemy w wypadku podziału oczekują na przywrócenie połączenia, ograniczając w ten sposób dostępność.
\end{enumerate}

W praktyce systemy omawiane w tej pracy zazwyczaj zadowalają się częściowym zapewnieniem wszystkich wymienionych gwarancji, przy czym wysoka dostępność odgrywa główną rolę, a poświęcana jest albo odporność na podziały, albo konsystencja. 
Dlatego systemy te należą albo do grupy CA (Google BigTable, HBase), albo do grupy AP (Amazon Dynamo, Riak).
\todo{Podział na CA, AP, CP - po lepszym poznaniu poszczególnych rozwiązań} 

\section{BASE}

BASE (\emph{Basically Available, Soft state, Eventual consistency}) to model konsystencji, który jest przeciwstawiany modelowi ACID (\emph{Atomicity, Consistency, Isolation, Durability}). 
Oba te modele dotyczą baz danych, zatem oba wymagają aby operacje klienta były trwałe (\emph{Durability}).
Różnica między nimi bierze się z podejścia do konsystencji.
W ACID system zawsze musi być w spójnym stanie, a dokonanie zmiany może wymagać szeregu operacji które doprowadzą system do tego stanu.
Operacje te ponadto zostają objęte transakcją i zostają aplikowane albo wszystkie, albo żadna.
W BASE system może być w stanie niespójnym z punktu widzenia aplikacji, a operacje które mają przywrócić tą spójność są wykonywane asynchronicznie.

Producenci relacyjnych baz danych od dawna już byli świadomi potrzeby partycjonowania danych na wiele węzłów.
Aby zapewnić semantykę ACID w kontekście rozproszonych transakcji stosuje się technikę 2PC (ang. \emph{2 Phase Commit}).
Protokół 2PC działa dwustopniowo:

\begin{enumerate}
 \item Najpierw koordynator transakcji żąda od wszystkich węzłów biorących udział w operacji aby wstępnie dokonały operacji commit dla transakcji i potwierdziły możliwość wykonania tej operacji.
 Jeżeli wszystkie węzły dokonały tego potwierdzenia, przechodzi się do drugiego kroku.
 \item W drugim kroku koordynator żąda od wszystkich zainteresowanych węzłów dokonania operacji commit.
 Jeżeli którakolwiek z baz zawetuje tą operację, wszystkie muszą wycofać transakcję.
\end{enumerate}

Problem, na jaki napotykamy w tym podejściu, to ograniczenie dostępności systemu (A w CAP).
Wystarczy aby jeden z węzłów systemu podległ awarii, aby cały system stał się niedostępny dla zapisów.
Dostępność w kontekście transakcji staje się iloczynem dostępności poszczególnych węzłów systemu.
Jeżeli mamy zatem węzły o indywidualnej dostępności 99.9\% to transakcja, która obejmuje trzy z nich będzie miała dostępność ok. 99.7\% - czyli o ok. 90 minut mniejszy \emph{uptime} w skali miesiąca \cite{base-an-acid-alternative}.

Jeżeli zatem ACID oferuje nam poziom konsystencji, który można byłoby określić mianem Strong Consistency, ale kosztem dostępności, to BASE oferuje w zamian wysoką dostępność kosztem konsystencji. 

\subsection{Eventual Consistency}

Eventual Consistency (w wolnym tłumaczeniu: konsystencja po pewnym czasie, ostatecznie) to słaba forma gwarancji konsystencji, która gwarantuje jedynie, że po pewnym, możliwym do przewidzenia czasie od momentu wykonania operacji, jej efekty będą widziane przez klientów systemu, niezależnie od tego, do którego z węzłów systemu się zwrócą z zapytaniem.
Okno czasowe między operacją a propagacją jej efektów do wszystkich zainteresowanych węzłów w systemie nazywamy oknem niespójności (ang. \emph{inconsistency window}).

Choć początkowo może się wydawać, że tego typu model sprawia duże trudności w implementacji aplikacji korzystających z baz danych, które go zapewniają, w rzeczywistości tego typu interakcje napotykamy każdego dnia.
Kiedy w systemie bankowym dokonujemy przelewu z konta na konto, pieniądze znikają z bilansu jednego z nich, ale na drugim pojawiają się z pewnym opóźnieniem.
Innym przykładem może być system DNS, gdzie zmiana jest propagowana w systemie stopniowo, często oczekując na przeterminowanie cache, ale po jakimś czasie jest zauważalna u każdego klienta.

Artykuł \cite{vogels-eventually-consistent} wprowadza ponadto kilka rodzajów Eventual Consistency:

\begin{enumerate}
 \item \emph{Causal Consistency} - Jeżeli proces A wykonał jakąś operację, a następnie zakomunikował ten fakt procesowi B, to proces B będzie widział zmienione dane w taki sam sposób jak proces A, a jego zapisy nie będą wchodzić w konflikt z tą operacją.
 Proces C, któremu ta informacja nie została przekazana, będzie podlegał normalnym regułom.
 \item \emph{Read-your-writes Consistency} - Proces dokonujący operacji w kolejnych operacjach zawsze widzi rezultaty tej operacji.
 \item \emph{Session Consistency} - To praktyczna realizacja poprzedniego rodzaju konsystencji.
 W tym przypadku proces komunikuje się z systemem w kontekście sesji, w ramach której ma zapewnioną gwarancję odczytu swoich operacji.
 W przypadku awarii i konieczności nawiązania nowej sesji, gwarancje te nie przechodzą na nowo nawiązaną sesję.
 \item \emph{Monotonic Write Consistency} - W tym przypadku system gwarantuje, że operacje zostaną wykonane w tej samej kolejności, w jakiej żądania ich wykonania zostały wysłane.
 Systemy które nie oferują tej gwarancji są bardzo trudne w użyciu.
\end{enumerate}

\subsubsection*{Konfiguracja Eventual Consistency}

Werner Vogels w artykule o Eventual Consistency \cite{vogels-eventually-consistent} wprowadził nomenklaturę stosowaną w konfiguracji konsystencji wielu systemów NoSQL (np. Cassandra, Riak).
Konfigurację tą opisują zazwyczaj trzy liczby:

\begin{enumerate}
 \item \emph{N} - liczba węzłów systemu na które zostanie zreplikowany pojedynczy rekord.
 Liczba ta jest zazwyczaj określana jako parametr konfiguracji systemu, lub podczas wydawania polecenia utworzenia ``tabeli'' (nazwanego zbioru rekordów).
 Niektóre systemy pozwalają na zmianę tej wartości w trakcie działania systemu (np. Riak), ale większość wymaga ponownego uruchomienia aplikacji w celu zastosowania tej zmiany.
 \item \emph{R} - liczba węzłów systemu, które muszą dokonać odczytu zanim wartość zostanie zwrócona do klienta.
 Czasem wartości zwrócone przez poszczególne węzły będą różne.
 Wtedy system  odpowiada albo za rozwiązanie konfliktu, albo za przekazanie wielu wersji klientowi.
 Parametr R jest najczęściej określany z osobna dla każdego polecenia odczytu.
 \item \emph{W} - liczba węzłów systemu, które muszą potwierdzić zapis aby operacja została zakończyła się sukcesem.
 Podobnie jak R jest to parametr przekazywany dla każdego zapytania.
\end{enumerate}

Jeżeli $R+W>N$, to mamy do czynienia z silną konsystencją (ang. \emph{Strong Consistency}) - każdy odczyt zwróci ostatnią zapisaną wartość.
Jeżeli $W = 0$, to zapis jest dokonywany w pełni asynchronicznie.

\subsubsection*{Znaczenie}

Eventual Consistency opisuje problem dotykający każdej rozproszonej bazy danych, niezależnie od tego czy jest to baza relacyjna, sieciowy system plików czy baza NoSQL.
Tradycyjne podejście do konsystencji w kontekście replikacji jest ograniczające.
Systemy bazodanowe najczęściej implementują rozwiązanie typu wszystko-albo-nic: operacja zapisu musi się powieść na wszystkich węzłach albo zostać cofnięta.
Podejście takie nie tylko ogranicza dostępność systemu, powoduje ono także ograniczenie możliwości decyzyjnych autorów aplikacji korzystających z tych systemów.
Nawet jeżeli system umożliwia asynchroniczną replikację, zazwyczaj jest to bardzo prymitywny mechanizm, który nie bierze pod uwagę wersjonowania rekordów i sprowadza bazę do konfiguracji R=1, W=1.

Z drugiej strony systemy takie jak Amazon Dynamo pozwalają swoim użytkownikom na pełną dowolność w konfiguracji mechanizmów persystencji.
Nawet przy $R+W>N$ mamy możliwość sterowania zachowaniem systemu: czy zapisy powinny być szybsze kosztem odczytów, czy na odwrót, czy też może gdzieś pomiędzy.
Wiele z tych systemów zapewnia \emph{Read-your-writes Consistency} co stanowi dodatkowe ułatwienie.
Możliwość konfiguracji parametrów R, W i N stopniowo staje się standardem wśród systemów NoSQL obsługujących partycjonowanie danych.

\section{Google MapReduce}

Google MapReduce \cite{google-mapreduce} jest biblioteką wykorzystywaną do przetwarzania dużych zbiorów danych w środowisku rozproszonym.
Użytkownik biblioteki specyfikuje dwie funkcje nazywane \emph{map} i \emph{reduce} oraz kilka innych parametrów konfiguracyjnych.
Następnie biblioteka dba o to aby dane wejściowe zostały podzielone, na poszczególnych rekordach została wykonana funkcja \emph{map}, a jej wyniki zostały zagregowane przy pomocy funkcji \emph{reduce}.

Operacje \emph{map} i \emph{reduce} są powszechnie spotykane w językach funkcyjnych, takich jak na przykład LISP.
\emph{Map} na wejściu otrzymuje parę $(k, v): k \in K_1, v \in V_1$ a na wyjściu emituje listę par $(k, v): k \in K_2, v \in V_2$.
\emph{Reduce} na wejściu otrzymuje parę $(k, (v_1, ..., v_n)): k \in K_2, v_1...v_n \in V_2$ i na wyjściu emituje $v: v \in V_2$.

\subsection*{Przykład}

Poniżej przedstawiam przykładowy kod funkcji \emph{map} i \emph{reduce} w języku Python dla problemu zliczania wystąpień słów w zbiorze tekstów. 
Jak widzimy funkcja \emph{map} przyjmuje pary (klucz, wartość) z przestrzeni (Nazwy Dokumentów, Treść Dokumentów), zwracając pary z innej przestrzeni (Słowa, Liczby Naturalne).
Funkcja \emph{reduce} w przykładzie przyjmuje pary gdzie kluczem jest słowo, natomiast wartością jest lista liczb naturalnych określająca liczby wystąpień tego słowa w różnych dokumentach (albo wielokrotnie w tym samym dokumencie).

\begin{verbatim}
def map(document_name, document_value):
  """ funkcja mapujaca dokumenty na pary (slowo, 1)  """
  for word in words(document_value):
    yield (word, 1) # emit word

def reduce(word, counts):
  """ 
  funkcja redukujaca, przyjmuje slowo 
  i liste (iterator) po liczbie jego wystapien
  zwrace sumaryczna liczbe wystapien danego slowa
  """
  sum = 0
  for value in counts:
    sum += value
    # sum += 1
    # tak tez mozna byloby zapisac, 
    # ale wtedy funkcja nie bylaby laczna     
  return sum 
\end{verbatim}


\subsection*{Opis działania}

Użytkownik tworzy aplikację, w której specyfikuje dwie funkcje \emph{map} i \emph{reduce}, oraz dwa parametry konfiguracyjne: \emph{M} i \emph{R}:

\begin{itemize}
 \item \emph{M} - określa na ile części ma zostać podzielony plik wejściowy.
 Zazwyczaj wybiera się taką liczbę aby wielkość plików wejściowych zawierała się między 16MB a 64MB.
 Ponieważ GFS dzieli pliki na kawałki (ang. \emph{chunks}) wielkości 64MB, jest dość istotne aby pliki wejściowe nie przekraczały tej wielkości, gdyż w przeciwnym przypadku mogłaby występować konieczność komunikacji sieciowej w celu odczytania danych z pliku wejściowego.
 \emph{M} określa ponadto liczbę zadań \emph{map}.
 \item \emph{R} - określa liczbę zadań \emph{reduce}.
\end{itemize}

\myfigure{chapters/studium_literatury/map-reduce.png}{Google MapReduce}{fig:map-reduce}

\begin{enumerate}
 \item Biblioteka MapReduce dzieli plik wejściowy na \emph{M} części.
 \item Program użytkownika zostaje wysłany i uruchomiony na maszynach klastra.
 Jedna z tych maszyn przyjmuje specjalną rolę \emph{master}, pozostałe zaś mają rolę \emph{worker}\todo{może powinienem zamienić master na zarządca/nadzorca a worker na pracownik?}.
 \item \emph{master} przypisuje poszczególnym \emph{workerom} po jednym zadaniu do wykonania.
 Kolejne są przydzielane w miarę jak węzły kończą przydzieloną im pracę.
 Zadanie \emph{map} zostanie przydzielone w pierwszej kolejności maszynie która jest równocześnie \emph{chunkserverem} przechowującym odpowiedni plik wejściowy.
 Pozwala to uniknąć komunikacji sieciowej w celu odczytania pliku.
 \item \emph{Worker} przetwarza plik wejściowy rekord po rekordzie wywołując funkcję \emph{map} i zapisując jej wynik w pamięci.
 \item Co pewien czas dane zapisane w pamięci są zrzucane na dysk do plików lokalnych.
 W tym procesie dane są rozdzielane do \emph{R} plików poprzez funkcję partycjonującą, domyślnie $hash(key) mod R$.
 Lokacje tych plików są przekazywane do węzła \emph{master}, który z kolei jest odpowiedzialny za przekazanie ich do węzła wykonującego operację \emph{reduce} na odpowiednim fragmencie danych.
 \item Węzeł wykonujący operację \emph{reduce} po otrzymaniu takiego powiadomienia pobiera odpowiednie pliki bezpośrednio od węzła, który je przechowuje.
 Po otrzymaniu wszystkich potrzebnych plików, \emph{worker} sortuje otrzymane dane po kluczu, tak aby wartości dla danego klucza sąsiadowały ze sobą w pliku.
 \item Po posortowaniu plików wejściowych węzeł iteruje po kluczach i dla każdego z nich przekazuje klucz oraz listę wszystkich przypisanych mu wartości do funkcji \emph{reduce}, zapisując następnie jej wynik w pliku wyjściowym.
 \item Kiedy wszystkie operacje \emph{reduce} zakończą się, \emph{master} budzi program użytkownika i wywołanie funkcji \emph{MapReduce} kończy się.
\end{enumerate}

Wynikiem operacji jest \emph{R} plików wynikowych.
W większości przypadków konsumentem tych danych są inne operacje MapReduce, bądź aplikacje rozproszone, więc nie ma potrzeby łączenia tych plików w jedną całość.

\subsection*{Optymalizacje}

W artykule \cite{google-mapreduce} zostało opisanych kilka istotnych optymalizacji i ulepszeń:

\begin{enumerate}
 \item Operacja \emph{map} na pliku wejściowym jest wykonywana na tym samym serwerze, który przechowuje ten plik.
 \item Operacja \emph{map} może zwrócić bardzo wiele wartości dla danego klucza pośredniego.
 Z tego względu biblioteka wprowadza pojęcie funkcji łączącej (ang. \emph{combiner}).
 Funkcja ta dokonuje wstępnej redukcji przed wysłaniem wartości przez sieć do węzła wykonującego operację \emph{reduce}.
 Najczęściej stosuje się w tym miejscu tą samą funkcję co w operacji \emph{reduce}, ale aby to było możliwe, funkcja ta musi być łączna i przemienna, co czasem wymaga wprowadzenia pewnych zmian.
 Dla przykładu: przedstawiona wcześniej funkcja map emitująca wszystkie słowa w danym dokumencie emituje powtarzające się słowa wielokrotnie.
 Poprzez zsumowanie wystąpień przed przesłaniem znacznie zmniejszamy ilość danych do wysłania.
 \item Funkcja partycjonująca może być wyspecyfikowana przez użytkownika, dzięki czemu potencjalnie możliwe jest takie jej określenie, aby dane powiązane ze sobą znalazły się w jednym pliku wynikowym (aczkolwiek kosztem ryzyka nierównomiernego podziału kluczy między partycje).
 \item Dzięki sortowaniu kluczy pośrednich, pliki wynikowe są łatwiejsze do przetwarzania, umożliwiając na przykład wyszukiwanie binarne.
 \item Kiedy zbliża się koniec operacji, zadania \emph{reduce} są zlecane do wykonania przez dodatkowe węzły.
 Dzięki temu uszkodzone, nadmiernie obciążone przez inne procesy albo wadliwie skonfigurowane maszyny nie powodują nadmiernego wydłużenia całości operacji MapReduce.
\end{enumerate}

\subsection*{Odporność na awarie}

Ponieważ biblioteka MapReduce służy do wykonywania operacji w rozproszonym środowisku, często nawet na tysiącach węzłów, konieczne jest aby była ona odporna na awarie części z węzłów.
Rozróżniamy dwa typy awarii: awaria węzła \emph{master} i awarie węzłów typu \emph{worker}.

\subsubsection*{Awaria węzła master}

Ponieważ \emph{master} przechowuje między innymi informacje o zrealizowanych zadaniach i lokalizacji plików wynikowych.
\emph{Master} musi działać aby operacja MapReduce się zakończyła powodzeniem, ale możliwe jest aby jego struktury danych były zapisywane w GFS, albo replikowane do zapasowego węzła.
W opisanym systemie awaria węzła master zawsze kończy się niepowodzeniem całości operacji MapReduce i koniecznością jej ponownego uruchomienia.
Jest to dopuszczalne ponieważ czas trwania operacji jest liczony w minutach, więc awaria tego konkretnego węzła jest mało prawdopodobna (w odróżnieniu od np. BigTable, który jest systemem, który działa bez przerwy).

\subsubsection*{Awaria węzła slave}

\emph{Master} regularnie komunikuje się z węzłami \emph{slave} w celu ustalenia ich stanu.
W przypadku gdy węzeł przestaje odpowiadać jest uznawany za ,,martwy'', w związku z czym \emph{master} oznacza zadanie aktualnie przez niego wykonywane jako przeznaczone to przydziału, tak samo wszystkie wykonane przez niego zadania \emph{map}.
Zadania \emph{map} muszą być wykonane ponownie, ponieważ ich wyniki zostały zapisane w lokalnych plikach i przez to są niedostępne do odczytu.
Zadania \emph{reduce} zapisują swoje wyniki w GFS, w związku z tym nie muszą być powtarzane. 

\subsection*{Znaczenie}

Większość systemów opisanych w niniejszej pracy nie dysponuje zaawansowanymi metodami wykonywania zapytań, a w szczególności zapytań agregujących czy zliczających takich jak funkcje COUNT, SUM, AVG i operator GROUP BY w relacyjnych bazach danych.
Operacje tego typu są szczególnie trudne w kontekście systemów rozproszonych, gdzie wykonanie zapytań tego typu w trybie on-line przy zachowaniu odpowiedniego czasu odpowiedzi jest często wręcz niemożliwe.
Dlatego najczęściej wykonywanie tego typu operacji jest dokonywane co pewien czas, lub zlecane przy zapisie danych, a jego wyniki są przechowywane w systemie.

W przeważającej większości obliczenia te są wykonywane przy zastosowaniu algorytmu MapReduce.
Wiele systemów, tak jak MongoDB czy Riak, zapewnia taką funkcjonalność, inne wymagają zastosowania zewnętrznych narzędzi.
Wierną implementacją Google MapReduce jest Hadoop, który opiszemy nieco bliżej przy okazji Hbase.
Bardzo ciekawe podejście do MapReduce prezentuje CouchDB, która przechowuje wyniki funkcji map, dzięki czemu umożliwia dokonywanie zapytań opartych o MapReduce w trybie on-line.
CouchDB zostanie opisane bliżej w kolejnym rozdziale.

Algorytm MapReduce ma duże znaczenie w systemach NoSQL, gdyż stanowi surogat dla wykonywania skomplikowanych zapytań.
Stanowi on jedno z podstawowych narzędzi dla praktyki prostych odczytów, ale złożonych zapisów.

\section{Amazon Dynamo}

Amazon Dynamo to baza typu klucz-wartość używana w największym na świecie sklepie internetowym \emph{amazon.com}.
Baza została opisana w artykule z 2007 roku \cite{amazon-dynamo} i od tego czasu opisany w nim system doczekał się już dwóch implementacji open-source: Dynomite i Riak, oraz stał się inspiracją dla innych baz takich jak Cassandra, czy rozszerzenia CouchDB pozwalającego na rozpraszanie tej bazy.

Amazon Dynamo skaluje się bardzo dobrze - do setek węzłów, co dzięki zastosowaniu architektury opartej na usługach w zupełności wystarcza nawet takiemu gigantowi jak Amazon.
Interesującym aspektem architektury tego sklepu internetowego jest to, że poszczególne usługi muszą oferować gwarancje na czas wykonania (ang. \emph{Service Level Agreements}).
Przykładowym kontraktem tego typu jest gwarancja, że usługa zwróci odpowiedź w ciągu 300ms dla 99,9\% zapytań przy obciążeniu 500 zapytań na sekundę.
Konsekwencją istnienia takich gwarancji jest to, że Dynamo musi udostępniać wiele możliwości konfiguracji, tak aby usługi mogły dostosować właściwości bazy na potrzeby oferowanego kontraktu.

Jednym z wymagań dla systemu obsługującego sklep internetowy jest to aby użytkownik był w stanie zawsze dodać przedmioty do koszyka czy złożyć zamówienie.
W związku z tym Amazon Dynamo jest systemem w którym dostępność (A w CAP) odgrywa kluczową rolę, a odporność na podział sieci (P w CAP) jest jej uzupełnieniem.
Wydawało by się, że konsystencja ma duże znaczenie w przypadku sklepu internetowego - nie można przecież sprzedać towaru, którego się nie ma, a przecież w przypadku sklepu z którego korzystają miliony użytkowników równocześnie warunki wyścigu (ang. \emph{race conditions}) muszą występować nagminnie.
W amazon.com dopuszczalne jest aby dwóch klientów zamówiło ostatnią z książek w magazynie, a kiedy okaże się że jeden z nich jej nie może otrzymać sklep kontaktuje się z nim proponując na przykład dłuższy okres dostawy.
Nawet jeżeli nie wszyscy użytkownicy się zgodzą z taką sytuacją, to i tak przekłada się to na wyższe przychody.
Pokazuje to jak Eventual Consistency może z powodzeniem być stosowane w sytuacjach, gdzie normalnie kładzie się duży nacisk na spójność danych, nie powodując przy tym ujmy dla systemu.

\subsection*{Główne założenia architektury}

Autorzy Amazon Dynamo określili takie założenia co do architektury:

\begin{itemize}
 \item system jest zawsze w stanie przyjąć operację zapisu
 \item w związku z replikacją danych i naciskiem na wysoką dostępność, w systemie może wystąpić wiele wersji rekordu
 \item rozwiązywanie konfliktów między wersjami następuje przy odczycie i jest dokonywane przez aplikację, nie przez bazę (ale aplikacja może z tego zrezygnować i wybrać prosty mechanizm, np. ostatni zapis wygrywa)
 \item system musi się łatwo skalować wszerz poprzez dodawanie kolejnych węzłów i nie powinno to mieć dużego wpływu ani na administrację systemem ani na sam system
 \item system musi się charakteryzować symetrią: każdy węzeł ma taki sam zestaw obowiązków jak wszystkie inne
 \item system musi być zdecentralizowany: żaden węzeł nie jest wyróżniony i wszelkie operacje są wykonywane korzystając z mechanizmów \emph{peer-to-peer}
 \item system musi radzić sobie z heterogenicznością środowiska: narzut pracy na pojedynczy węzeł powinien uwzględniać jego możliwości w porównaniu do innych węzłów
\end{itemize}

\subsection*{Stosowane techniki}

Amazon Dynamo łączy w sobie wiele ciekawych technik rozwiązujących problemy takie jak partycjonowanie, wersjonowanie rekordów czy wykrywanie awarii.
W niniejszym rozdziale postaram się je czytelnikowi przybliżyć.

\subsubsection*{Consistent Hashing} 

W systemie takim jak Dynamo, który ma za zadanie skalować się do setek węzłów, horyzontalne partycjonowanie jest nieuniknione.
W Amazon Dynamo za podział na partycje odpowiada zmodyfikowany algorytm Consistent Hashing.
W następnych kilku paragrafach opiszę najpierw podstawowy algorytm, a następnie kolejne jego modyfikacje.

Consistent Hashing to algorytm który dla dowolnego klucza określa który węzeł systemu go przechowuje.
Ponieważ klucze są dowolnymi ciągami bajtów, zawsze operując na nich używamy funkcji mieszającej (ang. \emph{hashing function}).
Przeciwdziedzinę tej funkcji mieszającej traktujemy jako pierścień gdzie najmniejsza i największa możliwa wartość niejako stykają się ze sobą, podobnie jak ma to na przykład miejsce w przypadku długości geograficznych czy godzin na tarczy zegara.
W podstawowej wersji systemu każdy węzeł systemu losuje jedną wartość na tym pierścieniu.
Aby określić któremu węzłowi odpowiada dany klucz, obliczamy dla niego wartość funkcji mieszającej, a następnie znajdujemy węzeł, którego ,,pozycja'' na pierścieniu jest najbliższą zgodnie z ruchem wskazówek zegara po wartości wyliczonej.
W takim schemacie każdemu węzłowi odpowiada jeden, ciągły fragment pierścienia (patrz rysunek \ref{fig:consistent-hashing-01}).

\myfigure{chapters/studium_literatury/consistent-hashing-01.png}{Podstawowe Consistent Hashing}{fig:consistent-hashing-01}

Podstawowy wariant algorytmu ma wiele wad.
Problemem jest na przykład potencjalnie bardzo nierównomierna dystrybucja kluczy między węzłami.
Nie ma też żadnego wsparcia dla heterogeniczności środowiska - nie możemy ,,mocniejszemu'' serwerowi przekazać większego zakresu kluczy.
W związku z tymi ograniczeniami, wprowadza się tak zwane ,,wirtualne węzły'': pojedynczemu fizycznemu węzłowi przypisuje się wiele pozycji na pierścieniu (zazwyczaj liczba tych pozycji jest znacznie większa od ogólnej liczby węzłów).
Dzięki tej modyfikacji (o ile liczba wirtualnych węzłów jest wystarczająco duża) dystrybucja kluczy będzie znacznie bardziej sprawiedliwa, możemy też kontrolować obciążenie poszczególnych węzłów poprzez przyporządkowanie im mniejszej lub większej liczby pozycji na pierścieniu (patrz rysunek \ref{fig:consistent-hashing-02}).

\myfigure{chapters/studium_literatury/consistent-hashing-02.png}{Consistent Hashing z wirtualnymi węzłami}{fig:consistent-hashing-02}

Opisana powyżej wersja algorytmu radzi sobie zbyt dobrze z dodawaniem i usuwaniem węzłów niż wersja podstawowa, jednak w rzeczywistości nie sprawdza się zbyt dobrze.
Przy dodaniu węzła do systemu, klucze znajdujące się do tej pory pod opieką innych węzłów muszą być przekazane nowemu węzłowi.
Aby tego dokonać, konieczne jest dokonanie przeglądu wszystkich kluczy w dzielonym zakresie, konieczne jest także przeliczenie na nowo i synchronizacja drzew Merkle (vide \emph{Merkel Trees} na stronie \pageref{merkle-trees}). 
Przegląd taki obciąża system i musi być dokonywany w tle aby nie złamać gwarancji dawanych przez korzystającą z Dynamo usługę.
Aby uniknąć tego problemu należy rozdzielić mechanizm partycjonowania danych (w jaki sposób są tworzone przedziały) od tego które węzły nimi zarządzają.

W tym wariancie algorytmu przestrzeń kluczy zostaje podzielona z góry na określoną liczbę przedziałów S.
Najczęściej liczba ta będzie znacznie większa niż liczba węzłów systemu N ($S >> N$).
Następnie każdy z przedziałów przydzielamy losowo jednemu z węzłów tak aby każdy miał ich po $S/N$\footnote{oczywiście ten mechanizm może być dostosowany do wymagania heterogeniczności, tak aby jedne węzły otrzymywały więcej przedziałów niż inne}.
Dzięki temu rekordy przynależące do różnych z przedziałów mogą być przechowywane w odrębnych plikach, które z kolei mogą być przesyłane w ramach potrzeby do przejmujących nad przedziałem kontrolę węzłów bez zbędnego przeglądania danych na dysku.
Rysunek \ref{fig:consistent-hashing-03} przedstawia opisaną powyżej wersję algorytmu.

\myfigure{chapters/studium_literatury/consistent-hashing-03.png}{Consistent Hashing z rozdziałem partycjonowania i pozycjonowania rekordów}{fig:consistent-hashing-03}

\subsubsection*{Merkle Trees}
\label{merkle-trees}

\section{Google BigTable}

W kolejnym rozdziale opiszę Google BigTable \cite{google-bigtable} - bazę stosowaną w Google, przewyższającą Amazon Dynamo o rząd wielkości pod względem możliwej liczby węzłów, opartą na rozproszonym systemie plików GFS.
Google BigTable jest przykładem bazy CA (\emph{Consistent, Avaliable}).
W rozdziale opisującym dostępne systemy opiszę Hbase - bazę silnie wzorowaną na BigTable, ale opartą na Hadoop Core zamiast GFS, oraz Apache Cassandra, która łączy w sobie cechy Amazon Dynamo i Google BigTable.
