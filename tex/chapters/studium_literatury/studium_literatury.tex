\chapter{Studium Literatury}

\section*{Streszczenie}

W studium literatury zajmę się opisaniem teorii CAP (\emph{Consistency, Availability, Partition Tolerance}), zwanej również teorią Brewer'a od nazwiska jej autora. 
Teoria ta twierdzi, że rozproszony system nie jest w stanie zapewnić równocześnie wszystkich trzech gwarancji: konsystencji danych widzianych przez węzły systemu, odporności całości systemu na awarie poszczególnych jego węzłów oraz odporności systemu na utratę połączenia pomiędzy poszczególnymi węzłami lub ich grupami. 

Opiszę także BASE (\emph{Basically Available, Soft state, Eventual consistency}) i Eventual Consistency, które wprowadzają model konsystencji systemu bazodanowego, który o wiele lepiej przystaje do systemów rozproszonych niż ACID, dając programiście dużo większe możliwości wpłynięcia na zachowanie systemu i jego charakterystyki wydajnościowe, ale opłacając to kosztem zwiększenia złożoności korzystania z takiego systemu.

Google MapReduce to nie tylko narzędzie pozwalające na przetwarzanie astronomicznych ilości danych.
Jest to także wzorzec wykorzystywany przez wiele systemów NoSQL w celu zapewnienia możliwości przetwarzania dużych zbiorów rekordów pod nieobecność takich operatorów jak GROUP BY w SQL.

Przedstawię także zasady działania Google BigTable oraz Amazon Dynamo, które bardzo istotnie wpłynęły na architekturę systemów NoSQL. 
Bazy te przedstawiają sobą zupełnie różne podejścia do problemu skalowalności: Amazon Dynamo stawia przede wszystkim na dostępność, podczas gdy Google BigTable stawia na konsystencję.

Koncepcje i techniki opisane w tym rozdziale odbijają się echem w architekturach wielu z systemów opisanych w kolejnych częściach niniejszej pracy, dlatego przedstawienie ich tutaj ma za zadanie umożliwić czytelnikowi lepsze zrozumienie tych systemów i tego, na czym opierali się ich autorzy podczas ich projektowania.

\section{Teoria CAP}

Teoria CAP (\emph{Consistency, Availability, Partition Tolerance}) zwana również teorią Brewera od nazwiska jej autora została po raz pierwszy zaprezentowana podczas prezentacji profesora Uniwersytetu Berkley Eryka Brewera 19 czerwca 2000r. na konferencji \emph{ACM Symposium on the Principles of Distributed Computing} \cite{podc-keynote}. 
W około dwa lata później, w 2002 roku, teoria ta (pod nazwą \emph{Brewer's Conjecture} - Domysł Brewera) została formalnie udowodniona przez Nancy Lynch oraz Setha Gilberta z MIT \cite{brewers-conjecture}.

Teoria CAP powstała jako efekt doświadczeń Brewera w firmie Inktomi oraz jego prac badawczych nad systemami rozproszonymi na Uniwersytecie w Berkley. 
Mówi ona, że z trzech pożądanych właściwości systemu rozproszonego: Konsystencji (ang. \emph{Consistency}), Wysokiej Dostępności (ang. \emph{Availability}) oraz Odporności na Podział Sieci (ang. \emph{Partition Tolerance}) możliwe jest zapewnienie co najwyżej dwóch z nich \cite{browne-cap-theorem}.

\subsection*{Konsystencja}

Termin ,,Konsystencja'' w Teorii CAP ma nieco inne znaczenie niż w ACID, gdzie oznacza on, iż zapisywane dane nie mogą złamać pewnych określonych reguł integralności. 
W Teorii CAP \emph{Consistency} jest dużo bardziej zbliżone do \emph{Atomicity} z ACID, oznacza ono bowiem, że gdy dokonamy operacji zapisu $x=x_0$ każdy kolejny odczyt $x$, niezależnie do którego węzła byłby skierowany, zwróci wartość $x_0$.

\subsection*{Wysoka Dostępność}

Wysoka dostępność jest najbardziej pożądaną właściwością z trzech wymienionych.
Oznacza ona, jak sama nazwa wskazuje, że system powinien udostępniać swoje usługi w pełni przez cały czas, wliczając w to awarie poszczególnych węzłów, aktualizacje oprogramowania czy awarie sieci. 
Bardziej formalnie: jeżeli operacja dotrze do nie ulegającego właśnie awarii węzła, to w pewnym skończonym czasie zwróci wynik do klienta.
Warto przy tym zwrócić uwagę (za  \cite{brewers-conjecture}), że dostępność zawodzi najczęściej właśnie wtedy, gdy jest najbardziej potrzebna, czyli w okresach największego obciążenia systemu.

\subsection*{Odporność na Podział Sieci}

W systemach rozproszonych, działających na tysiącach węzłów, często rozsianych w centrach obliczeniowych na wielu kontynentach utrata połączenia pomiędzy grupami węzłów jest oczekiwanym, codziennym problemem.
Podział sieci, rozumiany tu właśnie jako utrata połączenia między dowolnymi dwoma lub więcej węzłami systemu, przy zachowaniu połączenia tych węzłów z klientem, może nastąpić z wielu powodów: awarie switchy lub routerów, utrata połączenia między centrami obliczeniowymi, dokonywane naprawy.
W przypadku kiedy węzeł lub ich grupa zostanie całkowicie odcięty od klientów i innych węzłów systemu, możemy traktować te węzły tak samo jak gdyby na przykład odcięto im nagle zasilanie, dlatego definicja podziału takiego przypadku nie obejmuje.

Dla przykładu wyobraźmy sobie bazę danych replikowaną w systemie master-master.
Jeżeli połączenie między węzłami zostanie zerwane, modyfikacje dokonane na jednym z nich nie będą widoczne na drugim. 
Z kolei w sytuacji gdy mamy bazę danych z horyzontalnym podziałem danych (ang. \emph{sharded}), ponieważ każdy z serwerów zawiera informacje dotyczące tylko części danych i z góry wiadomo do którego z nich należy się zwrócić aby otrzymać informacje dotyczące dowolnego klucza, nawet w przypadku utraty połączenia między nimi, o ile klient ma dostęp do obu serwerów, ciągłość dostarczanych usług jest zapewniona.

\subsection*{Znaczenie Teorii}

Teoria CAP nabiera znaczenia w miarę wzrostu wielkości systemu. 
Gdy dysponujemy bazą rozsianą na kilku maszynach, narzut czasowy replikacji danych pomiędzy nimi jest akceptowalny dla większości zastosowań, nie musimy się też zbytnio martwić o podział sieci, gdyż zazwyczaj jest tak, że maszyny zlokalizowane w jednej szafie (ang. \emph{rack}) będą albo działać wszystkie, albo żadna. 
Kiedy jednak zajmujemy się usługami rozproszonymi na tysiącach węzłów, nawet gdybyśmy dysponowali 10000 maszynami o niezawodności MTBF 30 lat, każdego dnia następowałaby awaria którejś z nich \cite{google-lessons}. 
W przypadku tak dużych systemów, czas jakiego wymaga replikacja danych aby doprowadzić aby każdy węzeł widział ten sam stan, czy to jak system reaguje na podziały sieci nabiera o wiele większego znaczenia.

\subsubsection*{Podział systemów}

Teoria CAP mówi, że nie możemy zapewnić równocześnie wszystkich trzech gwarancji, dlatego skalowalne systemy muszą porzucić jedną z nich. 
Ze względu na to dzielimy je na:

\begin{enumerate}
 \item \emph{CA} - (Consistent, Available) te systemy mają problemy z podziałem sieci, wymagając zazwyczaj aby operacje dotyczące poszczególnych transakcji trafiały do pojedynczej grupy węzłów, które podlegają awarii ,,atomowo'' - albo wszystkie działają, albo żaden. 
 To podejście zazwyczaj wiąże się z problemami dla skalowalności.
 \item \emph{AP} - (Available, Partition-Tolerant) te systemy zapewniają największą odporność na awarie wynikające z rozproszonego środowiska, jednocześnie jednak stawiając twórców aplikacji przed trudnym zadaniem radzenia sobie z problemami wynikającymi z niespójności danych widzianych przez klientów bazy.
 \item \emph{CP} - (Consistent, Partition-Tolerant) te systemy w wypadku podziału oczekują na przywrócenie połączenia, ograniczając w ten sposób dostępność.
\end{enumerate}

W praktyce systemy omawiane w tej pracy zazwyczaj zadowalają się częściowym zapewnieniem wszystkich wymienionych gwarancji, przy czym wysoka dostępność odgrywa główną rolę, a poświęcana jest albo odporność na podziały, albo konsystencja. 
Dlatego systemy te należą albo do grupy CP (Google BigTable, HBase), albo do grupy AP (Amazon Dynamo, Riak).

\section{BASE}

BASE (\emph{Basically Available, Soft state, Eventual consistency}) to model konsystencji, który jest przeciwstawiany modelowi ACID (\emph{Atomicity, Consistency, Isolation, Durability}). 
Oba te modele dotyczą baz danych, zatem oba wymagają aby operacje klienta były trwałe (\emph{Durability}).
Różnica między nimi bierze się z podejścia do konsystencji.
W ACID system zawsze musi być w spójnym stanie, a dokonanie zmiany może wymagać szeregu operacji które doprowadzą system do tego stanu.
Operacje te ponadto zostają objęte transakcją i zostają aplikowane albo wszystkie, albo żadna.
W BASE system może być w stanie niespójnym z punktu widzenia aplikacji, a operacje które mają przywrócić tą spójność są wykonywane asynchronicznie.

Producenci relacyjnych baz danych od dawna już byli świadomi potrzeby partycjonowania danych na wiele węzłów.
Aby zapewnić semantykę ACID w kontekście rozproszonych transakcji stosuje się technikę 2PC (ang. \emph{2 Phase Commit}).
Protokół 2PC działa dwustopniowo:

\begin{enumerate}
 \item Najpierw koordynator transakcji żąda od wszystkich węzłów biorących udział w operacji aby wstępnie dokonały operacji commit dla transakcji i potwierdziły możliwość wykonania tej operacji.
 Jeżeli wszystkie węzły dokonały tego potwierdzenia, przechodzi się do drugiego kroku.
 \item W drugim kroku koordynator żąda od wszystkich zainteresowanych węzłów dokonania operacji commit.
 Jeżeli którakolwiek z baz zawetuje tą operację, wszystkie muszą wycofać transakcję.
\end{enumerate}

Problem, na jaki napotykamy w tym podejściu, to ograniczenie dostępności systemu (A w CAP).
Wystarczy aby jeden z węzłów systemu podległ awarii, aby cały system stał się niedostępny dla zapisów.
Dostępność w kontekście transakcji staje się iloczynem dostępności poszczególnych węzłów systemu.
Jeżeli mamy zatem węzły o indywidualnej dostępności 99.9\% to transakcja, która obejmuje trzy z nich będzie miała dostępność ok. 99.7\% - czyli o ok. 90 minut mniejszy \emph{uptime} w skali miesiąca \cite{base-an-acid-alternative}.

Jeżeli zatem ACID oferuje nam poziom konsystencji, który można byłoby określić mianem Strong Consistency, ale kosztem dostępności, to BASE oferuje w zamian wysoką dostępność kosztem konsystencji. 

\section{Eventual Consistency}

Eventual Consistency (w wolnym tłumaczeniu: konsystencja po pewnym czasie, ostatecznie) to słaba forma gwarancji konsystencji, która gwarantuje jedynie, że po pewnym, możliwym do przewidzenia czasie od momentu wykonania operacji, jej efekty będą widziane przez klientów systemu, niezależnie od tego, do którego z węzłów systemu się zwrócą z zapytaniem.
Okno czasowe między operacją a propagacją jej efektów do wszystkich zainteresowanych węzłów w systemie nazywamy oknem niespójności (ang. \emph{inconsistency window}).

Choć początkowo może się wydawać, że tego typu model sprawia duże trudności w implementacji aplikacji korzystających z baz danych, które go zapewniają, w rzeczywistości tego typu interakcje napotykamy każdego dnia.
Kiedy w systemie bankowym dokonujemy przelewu z konta na konto, pieniądze znikają z bilansu jednego z nich, ale na drugim pojawiają się z pewnym opóźnieniem.
Innym przykładem może być system DNS, gdzie zmiana jest propagowana w systemie stopniowo, często oczekując na przeterminowanie cache, ale po jakimś czasie jest zauważalna u każdego klienta.

Artykuł \cite{vogels-eventually-consistent} wprowadza ponadto kilka rodzajów Eventual Consistency:

\begin{enumerate}
 \item \emph{Causal Consistency} - Jeżeli proces A wykonał jakąś operację, a następnie zakomunikował ten fakt procesowi B, to proces B będzie widział zmienione dane w taki sam sposób jak proces A, a jego zapisy nie będą wchodzić w konflikt z tą operacją.
 Proces C, któremu ta informacja nie została przekazana, będzie podlegał normalnym regułom.
 \item \emph{Read-your-writes Consistency} - Proces dokonujący operacji w kolejnych operacjach zawsze widzi rezultaty tej operacji.
 \item \emph{Session Consistency} - To praktyczna realizacja poprzedniego rodzaju konsystencji.
 W tym przypadku proces komunikuje się z systemem w kontekście sesji, w ramach której ma zapewnioną gwarancję odczytu swoich operacji.
 W przypadku awarii i konieczności nawiązania nowej sesji, gwarancje te nie przechodzą na nowo nawiązaną sesję.
 \item \emph{Monotonic Write Consistency} - W tym przypadku system gwarantuje, że operacje zostaną wykonane w tej samej kolejności, w jakiej żądania ich wykonania zostały wysłane.
 Systemy które nie oferują tej gwarancji są bardzo trudne w użyciu.
\end{enumerate}

\subsection*{Konfiguracja Eventual Consistency}

Werner Vogels w artykule o Eventual Consistency \cite{vogels-eventually-consistent} wprowadził nomenklaturę stosowaną w konfiguracji konsystencji wielu systemów NoSQL (np. Cassandra, Riak).
Konfigurację tą opisują zazwyczaj trzy liczby:

\begin{enumerate}
 \item \emph{N} - liczba węzłów systemu na które zostanie zreplikowany pojedynczy rekord.
 Liczba ta jest zazwyczaj określana jako parametr konfiguracji systemu, lub podczas wydawania polecenia utworzenia ``tabeli'' (nazwanego zbioru rekordów).
 Niektóre systemy pozwalają na zmianę tej wartości w trakcie działania systemu (np. Riak), ale większość wymaga ponownego uruchomienia aplikacji w celu zastosowania tej zmiany.
 \item \emph{R} - liczba węzłów systemu, które muszą dokonać odczytu zanim wartość zostanie zwrócona do klienta.
 Czasem wartości zwrócone przez poszczególne węzły będą różne.
 Wtedy system  odpowiada albo za rozwiązanie konfliktu, albo za przekazanie wielu wersji klientowi.
 Parametr R jest najczęściej określany z osobna dla każdego polecenia odczytu.
 \item \emph{W} - liczba węzłów systemu, które muszą potwierdzić zapis aby operacja została zakończyła się sukcesem.
 Podobnie jak R jest to parametr przekazywany dla każdego zapytania.
\end{enumerate}

Jeżeli $R+W>N$, to mamy do czynienia z silną konsystencją (ang. \emph{Strong Consistency}) - każdy odczyt zwróci ostatnią zapisaną wartość.
Jeżeli $W = 0$, to zapis jest dokonywany w pełni asynchronicznie.

\subsection*{Znaczenie}

Eventual Consistency opisuje problem dotykający każdej rozproszonej bazy danych, niezależnie od tego czy jest to baza relacyjna, sieciowy system plików czy baza NoSQL.
Tradycyjne podejście do konsystencji w kontekście replikacji jest ograniczające.
Systemy bazodanowe najczęściej implementują rozwiązanie typu wszystko-albo-nic: operacja zapisu musi się powieść na wszystkich węzłach albo zostać cofnięta.
Podejście takie nie tylko ogranicza dostępność systemu, powoduje ono także ograniczenie możliwości decyzyjnych autorów aplikacji korzystających z tych systemów.
Nawet jeżeli system umożliwia asynchroniczną replikację, zazwyczaj jest to bardzo prymitywny mechanizm, który nie bierze pod uwagę wersjonowania rekordów i sprowadza bazę do konfiguracji R=1, W=1.

Z drugiej strony systemy takie jak Amazon Dynamo pozwalają swoim użytkownikom na pełną dowolność w konfiguracji mechanizmów persystencji.
Nawet przy $R+W>N$ mamy możliwość sterowania zachowaniem systemu: czy zapisy powinny być szybsze kosztem odczytów, czy na odwrót, czy też może gdzieś pomiędzy.
Wiele z tych systemów zapewnia \emph{Read-your-writes Consistency} co stanowi dodatkowe ułatwienie.
Możliwość konfiguracji parametrów R, W i N stopniowo staje się standardem wśród systemów NoSQL obsługujących partycjonowanie danych.

\section{Google MapReduce}

Google MapReduce \cite{google-mapreduce} jest biblioteką wykorzystywaną do przetwarzania dużych zbiorów danych w środowisku rozproszonym.
Użytkownik biblioteki specyfikuje dwie funkcje nazywane \emph{map} i \emph{reduce} oraz kilka innych parametrów konfiguracyjnych.
Następnie biblioteka dba o to aby dane wejściowe zostały podzielone, na poszczególnych rekordach została wykonana funkcja \emph{map}, a jej wyniki zostały zagregowane przy pomocy funkcji \emph{reduce}.

Operacje \emph{map} i \emph{reduce} są powszechnie spotykane w językach funkcyjnych, takich jak na przykład LISP.
\emph{Map} na wejściu otrzymuje parę $(k, v): k \in K_1, v \in V_1$ a na wyjściu emituje listę par $(k, v): k \in K_2, v \in V_2$.
\emph{Reduce} na wejściu otrzymuje parę $(k, (v_1, ..., v_n)): k \in K_2, v_1...v_n \in V_2$ i na wyjściu emituje $v: v \in V_2$.

\subsection*{Przykład}

Poniżej przedstawiam przykładowy kod funkcji \emph{map} i \emph{reduce} w języku Python dla problemu zliczania wystąpień słów w zbiorze tekstów. 
Jak widzimy funkcja \emph{map} przyjmuje pary (klucz, wartość) z przestrzeni (Nazwy Dokumentów, Treść Dokumentów), zwracając pary z innej przestrzeni (Słowa, Liczby Naturalne).
Funkcja \emph{reduce} w przykładzie przyjmuje pary gdzie kluczem jest słowo, natomiast wartością jest lista liczb naturalnych określająca liczby wystąpień tego słowa w różnych dokumentach (albo wielokrotnie w tym samym dokumencie).

\begin{verbatim}
def map(document_name, document_value):
  """ funkcja mapujaca dokumenty na pary (slowo, 1)  """
  for word in words(document_value):
    yield (word, 1) # emit word

def reduce(word, counts):
  """ 
  funkcja redukujaca, przyjmuje slowo 
  i liste (iterator) po liczbie jego wystapien
  zwrace sumaryczna liczbe wystapien danego slowa
  """
  sum = 0
  for value in counts:
    sum += value
    # sum += 1
    # tak tez mozna byloby zapisac, 
    # ale wtedy funkcja nie bylaby laczna     
  return sum 
\end{verbatim}


\subsection*{Opis działania}

Użytkownik tworzy aplikację, w której specyfikuje dwie funkcje \emph{map} i \emph{reduce}, oraz dwa parametry konfiguracyjne: \emph{M} i \emph{R}:

\begin{itemize}
 \item \emph{M} - określa na ile części ma zostać podzielony plik wejściowy.
 Zazwyczaj wybiera się taką liczbę aby wielkość plików wejściowych zawierała się między 16MB a 64MB.
 Ponieważ GFS dzieli pliki na kawałki (ang. \emph{chunks}) wielkości 64MB, jest dość istotne aby pliki wejściowe nie przekraczały tej wielkości, gdyż w przeciwnym przypadku mogłaby występować konieczność komunikacji sieciowej w celu odczytania danych z pliku wejściowego.
 \emph{M} określa ponadto liczbę zadań \emph{map}.
 \item \emph{R} - określa liczbę zadań \emph{reduce}.
\end{itemize}

\myfigure{chapters/studium_literatury/map-reduce.png}{Google MapReduce}{fig:map-reduce}

\begin{enumerate}
 \item Biblioteka MapReduce dzieli plik wejściowy na \emph{M} części.
 \item Program użytkownika zostaje wysłany i uruchomiony na maszynach klastra.
 Jedna z tych maszyn przyjmuje specjalną rolę \emph{master}, pozostałe zaś mają rolę \emph{worker}.
 \item \emph{master} przypisuje poszczególnym \emph{workerom} po jednym zadaniu do wykonania.
 Kolejne są przydzielane w miarę jak węzły kończą przydzieloną im pracę.
 Zadanie \emph{map} zostanie przydzielone w pierwszej kolejności maszynie która jest równocześnie \emph{chunkserverem} przechowującym odpowiedni plik wejściowy.
 Pozwala to uniknąć komunikacji sieciowej w celu odczytania pliku.
 \item \emph{Worker} przetwarza plik wejściowy rekord po rekordzie wywołując funkcję \emph{map} i zapisując jej wynik w pamięci.
 \item Co pewien czas dane zapisane w pamięci są zrzucane na dysk do plików lokalnych.
 W tym procesie dane są rozdzielane do \emph{R} plików poprzez funkcję partycjonującą, domyślnie $hash(key) mod R$.
 Lokacje tych plików są przekazywane do węzła \emph{master}, który z kolei jest odpowiedzialny za przekazanie ich do węzła wykonującego operację \emph{reduce} na odpowiednim fragmencie danych.
 \item Węzeł wykonujący operację \emph{reduce} po otrzymaniu takiego powiadomienia pobiera odpowiednie pliki bezpośrednio od węzła, który je przechowuje.
 Po otrzymaniu wszystkich potrzebnych plików, \emph{worker} sortuje otrzymane dane po kluczu, tak aby wartości dla danego klucza sąsiadowały ze sobą w pliku.
 \item Po posortowaniu plików wejściowych węzeł iteruje po kluczach i dla każdego z nich przekazuje klucz oraz listę wszystkich przypisanych mu wartości do funkcji \emph{reduce}, zapisując następnie jej wynik w pliku wyjściowym.
 \item Kiedy wszystkie operacje \emph{reduce} zakończą się, \emph{master} budzi program użytkownika i wywołanie funkcji \emph{MapReduce} kończy się.
\end{enumerate}

Wynikiem operacji jest \emph{R} plików wynikowych.
W większości przypadków konsumentem tych danych są inne operacje MapReduce, bądź aplikacje rozproszone, więc nie ma potrzeby łączenia tych plików w jedną całość.

\subsection*{Optymalizacje}

W artykule \cite{google-mapreduce} zostało opisanych kilka istotnych optymalizacji i ulepszeń:

\begin{enumerate}
 \item Operacja \emph{map} na pliku wejściowym jest wykonywana na tym samym serwerze, który przechowuje ten plik.
 \item Operacja \emph{map} może zwrócić bardzo wiele wartości dla danego klucza pośredniego.
 Z tego względu biblioteka wprowadza pojęcie funkcji łączącej (ang. \emph{combiner}).
 Funkcja ta dokonuje wstępnej redukcji przed wysłaniem wartości przez sieć do węzła wykonującego operację \emph{reduce}.
 Najczęściej stosuje się w tym miejscu tą samą funkcję co w operacji \emph{reduce}, ale aby to było możliwe, funkcja ta musi być łączna i przemienna, co czasem wymaga wprowadzenia pewnych zmian.
 Dla przykładu: przedstawiona wcześniej funkcja map emitująca wszystkie słowa w danym dokumencie emituje powtarzające się słowa wielokrotnie.
 Poprzez zsumowanie wystąpień przed przesłaniem znacznie zmniejszamy ilość danych do wysłania.
 \item Funkcja partycjonująca może być wyspecyfikowana przez użytkownika, dzięki czemu potencjalnie możliwe jest takie jej określenie, aby dane powiązane ze sobą znalazły się w jednym pliku wynikowym (aczkolwiek kosztem ryzyka nierównomiernego podziału kluczy między partycje).
 \item Dzięki sortowaniu kluczy pośrednich, pliki wynikowe są łatwiejsze do przetwarzania, umożliwiając na przykład wyszukiwanie binarne.
 \item Kiedy zbliża się koniec operacji, zadania \emph{reduce} są zlecane do wykonania przez dodatkowe węzły.
 Dzięki temu uszkodzone, nadmiernie obciążone przez inne procesy albo wadliwie skonfigurowane maszyny nie powodują nadmiernego wydłużenia całości operacji MapReduce.
\end{enumerate}

\subsection*{Odporność na awarie}

Ponieważ biblioteka MapReduce służy do wykonywania operacji w rozproszonym środowisku, często nawet na tysiącach węzłów, konieczne jest aby była ona odporna na awarie części z węzłów.
Rozróżniamy dwa typy awarii: awaria węzła \emph{master} i awarie węzłów typu \emph{worker}.

\subsubsection*{Awaria węzła master}

Ponieważ \emph{master} przechowuje między innymi informacje o zrealizowanych zadaniach i lokalizacji plików wynikowych.
\emph{Master} musi działać aby operacja MapReduce się zakończyła powodzeniem, ale możliwe jest aby jego struktury danych były zapisywane w GFS, albo replikowane do zapasowego węzła.
W opisanym systemie awaria węzła master zawsze kończy się niepowodzeniem całości operacji MapReduce i koniecznością jej ponownego uruchomienia.
Jest to dopuszczalne ponieważ czas trwania operacji jest liczony w minutach, więc awaria tego konkretnego węzła jest mało prawdopodobna (w odróżnieniu od np. BigTable, który jest systemem, który działa bez przerwy).

\subsubsection*{Awaria węzła slave}

\emph{Master} regularnie komunikuje się z węzłami \emph{slave} w celu ustalenia ich stanu.
W przypadku gdy węzeł przestaje odpowiadać jest uznawany za ,,martwy'', w związku z czym \emph{master} oznacza zadanie aktualnie przez niego wykonywane jako przeznaczone to przydziału, tak samo wszystkie wykonane przez niego zadania \emph{map}.
Zadania \emph{map} muszą być wykonane ponownie, ponieważ ich wyniki zostały zapisane w lokalnych plikach i przez to są niedostępne do odczytu.
Zadania \emph{reduce} zapisują swoje wyniki w GFS, w związku z tym nie muszą być powtarzane. 

\subsection*{Znaczenie}

Większość systemów opisanych w niniejszej pracy nie dysponuje zaawansowanymi metodami wykonywania zapytań, a w szczególności zapytań agregujących czy zliczających takich jak funkcje COUNT, SUM, AVG i operator GROUP BY w relacyjnych bazach danych.
Operacje tego typu są szczególnie trudne w kontekście systemów rozproszonych, gdzie wykonanie zapytań tego typu w trybie on-line przy zachowaniu odpowiedniego czasu odpowiedzi jest często wręcz niemożliwe.
Dlatego najczęściej wykonywanie tego typu operacji jest dokonywane co pewien czas, lub zlecane przy zapisie danych, a jego wyniki są przechowywane w systemie.

W przeważającej większości obliczenia te są wykonywane przy zastosowaniu algorytmu MapReduce.
Wiele systemów, tak jak MongoDB czy Riak, zapewnia taką funkcjonalność, inne wymagają zastosowania zewnętrznych narzędzi.
Wierną implementacją Google MapReduce jest Hadoop, który opiszemy nieco bliżej przy okazji HBase.
Bardzo ciekawe podejście do MapReduce prezentuje CouchDB, która przechowuje wyniki funkcji map, dzięki czemu umożliwia dokonywanie zapytań opartych o MapReduce w trybie on-line.
CouchDB zostanie opisane bliżej w kolejnym rozdziale.

Algorytm MapReduce ma duże znaczenie w systemach NoSQL, gdyż stanowi surogat dla wykonywania skomplikowanych zapytań.
Stanowi on jedno z podstawowych narzędzi dla praktyki prostych odczytów, ale złożonych zapisów.

\section{Amazon Dynamo}

Amazon Dynamo to baza typu klucz-wartość używana w największym na świecie sklepie internetowym \emph{amazon.com}.
Baza została opisana w artykule z 2007 roku \cite{amazon-dynamo} i od tego czasu opisany w nim system doczekał się już dwóch implementacji open-source: Dynomite i Riak, oraz stał się inspiracją dla innych baz takich jak Cassandra, czy rozszerzenia CouchDB pozwalającego na rozpraszanie tej bazy.

Amazon Dynamo skaluje się bardzo dobrze - do setek węzłów, co dzięki zastosowaniu architektury opartej na usługach w zupełności wystarcza nawet takiemu gigantowi jak Amazon.
Interesującym aspektem architektury tego sklepu internetowego jest to, że poszczególne usługi muszą oferować gwarancje na czas wykonania (ang. \emph{Service Level Agreements}).
Przykładowym kontraktem tego typu jest gwarancja, że usługa zwróci odpowiedź w ciągu 300ms dla 99,9\% zapytań przy obciążeniu 500 zapytań na sekundę.
Konsekwencją istnienia takich gwarancji jest to, że Dynamo musi udostępniać wiele możliwości konfiguracji, tak aby usługi mogły dostosować właściwości bazy na potrzeby oferowanego kontraktu.

Jednym z wymagań dla systemu obsługującego sklep internetowy jest to aby użytkownik był w stanie zawsze dodać przedmioty do koszyka czy złożyć zamówienie.
W związku z tym Amazon Dynamo jest systemem w którym dostępność (A w CAP) odgrywa kluczową rolę, a odporność na podział sieci (P w CAP) jest jej uzupełnieniem.
Wydawało by się, że konsystencja ma duże znaczenie w przypadku sklepu internetowego - nie można przecież sprzedać towaru, którego się nie ma, a przecież w przypadku sklepu z którego korzystają miliony użytkowników równocześnie warunki wyścigu (ang. \emph{race conditions}) muszą występować nagminnie.
W amazon.com dopuszczalne jest aby dwóch klientów zamówiło ostatnią z książek w magazynie, a kiedy okaże się że jeden z nich jej nie może otrzymać sklep kontaktuje się z nim proponując na przykład dłuższy okres dostawy.
Nawet jeżeli nie wszyscy użytkownicy się zgodzą z taką sytuacją, to i tak przekłada się to na wyższe przychody.
Pokazuje to jak Eventual Consistency może z powodzeniem być stosowane w sytuacjach, gdzie normalnie kładzie się duży nacisk na spójność danych, nie powodując przy tym ujmy dla systemu.

\subsection*{Główne założenia architektury}

Autorzy Amazon Dynamo określili takie założenia co do architektury:

\begin{itemize}
 \item system jest zawsze w stanie przyjąć operację zapisu
 \item w związku z replikacją danych i naciskiem na wysoką dostępność, w systemie może wystąpić wiele wersji rekordu
 \item rozwiązywanie konfliktów między wersjami następuje przy odczycie i jest dokonywane przez aplikację, nie przez bazę (ale aplikacja może z tego zrezygnować i wybrać prosty mechanizm, np. ostatni zapis wygrywa)
 \item system musi się łatwo skalować wszerz poprzez dodawanie kolejnych węzłów i nie powinno to mieć dużego wpływu ani na administrację systemem ani na sam system
 \item system musi się charakteryzować symetrią: każdy węzeł ma taki sam zestaw obowiązków jak wszystkie inne
 \item system musi być zdecentralizowany: żaden węzeł nie jest wyróżniony i wszelkie operacje są wykonywane korzystając z mechanizmów \emph{peer-to-peer}
 \item system musi radzić sobie z heterogenicznością środowiska: narzut pracy na pojedynczy węzeł powinien uwzględniać jego możliwości w porównaniu do innych węzłów
\end{itemize}

\subsection*{Stosowane techniki}

Amazon Dynamo łączy w sobie wiele ciekawych technik rozwiązujących problemy takie jak partycjonowanie, wersjonowanie rekordów czy wykrywanie awarii.
W niniejszym rozdziale postaram się je czytelnikowi przybliżyć.

\subsubsection*{Partycjonowanie - Consistent Hashing} 

W systemie takim jak Dynamo, który ma za zadanie skalować się do setek węzłów, horyzontalne partycjonowanie jest nieuniknione.
W Amazon Dynamo za podział na partycje odpowiada zmodyfikowany algorytm Consistent Hashing.
W następnych kilku paragrafach opiszę najpierw podstawowy algorytm, a następnie kolejne jego modyfikacje.

Consistent Hashing to algorytm który dla dowolnego klucza określa który węzeł systemu go przechowuje.
Ponieważ klucze są dowolnymi ciągami bajtów, zawsze operując na nich używamy funkcji mieszającej (ang. \emph{hashing function}).
Przeciwdziedzinę tej funkcji mieszającej traktujemy jako pierścień gdzie najmniejsza i największa możliwa wartość niejako stykają się ze sobą, podobnie jak ma to na przykład miejsce w przypadku długości geograficznych czy godzin na tarczy zegara.
W podstawowej wersji systemu każdy węzeł systemu losuje jedną wartość na tym pierścieniu.
Aby określić któremu węzłowi odpowiada dany klucz, obliczamy dla niego wartość funkcji mieszającej, a następnie znajdujemy węzeł, którego ,,pozycja'' na pierścieniu jest najbliższą zgodnie z ruchem wskazówek zegara po wartości wyliczonej.
W takim schemacie każdemu węzłowi odpowiada jeden, ciągły fragment pierścienia (patrz rysunek \ref{fig:consistent-hashing-01}).

\myfigure{chapters/studium_literatury/consistent-hashing-01.png}{Podstawowe Consistent Hashing}{fig:consistent-hashing-01}

Podstawowy wariant algorytmu ma wiele wad.
Problemem jest na przykład potencjalnie bardzo nierównomierna dystrybucja kluczy między węzłami.
Nie ma też żadnego wsparcia dla heterogeniczności środowiska - nie możemy ,,mocniejszemu'' serwerowi przekazać większego zakresu kluczy.
W związku z tymi ograniczeniami, wprowadza się tak zwane ,,wirtualne węzły'': pojedynczemu fizycznemu węzłowi przypisuje się wiele pozycji na pierścieniu (zazwyczaj liczba tych pozycji jest znacznie większa od ogólnej liczby węzłów).
Dzięki tej modyfikacji (o ile liczba wirtualnych węzłów jest wystarczająco duża) dystrybucja kluczy będzie znacznie bardziej sprawiedliwa, możemy też kontrolować obciążenie poszczególnych węzłów poprzez przyporządkowanie im mniejszej lub większej liczby pozycji na pierścieniu (patrz rysunek \ref{fig:consistent-hashing-02}).

\myfigure{chapters/studium_literatury/consistent-hashing-02.png}{Consistent Hashing z wirtualnymi węzłami}{fig:consistent-hashing-02}

Opisana powyżej wersja algorytmu radzi sobie zbyt dobrze z dodawaniem i usuwaniem węzłów niż wersja podstawowa, jednak w rzeczywistości nie sprawdza się zbyt dobrze.
Przy dodaniu węzła do systemu, klucze znajdujące się do tej pory pod opieką innych węzłów muszą być przekazane nowemu węzłowi.
Aby tego dokonać, konieczne jest dokonanie przeglądu wszystkich kluczy w dzielonym zakresie, konieczne jest także przeliczenie na nowo i synchronizacja drzew Merkle (vide \emph{Merkel Trees} na stronie \pageref{merkle-trees}). 
Przegląd taki obciąża system i musi być dokonywany w tle aby nie złamać gwarancji dawanych przez korzystającą z Dynamo usługę.
Aby uniknąć tego problemu należy rozdzielić mechanizm partycjonowania danych (w jaki sposób są tworzone przedziały) od tego które węzły nimi zarządzają.

W tym wariancie algorytmu przestrzeń kluczy zostaje podzielona z góry na określoną liczbę przedziałów S.
Najczęściej liczba ta będzie znacznie większa niż liczba węzłów systemu N ($S >> N$).
Następnie każdy z przedziałów przydzielamy losowo jednemu z węzłów tak aby każdy miał ich po $S/N$\footnote{oczywiście ten mechanizm może być dostosowany do wymagania heterogeniczności, tak aby jedne węzły otrzymywały więcej przedziałów niż inne}.
Dzięki temu rekordy przynależące do różnych z przedziałów mogą być przechowywane w odrębnych plikach, które z kolei mogą być przesyłane w ramach potrzeby do przejmujących nad przedziałem kontrolę węzłów bez zbędnego przeglądania danych na dysku.
Rysunek \ref{fig:consistent-hashing-03} przedstawia opisaną powyżej wersję algorytmu.

\myfigure{chapters/studium_literatury/consistent-hashing-03.png}{Consistent Hashing z rozdziałem partycjonowania i pozycjonowania rekordów}{fig:consistent-hashing-03}

\subsubsection*{Replikacja}

Mechanizm opisany w poprzednim rozdziale przydziela przedziałów kluczy do węzłów, które są \emph{koordynatorami} tych przedziałów.
Oczywiście nie wystarcza aby każdy przedział był zapisany tylko na dysku koordynatora - awaria pojedynczego węzła powodowałaby wtedy (potencjalnie nieodwracalne) straty danych, a przynajmniej ich czasową niedostępność.
W Amazon Dynamo dane są replikowane do N fizycznych węzłów, gdzie N\footnote{
Uważny czytelnik zwróci uwagę na to, że ta sama nomenklatura była wykorzystana w artykule o Eventual Consistency.
W rzeczy samej, autor tego artykułu Werner Vogels (CTO amazon.com) figuruje na także na liście autorów artykułu o Amazon Dynamo.
Obie prace są ze sobą blisko związane i dobrze uzupełniają się.
}
jest parametrem określanym w konfiguracji bazy.
Najczęściej stosowaną wartością N jest 3.

Klucze są zapisywane na dysku koordynatora, oraz na dyskach N-1 kolejnych węzłów.
Kolejne węzły to węzły, które są koordynatorami kolejnych w kierunku ruchu wskazówek zegara przedziałów pierścienia.
Ponieważ może zajść sytuacja, że koordynatorem kolejnych przedziałów jest ten sam węzeł, poruszamy się wzdłuż pierścienia aż znajdziemy N różnych węzłów.
Lista węzłów odpowiedzialnych za przechowywanie klucza jest nazywana \emph{listą preferencyjną}.
Lista ta zazwyczaj zawiera więcej niż N adresów, na wypadek awarii jednego lub więcej z N podstawowych węzłów.

\subsubsection*{Wersjonowanie - Zegary Wektorowe}

Amazon Dynamo jest systemem, w którym dane są replikowane asynchronicznie i który zachowuje dostępność nawet w wypadku podziałów sieci, czy awarii poszczególnych węzłów.
Konsekwencją tego podejścia jest możliwość występowania wielu wersji rekordu równocześnie w systemie, a w przypadku długotrwałych podziałów sieci możliwe jest nawet istnienie równoległych ,,drzew historii'' dla tego rekordu.

Podobnie jak wcześniej i tu widzimy wyraźny wpływ tego, jak wymagania biznesowe wpłynęły na wybór algorytmów i architektury Dynamo.
Jednym z rozdzajów danych które są przechowywane w tym systemie jest koszyk użytkownika.
Ze względów finansowych jest istotne aby użytkownik nie tylko mógł zawsze dodać nowe przedmioty do swojego koszyka, ale także aby informacja o dodaniu tych przedmiotów nigdy nie została utracona.
Gdyby zatem do wersjonowania rekordów w systemie użyto znaczników czasowych, nie byłoby możliwe określenie logicznej kolejności modyfikacji danego rekordu.
Wykorzystanie startegii ,,nowszy wygrywa'' do rozwiązywania ewentualnych konfliktów mogłoby grozić utratą zamówień z koszyka, a zatem negatywnymi konsekwencjami finansowymi dla firmy.

Autorzy Amazon Dynamo zdecydowali się na wykorzystanie mechanizmu nazywanego zegarami wektorowymi (ang. \emph{vector clocks}).
Zegar wektorowy jest to zbiór par, gdzie pierwszym elementem pary jest identyfikator węzła\footnote{Riak, opisany w rozdziale \ref{sec:riak}, używa identyfikatorów klientów jako pierwszych elementów pary. Użycie identyfikatorów serwerów wiąże się bowiem z ryzykiem utraty danych. Problem ten jest opisany bliżej w \cite{basho-vector-clocks-hard}.}, a drugim elementem jest liczba naturalna.
Przy każdej modyfikacji rekordu serwer dokonujący tej modyfikacji zwiększa o 1 liczbę przypisaną do swojego identyfikatora w zegarze wektorowym (albo wpisuje swój identyfikator z wartością 1, jeżeli go wcześniej nie było).
Jeżeli wszystkie elementy zegara A mają wszystkie wartości odpowiednich elementów mniejsze bądź równe wartościom wektora B, to mówimy że A jest przodkiem wektora B i w przypadku napotkania takich dwóch wersji B zastępuje A.
Jeżeli natomiast ani A nie jest przodkiem B ani vice versa, to mówimy że te dwie wersje rekordu znajdują się w konflikcie, który z kolei musi zostać rozwiązany przez aplikację (klienta).

Zegar wektorowy rekordu o długim czasie życia w systemie może osiągnąć potencjalnie nieograniczoną długość.
Aby temu zapobiec do pary identyfikator węzła-liczba, dodaje się jeszcze trzeci element: znacznik czasu (ang. \emph{timestamp}), który zapisuje kiedy ostatni raz dany węzeł modyfikował wartość rekordu.
Długość zegara można dzięki temu kontrolować poprzez usuwanie najstarszych elementów, kiedy długość zegara przekroczy pewien próg (10 dla Dynamo).
Teoretycznie utrata tych informacji grozi wystąpieniem konieczności rozwiązywania konfliktów między wersjami które w rzeczywistości są w relacji następstwa, ale zdarzenie takie jest wysoce nieprawdopodobne i nie wiąże się z dużymi trudnościami dla aplikacji.

Bardzo dobry opis zegarów wektorowych czytelnik może znaleźć w artykułach na blogu firmy Basho, która to firma zajmuje się rozwojem bazy Riak: \cite{basho-vector-clocks-easy} opisuje tą technikę z punktu widzenia klienta, zaś \cite{basho-vector-clocks-hard} opisuje ją z punktu widzenia implementacji serwera.

\subsubsection*{Operacje odczytu i zapisu}

Jako baza typu klucz-wartość, Amazon Dynamo udostępnia użytkownikowi dwie podstawowe operacje: \emph{put} i \emph{get}.
Operacja \emph{get} przyjmuje między innymi parametr R, określający minimalną liczbę węzłów które muszą dokonać operacji odczytu aby zakończyła się ona sukcesem.
Operacja \emph{set} jako jeden z parametrów przyjmuje z kolei wartość W, określającą ile węzłów musi potwierdzić zapis wartości aby operacja się powiodła.

Amazon Dynamo używa protokołu HTTP w komunikacji między klientem i serwerem.
Zaletą tego podejścia jest brak konieczności linkowania aplikacji z kodem służącym do komunikacji z Amazon Dynamo, wadą jednak jest to, że klient który traktuje bazę jako ,,czarną skrzynkę'' jest wolniejszy.
Jeżeli klient nie jest świadomy istnienia list preferencyjnych i informacji w nich zawartych, operacja odczytu przebiega następująco: 
\begin{enumerate}
 \item Klient wysyła zapytanie, które jest obsługiwane przez \emph{load balancer}.
 \item \emph{Load balancer} może wybrać węzeł, do którego ma przekazać zapytanie, albo poprzez inspekcję przekazywanego zapytania i wybór węzła na podstawie listy preferencyjnej, albo losowo z pośród wszystkich węzłów systemu.
 \item Jeżeli węzeł, do którego trafiło polecenie zapisu nie znajduje się na jednym z N pierwszych miejsc listy preferencyjnej, przekazuje on zapytanie dalej do pierwszego, nie podlegającego aktualnie awarii węzła na tej liście.
 Nie dzieje się tak w przypadku poleceń odczytu, które mogą być koordynowane przez dowolny węzeł, gdyż nie muszą modyfikować zegarów wektorowych powiązanych z rekordami.
 \item Węzeł ten wykonuje żądaną operację, oraz przekazuje ją do wykonania do N-1 innych węzłów znajdujących się na szczycie listy preferencyjnej.
 \item Kiedy węzeł otrzyma potwierdzenie od $R-1$ bądź $W-1$ z tych węzłów, operacja kończy się powodzeniem.
 Jeżeli w systemie występują wersje rekordu, które znajdują się w konflikcie, wszystkie one zostaną przekazane do klienta.
 Nieaktualne wersje rekordów zostaną wykryte i automatycznie uaktualnione w sposób przeźroczysty dla klienta.
\end{enumerate}

Jak widać w powyższym schemacie, klient znający listy preferencyjne systemu jest w stanie całkowicie pominąć \emph{load balancer} i ewentualne przekazanie zapytania do jednego z węzłów na liście preferencyjnej klucza. 
W przypadku gdy Dynamo posługuje się znacznikami czasu do wersjonowania rekordów, klient może przejąć na siebie także obowiązki koordynatora zapytań.
W przypadku wykorzystania zegarów wektorowych nie jest to możliwe, gdyż w zegarze wektorowym w Dynamo jest zapisywany identyfikator węzła systemu, nie klienta (tak jak to ma miejsce w Riak).
Koordynacja zapytań przez klienta zmniejsza opóźnienia (ang. \emph{latency}) w systemie o ponad połowę, zarówno dla wartości średnich, jak i dla 99.9\% zapytań.

\subsubsection*{Obsługa awarii - Hinted Handoff}

W poprzednich rozdziałach opisane zostały listy preferencyjne oraz mechanizm koordynacji operacji zapisu i odczytu.
Przypomnijmy, że Amazon Dynamo na liście preferencyjnej zawiera więcej węzłów, niż liczba N podana przez użytkownika, a w razie awarii części węzłów przechowujących dany zakres kluczy, klient będzie kierował swoje zapytania do węzłów znajdujących się dalej na liście preferencyjnej, pomijając te, które uległy awarii.
Informacja o tym, że rekord miał trafić do innego węzła, ale ze względu na jego awarię trafił do węzła aktualnego jest zapisywana w metadanych tego rekordu.
Rekordy takie są przechowywane osobno od reszty rekordów i regularnie jest dokonywane sprawdzenie, czy można już taki rekord przekazać do węzła, na który miał on trafić oryginalnie.
Technikę tę nazywamy \emph{Hinted Handoff}, czyli w wolnym tłumaczeniu przekazywanie z sugestiami.
W Amazon Dynamo operacje dołączenia, czy usunięcia fizycznego węzła są jawne, stąd też przyjmujemy że węzły stają się niedostępne jedynie tymczasowo, w przypadku permanentnej awarii węzeł powinien zostać jawnie usunięty.

\subsubsection*{Wykrywanie różnic - Merkle Trees}
\label{merkle-trees}

W Amazon Dynamo każdy węzeł jest odpowiedzialny za przechowywanie pewnej liczby zakresów kluczy.
Węzły odpowiedzialne za określony zakres kluczy nazywamy jego replikami.
Repliki mogą zawierać różne wersje rekordów i aby zmniejszyć ryzyko utraty danych należy co jakiś czas dokonywać synchronizacji danych między nimi.
W tym celu stosuje się drzewa Merkle (ang. \emph{Merkle Trees}).
Drzewo takie jako liście posiada sumy kontrolne wartości dla wszystkich kluczy danego przedziału, wszystkie pozostałe węzły drzewa zawierają sumę kontrolną ze swoich dzieci.
Dzięki temu, że dwa drzewa o tej samej wartości w korzeniu są identyczne, możliwe jest porównanie zakresów kluczy przechowywane przez różne repliki w bardzo efektywny sposób, znacznie ograniczając ilość danych do przesłania.

\subsubsection*{Optymalizacje}

Podobnie jak wiele innych wysokowydajnych baz danych\footnote{MongoDB, Riak, Redis}, w celu zmniejszenia opóźnień w Amazon Dynamo zapisy mogą być przechowywane tymczasowo w pamięci i zrzucane na dysk w tle co jakiś czas.
Aby zapewnić trwałość danych Dynamo dba o to aby przynajmniej jeden węzeł z N zapisywał dane od razu na dysku.
Ponieważ jednak W jest zazwyczaj mniejsze od N, nie zmniejsza to szybkości działania.

Inną wartą uwagi optymalizacją, jest taka konstrukcja list preferencyjnych aby każdy zakres kluczy był przechowywany na węzłach znajdujących się w co najmniej dwóch centrach danych.
Dzięki temu w razie awarii całego centrum danych system jest w stanie zachować dostępność.

\subsection*{Znaczenie}

Amazon Dynamo jest bardzo ciekawym przykładem rozproszonego systemu bazodanowego.
Jest jednym z nielicznych systemów, w których wszystkie węzły są sobie równe.
Jest też warty uwagi ze względu na niezwykle wysokie gwarancje dostępności jakie oferuje i jakie ma to konsekwencje dla konsystencji.
Dynamo doczekało się naśladowców w postaci baz Riak i Dynomite, oraz zainspirowała twórców Apache Cassandra i programistów firmy Cloudant tworzących rozproszoną wersję CouchDB.
Artykuł ,,Dynamo: amazon's highly available key-value store'' \cite{amazon-dynamo} jest ponadto jednym z najciekawszych i najbardziej przystępnych artykułów dotyczących zagadnień związanych ze skalowalnymi bazami danych znanych autorowi tej pracy i warty polecenia wszystkim osobom zainteresowanym ruchem NoSQL.

\section{Google BigTable}

Google BigTable to podstawowa baza danych używana przez firmę Google.
Opisana została w artykule z 2006 roku pod tytułem ,,BigTable: A Distributed Storage System for Structured Data'' \cite{google-bigtable}.
Baza ta stała się inspiracją dla systemów takich jak Apache Cassandra, które zawdzięcza BigTable model danych, HBase, które jest dla BigTable tym, czym dla Dynamo jest Riak, czy też MongoDB, które stosuje mechanizm partycjonowania i replikacji podobny do bazy Google.

Google BigTable skaluje się bardzo dobrze: do tysięcy serwerów i petabajtów danych.
Podobnie jak Amazon Dynamo został stworzony z myślą o uruchamianiu go na klastrze maszyn średniej klasy.
Podstawową różnicą między BigTable a Dynamo jest natomiast podejście do konsystencji.
Baza firmy Amazon jest w stanie przyjąć zapis w każdej niemal sytuacji, przypłacając to kosztem tego, że aplikacja musi radzić sobie z wieloma wersjami rekordu, które mogą równocześnie występować w systemie.
BigTable gwarantuje konsystencję (w sensie CAP), ale kosztem opóźnień (wybór węzła \emph{master}, przekazanie roli serwera \emph{tabletów}, replikacja na poziomie GFS) oraz zmniejszonej odporności na podział sieci.

BigTable opiera się bardzo mocno na dwóch innych systemach: Google File System (GFS) oraz Google Chubby.
W kolejnych sekcjach zostaną one pokrótce opisane aby ułatwić czytelnikowi zrozumienie architektury tej bazy i jaką te systemy pełnią w niej rolę.

\subsection*{Google File System}

Google File System opisany w artykule \cite{google-file-system} jest rozproszonym systemem plików, który jest zoptymalizowany pod duże pliki, najczęściej aktualizowane przez dopisywanie na koniec (ang. \emph{append-only files}), ale umożliwia także przechowywanie małych plików i losowy dostęp.
Wszystkie pliki w GFS dzielone są na fragmenty rozmiaru 64MB (ang. \emph{chunk}).
Każdy fragment jest replikowany na kilka (najczęściej 3) maszyn, z których jedna przyjmuje rolę głównej repliki.
Jeden z węzłów jest wyróżniony i przyjmuje rolę \emph{master}.
\emph{Master} przechowuje metadane o systemie plików, oraz o podziale plików na fragmenty.
Informacja o lokalizacji fragmentów nie jest zapisywana trwale przez węzeł \emph{master} ale budowana po wyborze \emph{mastera} i uaktualniana w miarę potrzeby.
Dane \emph{mastera} są replikowane na kilka maszyn aby zapobiec ich utracie.
Wyboru \emph{mastera} dokonuje się wykorzystując usługę Google Chubby, podobnie jak ma to miejsce w BigTable.

\emph{Master} przyznaje dla każdego fragmentu jednej z jogo replik dzierżawę (trwającą 60s), która sprawia, że węzeł ten staje się wyróżniony dla tej repliki i zajmuje się koordynacją zapisów.
Klienci komunikują się z \emph{masterem} w celu zdobycia dostępu do metadanych systemu (lokalizacja fragmentów, system plików).
Operacje zapisu i odczytu nie wymagają zazwyczaj komunikacji z węzłem \emph{master}, pod warunkiem oczywiście, że klient ma zapisane lokalizacje fragmentów.

Poza typowymi operacjami na plikach, GFS udostępnia operację dodania ,,rekordu'' na koniec pliku.
Rekord taki jest dodawany atomowo, ale może wystąpić w pliku więcej niż raz, a poszczególne rekordy mogą być rozdzielone obszarami zawierającymi nic nie znaczące śmieci.

Zapis na koniec pliku w GFS przebiega w następujący sposób: 
\begin{enumerate}
 \item Najpierw klient przesyła dane do najbliższej\footnote{adresy IP serwerów pozwalają na określenie ,,odległości'' między nimi, gdyż są ściśle związane z topologią sieci} z replik.
 \item Replika ta przekazuje dane dalej w ten sam sposób i jest to powtarzane, aż wszystkie serwery otrzymają dane.
 \item Klient jest powiadamiany o zakończeniu transferu.
 \item Klient wysyła do wyróżnionej repliki żądanie zapisu.
 \item Wyróżniona replika definiuje kolejność zapisów (szereguje je) i zleca je pozostałym.
 \item Operacja kończy się sukcesem tylko jeżeli wszystkie repliki zapiszą poprawnie rekord.
 W przeciwnym razie błąd jest zgłaszany do użytkownika, ale ponieważ zapis mógł się powieść na niektórych replikach, rekord może występować w pliku więcej niż raz.
\end{enumerate}

BigTable wykorzystuje GFS do przechowywania tabletów, których dane zapisywane są w dwóch rodzajach plików: plikach typu SSTable, oraz dzienniku operacji (ang. \emph{tablet log}).
Żaden z powyższych rodzajów plików nie wymaga losowego dostępu dla zapisów - pliki SSTable są zapisywane raz, w całości, zaś dziennik tabletu jest zapisywany poprzez dodawanie rekordów na koniec.

W momencie pisania tych słów w użyciu jest już nowa wersja GFS -- GFS2, zaprojektowana z myślą o BigTable i zastosowaniach gdzie nawet kilkunastosekundowe opóźnienia spowodowane wyborem nowego mastera są niedopuszczalne.
Nowa wersja GFS zmniejsza znacznie rozmiar fragmentu pliku, z 64MB do 1MB oraz opiera się na architekturze opartej na wielu serwerach master i partycjonowaniu metadanych systemu plików.
Niestety dokładny opis tej architektury nie jest jeszcze dostępny.

\subsection*{Google Chubby}

Google Chubby jest to rozproszony system plików, ale o zastosowaniu zupełnie innym niż GFS.
Pliki w Chubbym są małe (limit 256kb), odczytywane i zapisywane atomowo, w całości.
Chubby jest to także (a właściwie przede wszystkim) rozproszony system blokad (ang. \emph{distributed lock service}).
Umożliwia on zakładanie blokad do odczytu i zapisu na plikach, mechanizm zdarzeń, oraz mechanizm cacheowania, który umożliwia automatyczne odświeżenie buforowanych wartości po wystąpieniu zmian.
Google Chubby został dokładniej opisany w artykule z 2006 roku \cite{google-chubby}.

Połączenie wyżej wymienionych funkcjonalności sprawia, że Chubby jest powszechnie używany jako serwer nazw, lepszy niż serwery DNS gdyż nie wymagający konfigurowania wartości TTL (ang. \emph{Time-To-Live}), która źle ustawiona może doprowadzić albo do nadmiernego obciążenia serwerów nazw, albo zbyt wolną propagację zmian wartości.

Innym bardzo ważnym zastosowaniem Google Chubby jest wybór wyróżnionego serwera (np. serwera \emph{master}).
Problem wyboru mastera jest problemem rozproszonego konsensu implementowany zazwyczaj przy pomocy algorytmu Paxos.
Zastosowanie usługi takiej jak Chubby nie tylko znacznie upraszcza ten problem, ale także pozwala na dokonanie wyboru nawet w sytuacji, gdy nie da się osiągnąć kworum (ze względu na awarie węzłów, czy podział sieci).

Procedura wyboru wyróżnionego serwera w Chubby przebiega następująco:

\begin{enumerate}
 \item Wszystkie zainteresowane węzły próbują otworzyć określony plik (np. /ls/foo/master) z blokadą do zapisu.
 \item Chubby pozwala jednemu z nich na otwarcie tego pliku.
 \item Węzeł zapisuje w tym pliku swój adres albo identyfikator.
 \item Wszystkie węzły są informowane o zmianie węzła master poprzez zdarzenie zmodyfikowania pliku, na które powinny wszystkie być zarejestrowane.
\end{enumerate}

Podobnie łatwo można zastosować ten system do wykrywania węzłów.
Chubby umożliwia tworzenie specjalnego rodzaju plików, zwanych plikami efemerycznymi.
Pliki te są usuwane natychmiast po ich zamknięciu, bądź po utracie połączenia z klientem, który go otwarł.
Jeżeli każdy węzeł podłączany do systemu utworzy efemeryczny plik w ogólnie znanym katalogu, wszystkie inne węzły z łatwością dowiedzą się o tej zmianie przy pomocy mechanizmu zdarzeń.
Podobnie jeżeli węzeł ulegnie awarii, jego plik zostanie wkrótce usunięty i inne węzły dowiedzą się o tym niemal natychmiast.

Google Chubby jest wprawdzie replikowany (komórka składa się zazwyczaj z 5 serwerów), ale cała komunikacja odbywa się między klientami a masterem\footnote{Artykuł \cite{google-chubby} opisuje potencjalne techniki skalowania przy pomocy partycjonowania i serwerów proxy, ale nie były one wykorzystywane w czasie pisania tego artykułu}.
Replikacja ma na celu jedynie zapewnienie wysokiej dostępności systemu.
Mimo tego ograniczenia Chubby jest w stanie obsłużyć ok. 90 000 klientów równocześnie.
Jest to na tyle duża liczba, że komórki Chubby są zazwyczaj współdzielone między różnymi aplikacjami.

W Google BigTable Chubby jest wykorzystywany do zapewnienia istnienia pojedynczego węzła master, wykrywania serwerów tabletów i ich awarii, przechowywania danych dotyczących schematu bazy i list dostępu.
Awaria i niedostępność Chubby powoduje także niedostępność BigTable.
Cytując za artykułem \cite{google-bigtable}, przełożyło się to średnio na zmniejszenie dostępności systemu średnio o 0.0047\%, a w najgorszym przypadku o 0.0326\%\footnote{Dla lepszego zobrazowania: odpowiednio 24 minuty i 171 minut w ciągu roku}.

\subsection*{Model Danych}

Google BigTable jest prekursorem tablicowych baz danych.
Model danych można opisać jako macierz, gdzie rzędami są rekordy, a kolumny reprezentują pola tych rekordów.
Każdy rząd identyfikowany jest przez klucz o wielkości maksymalnej 64KB, ale średnio klucze są mniejsze niż 100B.
System przechowuje rekordy posortowane po kluczu, podzielone na segmenty zwane tabletami.
Aby wykorzystać tę właściwość tabela przechowująca wyniki indeksowania sieci WWW, przechowuje adresy URL jako klucze w odwróconej kolejności (np. pl.edu.agh.eaie.www zamiast www.eaie.agh.edu.pl).
W ten sposób podobne klucze znajdą się blisko siebie.
Kolumny są grupowane w rodziny kolumn (ang. \emph{column families}).
Wszystkie kolumny z jednej rodziny mają nazwę postaci nazwa\_grupy:nazwa\_kolumny.
Nazwa grupy kolumn musi składać się ze znaków nadających się do wydruku, zaś nazwa kolumny może być dowolnym ciągiem bajtów.

Rodzina kolumn zazwyczaj przechowuje wartości tego samego typu, gdyż wartości te są kompresowane razem.
Rodzina kolumn musi być dodana do schematu zanim będzie możliwe dodawanie wartości w jej kolumnach.
Nie jest konieczne deklarowanie samych kolumn.
W bazach takich jak BigTable przyjmuje się, że liczba rodzin kolumn jest niewielka i zmienia się nieznacznie wraz z rozwojem aplikacji.
Jedynie nie-puste wartości kolumn są zapisywane, więc można powiedzieć, że tabela BigTable jest macierzą rzadką (ang. \emph{sparse}).

BigTable pozwala na przechowywanie wielu oznaczonych znacznikiem czasowym wersji dla każdej z komórek macierzy.
Stare rewizje mogą być usuwane przez system automatycznie albo dzięki określeniu maksymalnej liczby wartości do zapisania, albo przez określenie jak dawne wersje mają być przechowywane (np. z ostatnich siedmiu dni).

Modyfikacje rekordu są atomowe, co znacznie upraszcza pracę w rozproszonym środowisku.
Ponieważ rekordy są przechowywane posortowane, operacje na niewielkich\footnote{mniejszych niż rozmiar tabletu} zakresach podobnych kluczy zazwyczaj wymagają komunikacji z jednym albo dwoma węzłami systemu.
Dla porównania w Amazon Dynamo dla klucza jest wyliczana suma kontrolna i dopiero na podstawie tej wartości następuje przydział rekordu do określonego przedziału a co za tym idzie węzła, w związku z czym podobne klucze mogą znaleźć się na zupełnie innych węzłach.

Google BigTable nie udostępnia mechanizmów wyszukiwania rekordów podobnych do relacyjnych baz danych.
Jedyne mechanizmy wyszukiwania dla rekordów to wyszukiwanie po kluczu albo po zakresie kluczy.
Dla pojedynczego rekordu natomiast istnieje dość bogate API umożliwiające filtrowanie kolumn na różne sposoby.
Istnieje także możliwość wykonywania skryptów w przestrzeni adresowej serwera.
Skrypty te (pisane w języku Sawzall) nie mogą wprawdzie dokonywać żadnych modyfikacji, ale są przydatne w celu dokonywania różnorakich obliczeń czy podsumowań.

\subsection*{Architektura}

W tej sekcji przedstawiona zostanie architektura Google BigTable, najpierw z punktu widzenia całości systemu, a potem z punktu widzenia serwowania pojedynczego tabletu.

\subsubsection*{Architektura wysokiego poziomu}

W Google BigTable występują trzy rodzaje aktorów: \emph{master}, \emph{serwer tabletów}, i \emph{klient}.
Bardzo ważną rolę odgrywa też komórka Google Chubby.
Jak już wspomniano wyżej, rekordy w BigTable są zapisywane w grupach zwanych tabletami.
Każdy tablet reprezentuje pewien przedział kluczy.
Tablety mogą być dzielone i łączone w miarę potrzeby.

\emph{Master} zajmuje się przydziałem tabletów do serwerów tabletów, wykrywaniem dołączanych i usuwanych serwerów tabletów, równoważeniem obciążenia serwerów tabletów i usuwaniem zbędnych plików w GFS.

\emph{Serwer Tabletów} obsługuje zazwyczaj od 10 do 1000 tabletów.
Obsługuje zarówno odczyty, jak i zapisy, a także zajmuje się dzieleniem tabletów które przekroczyły maksymalny rozmiar.

Większość \emph{klientów} systemu nie musi się wcale komunikować z serwerem master.

Dane są zapisywane w trzypoziomowym drzewie.
Korzeniem tego drzewa jest tak zwany \emph{root tablet}.
Jest to specjalny tablet, który nigdy nie ulega podziałowi.
Jego lokalizacja jest zapisana w pliku w Google Chubby, a rolą tego tabletu jest przechowywanie lokalizacji tabletów zawierających metadane.
Tablety te przechowują lokalizacje wszystkich pozostałych tabletów w systemie (tabletów użytkownika).
Dane o lokalizacji tabletów są także buforowane u klienta w pamięci.

Serwery tabletów używają Google Chubby do rejestrowania się w systemie.
Aby tego dokonać przy starcie serwera tabletów tworzy on plik w specjalnym katalogu i zdobywa na nim blokadę do zapisu.
Dopóki serwer tabletów posiada tą blokadę, dopóty może on zajmować się serwowaniem tabletów.
Jeżeli straci blokadę, stara się ją odzyskać, jeżeli jednak plik na którym miał blokadę został usunięty, serwer tabletów jest zmuszony zakończyć działanie.
Węzeł master komunikuje się co pewien czas ze wszystkimi serwerami tabletów, żądając od nich podania statusu ich blokady.
Jeżeli master nie jest w stanie się połączyć z serwerem tabletów, lub jeżeli odpowie on, że stracił blokadę na pliku, master próbuje zdobyć tą blokadę i w przypadku powodzenia, usuwa plik powodując tym samym restart serwera tabletów.

\subsubsection*{Architektura serwera tabletów}

Dane o tablecie są zapisywane przez serwer tabletów w trzech lokacjach.
Pierwszą z nich jest \emph{tablet log}, do którego zapisywane są wszelkie modyfikujące tablet operacje.
Każda taka operacja musi zostać zapisana w tym pliku zanim zostanie przetworzona.

Po zapisaniu do \emph{tablet logu} operacja może zostać odwzorowana w pamięci operacyjnej.
Mutacje są wykonywane korzystając z techniki \emph{copy-on-write} (kopiowanie przy zapisie), dzięki czemu wynik operacji nie jest widoczny aż do jej zakończenia.
Co pewien czas struktura w pamięci (nazywana \emph{memtable}) jest zrzucana na dysk (do GFS) do pliku SSTable.
SSTable to format pozwalający na zapisywanie tablic asocjacyjnych, odczytywanie kluczy zakresami i posiadający specjalny indeks, który, po wczytaniu do pamięci operacyjnej przy otwarciu pliku, umożliwia odczyt dowolnej wartości z pliku przy pomocy pojedynczego wyszukania na dysku.

Odczyt musi przeszukać \emph{memtable} i wszystkie pliki SSTable, dlatego po przekroczeniu pewnego limitu plików SSTable, cześć z nich jest łączona w jeden.
Istnieje także możliwość połączenia wszystkich plików SSTable w jeden.

\subsection*{Znaczenie}

Wpływy Google BigTable można znaleźć w HBase, Hypertable, Apache Cassandra i nawet MongoDB.
Baza ta jest typowym przykładem systemu, który w obliczu wystąpienia podziałów sieci wybiera konsystencję kosztem dostępności (CP w Teorii CAP).
Bardzo interesujące jest zastosowanie Google Chubby w tym systemie jako sposób na uniknięcie skomplikowanego problemu rozproszonego konsensusu.
Odpowiednik Google Chubby o nazwie Zookeeper, zaimplementowany na potrzeby HBase, jest wykorzystywany do wyboru węzła master w grafowej bazie Neo4J.
Technika ta może być z powodzeniem stosowana w wielu systemach rozproszonych upraszczając ich architekturę.

Zainteresowanym lekturą artykułu przedstawiającego Google BigTable \cite{google-bigtable} polecam także lekturę dwóch innych pokrewnych artykułów o Google Chubby \cite{google-chubby} i Google File System \cite{google-file-system}.
Pominięcie ich może bowiem sprawić, że czytelnik nie będzie w stanie samodzielnie zrozumieć architektury BigTable, a tym bardziej konsekwencji jakie mają decyzje podjęte przez architektów firmy Google.

\section{Podsumowanie}

W powyższym rozdziale przedstawione zostały podstawowe artykuły i koncepcje które mają wpływ na skalowalne bazy danych które są obecnie dostępne na rynku.
Opisane zostały dwie wysoce skalowalne bazy danych wykorzystywane przez internetowych gigantów -- Google i Amazon.
Sukces obu rozwiązań nie ulega wątpliwości, a pokazują one jak bardzo mogą różnić się podejścia do skalowalności.
Z jednej strony mamy Amazon Dynamo, które stawia przede wszystkim na dostępność systemu, którą opłaca trudniejszym interfejsem z punktu widzenia programisty.
Z drugiej strony mamy Google BigTable, które poświęca dostępność dla konsystencji, ale dzięki temu jest o wiele prostsze i wymaga mniejszych nakładów pracy od programisty.
Przedstawiony został także framework MapReduce, który jest podstawą do wykonywania zapytań które muszą dokonać przeglądu wszystkich lub dużej części rekordów w bazie, w wielu nierelacyjnych systemach bazodanowych.