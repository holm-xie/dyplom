@Misc{ monash-db-hvsp,
	title = "The Naming of the Foo",
	author = "Curt Monash",
	month = mar,
	year = "2010",
	note = "Artyku{\l} sugerujący nazw\c{e} dla problemu rozwiązywanego przez NoSQL: HVSP (High Volume Simple Processing)",
	url = "http://www.dbms2.com/2010/03/13/the-naming-of-the-foo/"
}

@InProceedings{ google-bigtable,
	abstract = "Bigtable is a distributed storage system for managing structured data that is designed to scale to a very large size: petabytes of data across thousands of commodity servers. Many projects at Google store data in Bigtable, including web indexing, Google Earth, and Google Finance. These applications place very different demands on Bigtable, both in terms of data size (from URLs to web pages to satellite imagery) and latency requirements (from backend bulk processing to real-time data serving). Despite these varied demands, Bigtable has successfully provided a flexible, high-performance solution for all of these Google products. In this paper we describe the simple data model provided by Bigtable, which gives clients dynamic control over data layout and format, and we describe the design and implementation of Bigtable.",
	address = "Berkeley, CA, USA",
	author = "Fay Chang and Jeffrey Dean and Sanjay Ghemawat and Wilson C. Hsieh and Deborah A. Wallach and Mike Burrows and Tushar Chandra and Andrew Fikes and Robert E. Gruber",
	booktitle = "OSDI '06: Proceedings of the 7th symposium on Operating systems design and implementation",
	isbn = "1-931971-47-1",
	keywords = "bloom, bloom\_filter, data-intensive, distributed, parallel, storage",
	location = "Seattle, Washington",
	pages = "205--218",
	publisher = "USENIX Association",
	title = "Bigtable: a distributed storage system for structured data",
	url = "http://labs.google.com/papers/bigtable-osdi06.pdf",
	year = "2006",
	citeulike-article-id = "3765219",
	citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1298475",
	posted-at = "2009-02-02 22:45:44",
	priority = "0"
}

@Article{ amazon-dynamo,
	abstract = "Reliability at massive scale is one of the biggest challenges we face at Amazon.com, one of the largest e-commerce operations in the world; even the slightest outage has significant financial consequences and impacts customer trust. The Amazon.com platform, which provides services for many web sites worldwide, is implemented on top of an infrastructure of tens of thousands of servers and network components located in many datacenters around the world. At this scale, small and large components fail continuously and the way persistent state is managed in the face of these failures drives the reliability and scalability of the software systems. This paper presents the design and implementation of Dynamo, a highly available key-value storage system that some of Amazon's core services use to provide an ” always-on” experience. To achieve this level of availability, Dynamo sacrifices consistency under certain failure scenarios. It makes extensive use of object versioning and application-assisted conflict resolution in a manner that provides a novel interface for developers to use.",
	address = "New York, NY, USA",
	author = "Giuseppe DeCandia and Deniz Hastorun and Madan Jampani and Gunavardhan Kakulapati and Avinash Lakshman and Alex Pilchin and Swaminathan Sivasubramanian and Peter Vosshall and Werner Vogels",
	booktitle = "SOSP '07: Proceedings of twenty-first ACM SIGOPS symposium on Operating systems principles",
	doi = "10.1145/1294261.1294281",
	isbn = "9781595935915",
	issn = "0163-5980",
	journal = "SIGOPS Oper. Syst. Rev.",
	keywords = "2007, amazon, cloud, dynamo, key, sosp, value",
	number = "6",
	pages = "205--220",
	publisher = "ACM",
	title = "Dynamo: amazon's highly available key-value store",
	url = "http://s3.amazonaws.com/AllThingsDistributed/sosp/amazon-dynamo-sosp2007.pdf",
	volume = "41",
	year = "2007",
	citeulike-article-id = "1771837",
	citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1294281",
	citeulike-linkout-1 = "http://dx.doi.org/10.1145/1294261.1294281",
	posted-at = "2009-10-21 11:36:18",
	priority = "2"
}

@Article{ brewers-conjecture,
	abstract = "When designing distributed web services, there are three properties that are commonly desired: consistency, availability, and partition tolerance. It is impossible to achieve all three. In this note, we prove this conjecture in the asynchronous network model, and then discuss solutions to this dilemma in the partially synchronous model.",
	address = "New York, NY, USA",
	author = "Seth Gilbert and Nancy Lynch",
	doi = "10.1145/564585.564601",
	issn = "0163-5700",
	journal = "SIGACT News",
	keywords = "availability, available, brewer, conjecture, consistency, consistent, partition, tolerant",
	month = "June",
	number = "2",
	pages = "51--59",
	publisher = "ACM",
	title = "Brewer's conjecture and the feasibility of consistent, available, partition-tolerant web services",
	url = "http://lpd.epfl.ch/sgilbert/pubs/BrewersConjecture-SigAct.pdf",
	volume = "33",
	year = "2002",
	note = "Artyku{\l} formalnie dowodzący poprawno{\'s}ci Teorii CAP",
	citeulike-article-id = "1649756",
	citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=564601",
	citeulike-linkout-1 = "http://dx.doi.org/10.1145/564585.564601",
	posted-at = "2009-09-07 06:41:47",
	priority = "2"
}

@InProceedings{ podc-keynote,
	abstract = "Current distributed systems, even the ones that work, tend to be very fragile: they are hard to keep up, hard to manage, hard to grow, hard to evolve, and hard to program. In this talk, I look at several issues in an attempt to clean up the way we think about these systems. These issues include the fault model, high availability, graceful degradation, data consistency, evolution, composition, and autonomy. These are not (yet) provable principles, but merely ways to think about the issues that simplify design in practice. They draw on experience at Berkeley and with giant-scale systems built at Inktomi, including the system that handles 50\% of all web searches.",
	address = "New York, NY, USA",
	author = "Eric A. Brewer",
	booktitle = "PODC '00: Proceedings of the nineteenth annual ACM symposium on Principles of distributed computing",
	doi = "10.1145/343477.343502",
	isbn = "1-58113-183-6",
	journal = "Proceedings of the nineteenth annual ACM symposium on Principles of distributed computing",
	keywords = "distributed",
	location = "Portland, Oregon, United States",
	pages = "7+",
	publisher = "ACM",
	title = "Towards robust distributed systems",
	url = "http://www.cs.berkeley.edu/~brewer/cs262b-2004/PODC-keynote.pdf",
	year = "2000",
	note = "Slajdy z oryginalnej prezentacji Erica Brewera wprowadzającej poj\c{e}cie Teorii CAP",
	citeulike-article-id = "4299573",
	citeulike-linkout-0 = "http://www.cs.berkeley.edu/~brewer/cs262b-2004/PODC-keynote.pdf",
	citeulike-linkout-1 = "http://portal.acm.org/citation.cfm?id=343502",
	citeulike-linkout-2 = "http://dx.doi.org/10.1145/343477.343502",
	comment = "CAP Theorem. - Among Consistency, Availability, and Tolerance to network Partition, you can acheive at most two.",
	posted-at = "2009-04-11 09:51:07",
	priority = "0"
}

@Misc{ google-lessons,
	title = "Designs, Lessons and Advice from Building Large Distributed Systems",
	author = "Jeffrey Dean",
	month = oct,
	year = "2009",
	note = "Interesująca prezentacja Google, zawierająca wiele liczb dotyczących awaryjno{\'s}ci us{\l}ug rozproszonych na setkach tysi\c{e}cy serwer{\'o}w.",
	keywords = "distributed",
	url = "http://www.cs.cornell.edu/projects/ladis2009/talks/dean-keynote-ladis2009.pdf"
}

@Misc{ vogels-consistency,
	title = "Availability \& Consistency",
	author = "Werner Vogels",
	note = "Prezentacja CTO Amazon na konferencji QCon dotycząca skalowalnych serwis{\'o}w, a także teorii CAP i jej implikacji.",
	url = "http://www.infoq.com/presentations/availability-consistency",
	year = "2007"
}

@Misc{ browne-cap-theorem,
	title = "Brewer's CAP Theorem",
	author = "Julian Browne",
	key = "browne-cap-theorem",
	note = "Najciekawszy opis Teorii CAP, jaki znalaz{\l}em w sieci. Zdecydowanie warty przeczytania.",
	keywords = "availability, brewer, consistency, partition",
	url = "http://www.julianbrowne.com/article/viewer/brewers-cap-theorem",
	year = "2009"
}

@Misc{ highscalability-mysql-end-of-an-era,
	title = "MySQL and Memcached: End of an Era?",
	author = "Todd Hoff",
	url = "http://highscalability.com/blog/2010/2/26/mysql-and-memcached-end-of-an-era.html",
	note = "Artyku{\l} obwieszczający kres ery MySQL+Memcached na popularnym blogu High Scalability",
	year = "2010"
}

@Misc{ zaitsev-scaling-mysql,
	title = "Scaling MySQL-powered Web Sites by Sharding and Replication",
	author = "Peter Zaitsev",
	note = "Prezentacja na temat skalowania aplikacji opartych na MySQL. Opisuje dobre praktyki i ich ograniczenia.",
	url = "http://www.percona.com/files/presentations/Scaling-Web-Sites-by-Sharding-and-Replication.pdf",
	year = "2010"
}

@Misc{ codinghorror-scaling-up-vs-out,
	title = "Scaling Up vs. Scaling Out: Hidden Costs",
	author = "Jeff Atwood",
	note = "Artyku{\l} por{\'o}wnujący koszta skalowania wszerz i wzwyż.",
	url = "http://www.codinghorror.com/blog/2009/06/scaling-up-vs-scaling-out-hidden-costs.html",
	year = "2009"
}

@Misc{ highscalability-mysql-memcached,
	title = "A Bunch of Great Strategies for Using Memcached and MySql Better Together",
	author = "Todd Hoff",
	month = aug,
	year = "2008",
	note = "Przegląd strategii cacheowania na podstawie do{\'s}wiadcze{\'n} tw{\'o}rc{\'o}w serwisu Fotolog",
	url = "http://highscalability.com/bunch-great-strategies-using-memcached-and-mysql-better-together"
}

@Misc{ evans-nosql-what-is-in-a-name,
	title = "NoSQL: What's in a name?",
	author = "Eric Evans",
	month = oct,
	year = "2009",
	note = "Artyku{\l} wyja{\'s}niający pochodzenie terminu NoSQL",
	url = "http://blog.sym-link.com/2009/10/30/nosql_whats_in_a_name.html"
}

@Article{ base-an-acid-alternative,
	author = "Dan Pritchett",
	title = "BASE: An Acid Alternative",
	journal = "Queue",
	volume = "6",
	number = "3",
	year = "2008",
	issn = "1542-7730",
	pages = "48--55",
	doi = "http://doi.acm.org/10.1145/1394127.1394128",
	publisher = "ACM",
	address = "New York, NY, USA",
	note = "Artyku{\l} wprowadzający termin BASE i por{\'o}wnujący go do ACID.",
	url = "http://portal.acm.org/ft_gateway.cfm?id=1394128&type=pdf"
}

@Article{ vogels-eventually-consistent,
	author = "Werner Vogels",
	journal = "ACM Queue",
	keywords = "distributed",
	title = "Eventually Consistent",
	url = "http://portal.acm.org/ft_gateway.cfm?id=1466448&type=pdf",
	year = "2008",
	note = "Artyku{\l} obszernie obja{\'s}niający Eventual Consisteny (E w BASE) wraz z r{\'o}żnymi jej wariantami.",
	citeulike-article-id = "4313360",
	citeulike-linkout-0 = "http://queue.acm.org/detail.cfm?id=1466448",
	comment = "[quote]In larger distributed-scale system, network partitions are a given; therefore, consistency and availability cannot be achieved at the same time.[/quote] From the statement above, this article discuss weak consistency, eventually consistency, and their variations. Also server side setup with various N(number of nodes storing replicas), W(nodes needs to be acknowledged before write), and R(nodes neeeds to be accessed for read) configurations are discussed.",
	posted-at = "2009-04-15 14:34:27",
	priority = "0"
}

@InProceedings{ google-mapreduce,
	abstract = "MapReduce is a programming model and an associated implementation for processing and generating large data sets. Users specify a \_map\_ function that processes a key/value pair to generate a set of intermediate key/value pairs, and a \_reduce\_ function that merges all intermediate values associated with the same intermediate key. Many real world tasks are expressible in this model, as shown in the paper. <P> Programs written in this functional style are automatically parallelized and executed on a large cluster of commodity machines. The run-time system takes care of the details of partitioning the input data, scheduling the program's execution across a set of machines, handling machine failures, and managing the required inter- machine communication. This allows programmers without any experience with parallel and distributed systems to easily utilize the resources of a large distributed system. <P> Our implementation of MapReduce runs on a large cluster of commodity machines and is highly scalable: a typical MapReduce computation processes many terabytes of data on thousands of machines. Programmers find the system easy to use: hundreds of MapReduce programs have been implemented and upwards of one thousand MapReduce jobs are executed on Google's clusters every day. <P>",
	author = "Jeffrey Dean and Sanjay Ghemawat",
	journal = "OSDI '04",
	keywords = "google, map-reduce",
	month = "December",
	pages = "137--150",
	title = "MapReduce: Simplified Data Processing on Large Clusters",
	url = "http://labs.google.com/papers/mapreduce-osdi04.pdf",
	year = "2004",
	note = "Znany artyku{\l} opisujący stosowany w firmie Google framework MapReduce",
	citeulike-article-id = "430834",
	citeulike-linkout-0 = "http://www.usenix.org/events/osdi04/tech/dean.html",
	posted-at = "2008-02-11 12:00:06",
	priority = "0"
}

